"""
coordinator.py â€” ã‚´ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³ã®å¸ä»¤å¡”

ã‚´ãƒ¼ãƒ«ï¼ˆè‡ªç„¶è¨€èªï¼‰ã‚’å—ã‘å–ã‚Šã€åˆ†è§£â†’å§”ä»»â†’çµ±åˆâ†’å ±å‘Šã™ã‚‹ã€‚
è‡ªåˆ†ã§ã¯ä½•ã‚‚å®Ÿè¡Œã—ãªã„ã€‚tool_registry.json ã®ãƒ„ãƒ¼ãƒ«å®šç¾©ã«å¾“ã„ã€
handler_runner.py ã‚’é€šã˜ã¦ãƒãƒ³ãƒ‰ãƒ©ã«å§”ä»»ã™ã‚‹ã€‚

è¨­è¨ˆåŸå‰‡:
  - Coordinator ã¯ãƒ„ãƒ¼ãƒ«ã®ã€Œä½•ãŒã§ãã‚‹ã‹ã€ã ã‘çŸ¥ã£ã¦ã„ã‚‹
  - ãƒ„ãƒ¼ãƒ«ã®ã€Œã©ã†å®Ÿè¡Œã™ã‚‹ã‹ã€ã¯ handler_runner ãŒæ‹…ã†
  - æ–°ã—ã„ãƒ„ãƒ¼ãƒ«è¿½åŠ  = tool_registry.json ã«1ä»¶è¿½åŠ ã™ã‚‹ã ã‘
"""

import json
import os
import re
import time
from datetime import datetime
from pathlib import Path

import anthropic

from handler_runner import HandlerRunner

# Coordinator ãŒä½¿ã† LLM ãƒ¢ãƒ‡ãƒ«
COORDINATOR_MODEL = "claude-haiku-4-5-20251001"
COORDINATOR_MAX_TOKENS = 2000
MAX_ROUNDS = 10  # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãƒ«ãƒ¼ãƒ—ã®ä¸Šé™


def _build_claude_tools(registry: dict) -> list:
    """tool_registry.json ã‹ã‚‰ Claude API tool_use å½¢å¼ã«å¤‰æ›ã™ã‚‹"""
    tools = []
    for tool_def in registry["tools"]:
        schema = tool_def.get("input_schema", {"type": "object", "properties": {}})
        tools.append({
            "name": tool_def["name"],
            "description": tool_def["description"],
            "input_schema": schema,
        })
    return tools


def _load_agent_summary(project_root: Path) -> str:
    """profiles.json ã‹ã‚‰ active ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆäººé–“+AIï¼‰ã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    Coordinator ãŒã‚´ãƒ¼ãƒ«ã«å¯¾ã—ã¦æœ€é©ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸ã¶ãŸã‚ã®æƒ…å ±ã€‚"""
    profiles_path = project_root / "Master" / "people" / "profiles.json"
    if not profiles_path.exists():
        return ""

    try:
        profiles = json.loads(profiles_path.read_text(encoding="utf-8"))
    except Exception:
        return ""

    lines = ["ã€åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸€è¦§ã€‘"]

    # AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    ai_agents = []
    for name, prof in profiles.items():
        latest = prof.get("latest", {})
        if latest.get("type") != "ai":
            continue
        if latest.get("status", "active") == "inactive":
            continue
        caps = ", ".join(latest.get("capabilities", []))
        best = ", ".join(latest.get("best_for", []))
        speed = latest.get("constraints", {}).get("speed", "")
        cost = latest.get("constraints", {}).get("cost", "")
        ai_agents.append(f"  [{name}] AI / å¾—æ„: {best} / é€Ÿåº¦: {speed} / ã‚³ã‚¹ãƒˆ: {cost}")

    if ai_agents:
        lines.append("AI:")
        lines.extend(ai_agents)

    # äººé–“ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆä¸»è¦ãƒ¡ãƒ³ãƒãƒ¼ã®ã¿ã€‚capabilities ãŒã‚ã‚‹äººã ã‘ï¼‰
    human_agents = []
    for name, prof in profiles.items():
        latest = prof.get("latest", {})
        if latest.get("type") != "human":
            continue
        caps = latest.get("capabilities")
        if not caps:
            # capabilities ãŒãªã„äººé–“ã¯ã€inferred_domains + category ã§ä»£æ›¿
            domains = latest.get("inferred_domains", [])
            cat = latest.get("category", "")
            if domains and cat in ("ç›´ä¸‹ãƒ¡ãƒ³ãƒãƒ¼", "æ¨ªï¼ˆä¸¦åˆ—ï¼‰", "ä¸Šå¸"):
                human_agents.append(f"  [{name}] {cat} / ã‚¹ã‚­ãƒ«: {', '.join(domains[:3])}")
        else:
            best = ", ".join(latest.get("best_for", caps[:3]))
            human_agents.append(f"  [{name}] {latest.get('category', '')} / å¾—æ„: {best}")

    if human_agents:
        lines.append("äººé–“ï¼ˆä¸»è¦ãƒ¡ãƒ³ãƒãƒ¼ï¼‰:")
        lines.extend(human_agents[:10])  # ä¸Šä½10åã«åˆ¶é™

    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆtransfer_status ä»˜ãï¼‰
    workflow_agents = []
    for name, prof in profiles.items():
        latest = prof.get("latest", {})
        if latest.get("type") != "workflow":
            continue
        if latest.get("status", "active") == "inactive":
            continue
        best = ", ".join(latest.get("best_for", []))
        transfer = latest.get("transfer", {})
        t_status = transfer.get("transfer_status", "")
        t_target = transfer.get("transferable_to", "")
        status_text = f" [ç§»è­²: {t_status} â†’ {t_target}]" if t_status and t_target else ""
        workflow_agents.append(f"  [{name}] ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ / ç”¨é€”: {best}{status_text}")

    if workflow_agents:
        lines.append("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:")
        lines.extend(workflow_agents)

    return "\n".join(lines)


def _load_video_knowledge(project_root: Path, goal_text: str = "") -> str:
    """ã‚´ãƒ¼ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã«é–¢é€£ã™ã‚‹å‹•ç”»çŸ¥è­˜ã‚’æ¤œç´¢ã—ã¦æ³¨å…¥ã™ã‚‹ã€‚
    auto_confirm ã‚‚åŒæ™‚ã«å®Ÿè¡Œã™ã‚‹ã€‚"""
    knowledge_path = Path.home() / "agents" / "data" / "video_knowledge.json"
    if not knowledge_path.exists():
        return ""
    try:
        entries = json.loads(knowledge_path.read_text(encoding="utf-8"))
    except Exception:
        return ""
    if not entries:
        return ""

    # auto_confirm: pending â†’ confirmedï¼ˆ1æ™‚é–“è¶…ï¼‰
    now = datetime.now()
    changed = False
    for e in entries:
        if e.get("status") != "pending":
            continue
        learned_at = e.get("learned_at", "")
        if not learned_at:
            continue
        try:
            dt = datetime.strptime(learned_at, "%Y-%m-%dT%H:%M:%S")
        except ValueError:
            continue
        if (now - dt).total_seconds() > 3600:
            e["status"] = "confirmed"
            changed = True

    confirmed = [e for e in entries if e.get("status", "confirmed") == "confirmed"]
    if not confirmed:
        if changed:
            _save_video_knowledge(knowledge_path, entries)
        return ""

    # ã‚´ãƒ¼ãƒ«ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆ: é–¢é€£æ€§ãƒ™ãƒ¼ã‚¹ã§ä¸Šä½5ä»¶ã«çµã‚‹
    if goal_text:
        query_lower = goal_text.lower()
        query_words = set(query_lower.split())

        scored = []
        for e in confirmed:
            score = 0
            title = (e.get("title") or "").lower()
            summary = (e.get("summary") or "").lower()
            url = (e.get("url") or "").lower()
            procs = " ".join(e.get("key_processes", [])).lower()

            # URLç›´æ¥ãƒãƒƒãƒã¯é«˜ã‚¹ã‚³ã‚¢
            if url and url in query_lower:
                score += 100

            # å˜èªãƒãƒƒãƒ
            for word in query_words:
                if len(word) < 2:
                    continue
                if word in title:
                    score += 3
                if word in summary:
                    score += 2
                if word in procs:
                    score += 2

            if score > 0:
                scored.append((score, e))

        if not scored:
            if changed:
                _save_video_knowledge(knowledge_path, entries)
            return ""

        scored.sort(key=lambda x: x[0], reverse=True)
        selected = [e for _, e in scored[:5]]

        # access_count / last_accessed ã‚’æ›´æ–°
        now_str = now.strftime("%Y-%m-%dT%H:%M:%S")
        selected_ids = {e.get("id") for e in selected}
        for e in entries:
            if e.get("id") in selected_ids:
                e["access_count"] = e.get("access_count", 0) + 1
                e["last_accessed"] = now_str
        changed = True
    else:
        # ã‚´ãƒ¼ãƒ«ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„å ´åˆ: å…¨ä»¶ï¼ˆæœ€å¤§10ä»¶ã€æ–°ã—ã„é †ï¼‰
        selected = confirmed[-10:]

    if changed:
        _save_video_knowledge(knowledge_path, entries)

    lines = ["ã€é–¢é€£ã™ã‚‹å‹•ç”»çŸ¥è­˜ã€‘"]
    for i, e in enumerate(selected, 1):
        source_label = {"loom": "Loom", "youtube": "YouTube"}.get(e.get("source", ""), e.get("source", ""))
        date = e.get("learned_at", "")[:10]
        lines.append(f"[{i}] {e.get('title', '')} ({source_label}, {date})")
        lines.append(f"  è¦ç´„: {e.get('summary', '')}")
        procs = e.get("key_processes", [])
        if procs:
            lines.append(f"  æ‰‹é †: {' â†’ '.join(procs)}")
    return "\n".join(lines)


def _save_video_knowledge(path: Path, data: list):
    """video_knowledge.json ã‚’ã‚¢ãƒˆãƒŸãƒƒã‚¯æ›¸ãè¾¼ã¿ã§ä¿å­˜"""
    tmp = path.with_suffix(".tmp")
    tmp.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    tmp.rename(path)


def _build_system_prompt(sender_name: str = "", project_root: Path = None, goal_text: str = "") -> str:
    """Coordinator ç”¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"""
    prompt = """ã‚ãªãŸã¯ç”²åŸæµ·äººã®AIç§˜æ›¸ã‚·ã‚¹ãƒ†ãƒ ã® Coordinator ã§ã™ã€‚

ã€æœ€é‡è¦ãƒ«ãƒ¼ãƒ«: èªè­˜ã®ã™ã‚Šåˆã‚ã›ã€‘
ã‚´ãƒ¼ãƒ«ã‚’å—ã‘å–ã£ãŸã‚‰ã€ã¾ãšè‡ªåˆ†ã®èªè­˜ã‚’æç¤ºã—ã¦ç¢ºèªã‚’å–ã‚‹ã“ã¨ã€‚
è‡ªåˆ†ãŒåˆã£ã¦ã„ã‚‹ã¨æ€ã„è¾¼ã¾ãªã„ã€‚å¿…ãšèªè­˜ã®ã‚ºãƒ¬ãŒãªã„ã‹ç¢ºèªã™ã‚‹ã€‚

ã€Œèªè­˜ãŒåˆã£ã¦ã„ã‚‹ã€ã¨ã¯ã€ä»¥ä¸‹ã®3ã¤ãŒæƒã£ã¦ã„ã‚‹çŠ¶æ…‹ã‚’æŒ‡ã™:
  - è¦–é‡: ä½•ã‚’è¦‹ã¦ã„ã‚‹ã‹ï¼ˆå¯¾è±¡ç¯„å›²ã€‚æŠœã‘æ¼ã‚ŒãŒãªã„ã‹ï¼‰
  - è¦–åº§: ã©ã®ç«‹å ´ã‹ã‚‰è¦‹ã¦ã„ã‚‹ã‹ï¼ˆèª°ã®ç›®ç·šã§è€ƒãˆã‚‹ã‹ï¼‰
  - è¦–ç‚¹: ä½•ã«æ³¨ç›®ã—ã¦ã„ã‚‹ã‹ï¼ˆå„ªå…ˆã™ã¹ããƒã‚¤ãƒ³ãƒˆã¯ä½•ã‹ï¼‰

ç¢ºèªã®ä»•æ–¹:
  âœ•ã€Œã“ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ã„ã„ã§ã™ã‹ï¼Ÿã€â† è¨±å¯ã‚’æ±‚ã‚ã‚‹ã®ã¯NG
  â—‹ã€Œã“ã®èªè­˜ã§åˆã£ã¦ã„ã¾ã™ã‹ï¼Ÿã€â† è¦–é‡ãƒ»è¦–åº§ãƒ»è¦–ç‚¹ã®ã™ã‚Šåˆã‚ã›ã‚’ã™ã‚‹

ä¾‹:
  ã‚´ãƒ¼ãƒ«ã€Œæ¥é€±ã®å•†è«‡ã«å‚™ãˆã¦ã€ã«å¯¾ã—ã¦:
  âœ•ã€Œã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚’ç¢ºèªã—ã¦å•†è«‡æº–å‚™ãƒ¡ãƒ¢ã‚’ä½œæˆã—ã¦ã‚ˆã„ã§ã™ã‹ï¼Ÿã€
  â—‹ã€Œæ¥é€±ã®å•†è«‡ = ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«ã‚ã‚‹äºˆå®šã®ã“ã¨ã§ã™ã­ã€‚
     ã€è¦–é‡ã€‘å‚åŠ è€…æƒ…å ±ãƒ»éå»ã®ã‚„ã‚Šå–ã‚Šãƒ»é–¢é€£æ•°å€¤
     ã€è¦–åº§ã€‘ç”²åŸã•ã‚“ãŒå•†è«‡ã§ä¸»å°æ¨©ã‚’æŒã¦ã‚‹çŠ¶æ…‹ã«ã™ã‚‹
     ã€è¦–ç‚¹ã€‘å…ˆæ–¹ã¸ã®æœªè¿”ä¿¡ï¼ˆè¦‹ç©ã‚‚ã‚Šï¼‰ãŒæœ€å„ªå…ˆ
     ã“ã®èªè­˜ã§åˆã£ã¦ã„ã¾ã™ã‹ï¼Ÿã€

ç¢ºèªãŒå–ã‚ŒãŸã‚‰ï¼ˆã€Œã†ã‚“ã€ã€Œåˆã£ã¦ã‚‹ã€ã€Œãã‚Œã§ã€ç­‰ã®è¿”ç­”ãŒã‚ã£ãŸã‚‰ï¼‰ã€
ã™ãã«ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦å®Ÿè¡Œã«ç§»ã‚‹ã€‚

ãŸã ã—ä»¥ä¸‹ã¯ç¢ºèªä¸è¦ã§å³å®Ÿè¡Œã—ã¦ã‚ˆã„:
- ã€Œä»Šæ—¥ä½•ã™ã‚Œã°ã„ã„ï¼Ÿã€ã®ã‚ˆã†ãªæ˜ç¢ºãªæƒ…å ±å–å¾—ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
- ã€ŒKPIæ•™ãˆã¦ã€ã®ã‚ˆã†ãªå˜ç´”ãªç…§ä¼š
- ã€Œãƒ¡ãƒ¼ãƒ«ç¢ºèªã—ã¦ã€ã®ã‚ˆã†ãªæ—¢å­˜ã‚³ãƒãƒ³ãƒ‰ç›¸å½“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ

ã€å½¹å‰²ã€‘
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚´ãƒ¼ãƒ«ï¼ˆã‚„ã‚ŠãŸã„ã“ã¨ï¼‰ã‚’ç†è§£ã—ã€é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’é¸ã‚“ã§å®Ÿè¡Œã—ã€çµæœã‚’ã¾ã¨ã‚ã¦å ±å‘Šã™ã‚‹ã€‚

ã€ãƒ«ãƒ¼ãƒ«ã€‘
1. æ›–æ˜§ãªã‚´ãƒ¼ãƒ«ã‚„è¤‡æ•°è§£é‡ˆã§ãã‚‹ã‚´ãƒ¼ãƒ« â†’ å¿…ãšèªè­˜ç¢ºèªã—ã¦ã‹ã‚‰å®Ÿè¡Œ
2. æƒ…å ±å–å¾—ç³»ã®ãƒ„ãƒ¼ãƒ«ï¼ˆcalendar, mail, kpi, people, addness, sheets, searchï¼‰ã¯ä¸¦åˆ—ã§å‘¼ã‚“ã§OK
3. draft_reply, analyze, generate_image, generate_video ã¯ã€å¿…è¦ãªæƒ…å ±ãŒæƒã£ã¦ã‹ã‚‰å‘¼ã¶
4. send_message, ask_human ã¯ã€Œé€ä¿¡ææ¡ˆã€ã‚’è¿”ã™ã ã‘ã€‚å®Ÿéš›ã®é€ä¿¡ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ‰¿èªå¾Œ
5. æœ€çµ‚å ±å‘Šã¯ç°¡æ½”ã«ã€‚ç®‡æ¡æ›¸ãã§ã€‚LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦èª­ã¿ã‚„ã™ã„å½¢å¼ã§
6. ãƒ„ãƒ¼ãƒ«ãŒä¸è¦ãªç°¡å˜ãªè³ªå•ã«ã¯ã€ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã°ãšç›´æ¥å›ç­”ã—ã¦ã‚‚OK

ã€ç”ŸæˆAIç³»ãƒ„ãƒ¼ãƒ«ã€‘
- search: Webæ¤œç´¢ãŒå¿…è¦ãªã¨ãï¼ˆæœ€æ–°æƒ…å ±ã€ä¼æ¥­èª¿æŸ»ã€å¸‚å ´å‹•å‘ï¼‰â†’ Perplexity ã«å§”ä»»
- generate_image: ç”»åƒãƒ»ãƒãƒŠãƒ¼åˆ¶ä½œ â†’ Lubert ã«å§”ä»»
- generate_video: å‹•ç”»åˆ¶ä½œ â†’ å‹•ç”»AI ã«å§”ä»»ï¼ˆæœªè¨­å®šã®å ´åˆã¯ãã®æ—¨ã‚’è¿”ã™ï¼‰
- APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãƒ„ãƒ¼ãƒ«ã¯ã€æœªè¨­å®šã§ã‚ã‚‹æ—¨ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å ±å‘Šã™ã‚‹

ã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç§»è­²ãƒ«ãƒ¼ãƒ«ã€‘
profiles.json ã® transfer.transfer_status ã«å¿œã˜ã¦ã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æŒ¯ã‚Šå…ˆã‚’è‡ªå‹•ã§å¤‰ãˆã‚‹:
- Phase 1ï¼ˆAIå…¨è‡ªå‹•ï¼‰: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ç›´æ¥å®Ÿè¡Œã‚’å§”ä»»
- Phase 2ï¼ˆAIå®Ÿè¡Œ+äººé–“ç¢ºèªï¼‰: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã€çµæœã‚’ transfer_target ã®äººé–“ã«ã‚‚å…±æœ‰
- Phase 3ï¼ˆäººé–“å®Ÿè¡Œ+AIã‚µãƒãƒ¼ãƒˆï¼‰: transfer_target ã®äººé–“ã«ä¾é ¼ã—ã€AIã¯ã‚µãƒãƒ¼ãƒˆæƒ…å ±ã‚’æä¾›
- Phase 4ï¼ˆå®Œå…¨è‡ªèµ°ï¼‰: transfer_target ã®äººé–“ã«ç›´æ¥ä¾é ¼ã€‚AIã¯ä¸è¦

ã€å‹•ç”»å­¦ç¿’ãƒ•ãƒ­ãƒ¼ã€‘
Loomã‚„YouTubeã®URLãŒé€ã‚‰ã‚Œã¦ã€Œè¦‹ã¦ãŠã„ã¦ã€ã€Œç¢ºèªã—ã¦ã€ç­‰ã®æŒ‡ç¤ºãŒã‚ã£ãŸã‚‰:
1. video_reader ãƒ„ãƒ¼ãƒ«ã§å†…å®¹ã‚’å–å¾—
2. transcript_summaryï¼ˆã‚ã‚Œã°å„ªå…ˆï¼‰ã¾ãŸã¯ transcript_text ã‹ã‚‰å†…å®¹ã‚’ç†è§£ã—ã€è¦ç´„+æ‰‹é †ã‚’ç®‡æ¡æ›¸ãã§å ±å‘Š
3. åŒã˜ãƒ„ãƒ¼ãƒ«ãƒ«ãƒ¼ãƒ—å†…ã§ save_video_learning(status="pending") ã‚’å‘¼ã‚“ã§å³ä¿å­˜
4. å ±å‘Š + ã€Œä¿®æ­£ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„ã€‚ãªã‘ã‚Œã°ãã®ã¾ã¾è¦šãˆã¾ã™ã€
â€» OKã®è¿”äº‹ã¯ä¸è¦ã€‚ä¿®æ­£ãŒãªã‘ã‚Œã°1æ™‚é–“å¾Œã«è‡ªå‹•ç¢ºå®šã•ã‚Œã‚‹
â€» ä¿®æ­£æŒ‡ç¤ºãŒæ¥ãŸã‚‰ update_video_learning ã§æ›´æ–°ã™ã‚‹

ã€ç¦æ­¢ã€‘
- èªè­˜ç¢ºèªãªã—ã«æ›–æ˜§ãªã‚´ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨
- ã€Œå®Ÿè¡Œã—ã¦ã„ã„ã§ã™ã‹ï¼Ÿã€ã¨ã„ã†è¨±å¯å‹ã®è³ªå•
- ä¸è¦ãªãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ï¼ˆèã‹ã‚Œã¦ã„ãªã„æƒ…å ±ã¾ã§å–ã‚Šã«è¡Œã‹ãªã„ï¼‰
- 1å›ã®ã‚´ãƒ¼ãƒ«ã§10å›ä»¥ä¸Šã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—"""

    if sender_name:
        prompt += f"\n\nã€é€ä¿¡è€…ã€‘\n{sender_name}ï¼ˆç§˜æ›¸ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰ã®æŒ‡ç¤ºï¼‰"

    # profiles.json ã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸€è¦§ã‚’æ³¨å…¥
    if project_root:
        agent_summary = _load_agent_summary(project_root)
        if agent_summary:
            prompt += f"\n\n{agent_summary}"
            prompt += "\n\nä¸Šè¨˜ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¾—æ„åˆ†é‡ã‚’è¸ã¾ãˆã¦ãƒ„ãƒ¼ãƒ«ã‚’é¸æŠã™ã‚‹ã“ã¨ã€‚äººé–“ã«ä¾é ¼ã™ã‚‹å ´åˆã¯ ask_human ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã€‚"

        # éå»ã®å‹•ç”»çŸ¥è­˜ã‚’é–¢é€£æ€§ãƒ™ãƒ¼ã‚¹ã§æ³¨å…¥
        video_knowledge = _load_video_knowledge(project_root, goal_text)
        if video_knowledge:
            prompt += f"\n\n{video_knowledge}"

    return prompt


def _strip_markdown_for_line(text: str) -> str:
    """LINEé€ä¿¡å‰ã«ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã‚’é™¤å»"""
    text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
    text = re.sub(r'__(.+?)__', r'\1', text)
    text = re.sub(r'(?<!\w)\*(.+?)\*(?!\w)', r'\1', text)
    text = re.sub(r'(?<!\w)_(.+?)_(?!\w)', r'\1', text)
    text = re.sub(r'`(.+?)`', r'\1', text)
    text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
    return text


def execute_goal(
    goal: str,
    sender_name: str = "",
    system_dir: Path = None,
    project_root: Path = None,
    function_handlers: dict = None,
) -> tuple:
    """
    ã‚´ãƒ¼ãƒ«ã‚’å—ã‘å–ã‚Šã€åˆ†è§£â†’å§”ä»»â†’çµ±åˆâ†’å ±å‘Šã™ã‚‹ã€‚

    Args:
        goal:              ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚´ãƒ¼ãƒ«ï¼ˆè‡ªç„¶è¨€èªï¼‰
        sender_name:       é€ä¿¡è€…åï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ï¼‰
        system_dir:        System/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        project_root:      ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
        function_handlers:  {tool_name: callable(arguments) -> str} ã®ãƒãƒƒãƒ”ãƒ³ã‚°

    Returns:
        (success: bool, result_text: str)
    """
    # --- åˆæœŸåŒ– ---
    # APIã‚­ãƒ¼: ç’°å¢ƒå¤‰æ•° â†’ config.json ã®é †ã§å–å¾—
    api_key = os.environ.get("ANTHROPIC_API_KEY", "")
    if not api_key:
        config_path = Path(__file__).parent / "config.json"
        if config_path.exists():
            try:
                cfg = json.loads(config_path.read_text(encoding="utf-8"))
                api_key = cfg.get("anthropic_api_key", "")
            except Exception:
                pass
    if not api_key:
        return False, "ANTHROPIC_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ config.json ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
    try:
        client = anthropic.Anthropic(api_key=api_key)
    except Exception as e:
        return False, f"Claude API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"

    # ãƒ„ãƒ¼ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªèª­ã¿è¾¼ã¿
    registry_path = Path(__file__).parent / "tool_registry.json"
    try:
        with open(registry_path, encoding="utf-8") as f:
            registry = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        return False, f"tool_registry.json ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"

    claude_tools = _build_claude_tools(registry)
    system_prompt = _build_system_prompt(sender_name, project_root, goal_text=goal)

    # ãƒãƒ³ãƒ‰ãƒ©ãƒ©ãƒ³ãƒŠãƒ¼
    try:
        runner = HandlerRunner(
            system_dir=system_dir,
            project_root=project_root,
            function_handlers=function_handlers or {},
        )
    except Exception as e:
        return False, f"HandlerRunner ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"

    # --- ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãƒ«ãƒ¼ãƒ— ---
    messages = [{"role": "user", "content": goal}]
    total_tool_calls = 0
    start_time = time.time()

    for round_num in range(MAX_ROUNDS):
        try:
            response = client.messages.create(
                model=COORDINATOR_MODEL,
                max_tokens=COORDINATOR_MAX_TOKENS,
                system=system_prompt,
                tools=claude_tools,
                messages=messages,
            )
        except anthropic.APITimeoutError:
            return False, "Claude API ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„"
        except anthropic.APIConnectionError:
            return False, "Claude API ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ…‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
        except anthropic.APIError as e:
            return False, f"Claude API ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        except Exception as e:
            return False, f"Coordinator ã®å‡¦ç†ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {e}"

        # å®Œäº†åˆ¤å®š: end_turn â†’ æœ€çµ‚å›ç­”
        if response.stop_reason == "end_turn":
            text_parts = []
            for block in response.content:
                if hasattr(block, "text"):
                    text_parts.append(block.text)
            result = "\n".join(text_parts)
            elapsed = time.time() - start_time
            print(f"   ğŸ¯ Coordinator å®Œäº†: {round_num + 1}ãƒ©ã‚¦ãƒ³ãƒ‰, "
                  f"{total_tool_calls}ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—, {elapsed:.1f}ç§’")
            return True, _strip_markdown_for_line(result)

        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—
        if response.stop_reason == "tool_use":
            # assistant ã®å¿œç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
            messages.append({
                "role": "assistant",
                "content": [_serialize_content_block(b) for b in response.content],
            })

            # å„ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
            tool_results = []
            for block in response.content:
                if block.type == "tool_use":
                    total_tool_calls += 1
                    tool_name = block.name
                    tool_input = block.input

                    print(f"   ğŸ”§ [{round_num + 1}] {tool_name}({json.dumps(tool_input, ensure_ascii=False)[:100]})")

                    result_text = runner.run(tool_name, tool_input) or "ï¼ˆçµæœãªã—ï¼‰"

                    # çµæœã‚’æ–‡å­—æ•°åˆ¶é™ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„ï¼‰
                    # video_reader ã¯ transcript ã‚’å«ã‚€ãŸã‚ä¸Šé™ã‚’ç·©å’Œ
                    max_len = 4000 if tool_name == "video_reader" else 2000
                    if len(result_text) > max_len:
                        result_text = result_text[:max_len] + "\n\nï¼ˆ...çœç•¥ï¼‰"

                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": block.id,
                        "content": result_text,
                    })

            messages.append({"role": "user", "content": tool_results})
            continue

        # ãã®ä»–ã® stop_reason
        text_parts = []
        for block in response.content:
            if hasattr(block, "text"):
                text_parts.append(block.text)
        if text_parts:
            return True, _strip_markdown_for_line("\n".join(text_parts))
        return True, "ï¼ˆå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼‰"

    # ãƒ«ãƒ¼ãƒ—ä¸Šé™åˆ°é”
    elapsed = time.time() - start_time
    print(f"   âš ï¸ Coordinator ãƒ«ãƒ¼ãƒ—ä¸Šé™åˆ°é”: {MAX_ROUNDS}ãƒ©ã‚¦ãƒ³ãƒ‰, {elapsed:.1f}ç§’")
    return True, "å‡¦ç†ãŒè¤‡é›‘ãªãŸã‚é€”ä¸­ã§ä¸­æ–­ã—ã¾ã—ãŸã€‚ã‚‚ã†å°‘ã—å…·ä½“çš„ã«æŒ‡ç¤ºã—ã¦ãã ã•ã„ã€‚"


def _serialize_content_block(block) -> dict:
    """Anthropic SDK ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ–ãƒ­ãƒƒã‚¯ã‚’ dict ã«å¤‰æ›ã™ã‚‹"""
    if block.type == "text":
        return {"type": "text", "text": block.text}
    elif block.type == "tool_use":
        return {
            "type": "tool_use",
            "id": block.id,
            "name": block.name,
            "input": block.input,
        }
    return {"type": "text", "text": str(block)}
