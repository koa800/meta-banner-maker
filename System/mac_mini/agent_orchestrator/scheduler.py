"""
APScheduler-based task scheduler for the agent orchestrator.
Replaces cron jobs with in-process scheduling and logging.
"""

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger

import os
import re
from datetime import datetime

from . import tools
from .memory import MemoryStore
from .shared_logger import get_logger

logger = get_logger("scheduler")

_repair_agent_ref = None


def set_repair_agent(agent):
    """Set the RepairAgent reference for the scheduler to use."""
    global _repair_agent_ref
    _repair_agent_ref = agent


class TaskScheduler:
    def __init__(self, config: dict, memory: MemoryStore):
        self.config = config
        self.memory = memory
        self.scheduler = AsyncIOScheduler()
        self._task_map = {
            "addness_fetch": self._run_addness_fetch,
            "ai_news": self._run_ai_news,
            "mail_inbox_personal": self._run_mail_personal,
            "mail_inbox_kohara": self._run_mail_kohara,
            "addness_goal_check": self._run_addness_goal_check,
            "daily_report": self._run_daily_report,
            "health_check": self._run_health_check,
            "repair_check": self._run_repair_check,
            "weekly_idea_proposal": self._run_weekly_idea_proposal,
            "weekly_stats": self._run_weekly_stats,
            "daily_addness_digest": self._run_daily_addness_digest,
            "oauth_health_check": self._run_oauth_health_check,
            "render_health_check": self._run_render_health_check,
            "weekly_content_suggestions": self._run_weekly_content_suggestions,
            "kpi_daily_import": self._run_kpi_daily_import,
            "sheets_sync": self._run_sheets_sync,
            "git_pull_sync": self._run_git_pull_sync,
            "daily_group_digest": self._run_daily_group_digest,
            "weekly_profile_learning": self._run_weekly_profile_learning,
            "kpi_nightly_cache": self._run_kpi_nightly_cache,
            "log_rotate": self._run_log_rotate,
            "slack_ai_team_check": self._run_slack_ai_team_check,
        }

    def setup(self):
        schedule_cfg = self.config.get("schedule", {})

        for task_name, task_fn in self._task_map.items():
            cfg = schedule_cfg.get(task_name, {})
            if not cfg.get("enabled", False):
                logger.info(f"Task '{task_name}' is disabled, skipping")
                continue

            if "cron" in cfg:
                parts = cfg["cron"].split()
                trigger = CronTrigger(
                    minute=parts[0], hour=parts[1], day=parts[2],
                    month=parts[3], day_of_week=parts[4]
                )
                self.scheduler.add_job(task_fn, trigger, id=task_name, name=task_name, replace_existing=True)
                logger.info(f"Scheduled '{task_name}' with cron: {cfg['cron']}")
            elif "interval_minutes" in cfg:
                trigger = IntervalTrigger(minutes=cfg["interval_minutes"])
                self.scheduler.add_job(task_fn, trigger, id=task_name, name=task_name, replace_existing=True)
                logger.info(f"Scheduled '{task_name}' every {cfg['interval_minutes']} minutes")

    def start(self):
        self.scheduler.start()
        logger.info("Scheduler started")

    def shutdown(self):
        self.scheduler.shutdown()
        logger.info("Scheduler shut down")

    # ã‚¿ã‚¹ã‚¯å¤±æ•—é€šçŸ¥ã‚’é€ã‚‰ãªã„ã‚¿ã‚¹ã‚¯ï¼ˆè‡ªå‰ã§ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã™ã‚‹ã‚‚ã®ï¼‰
    _NO_FAILURE_NOTIFY = {"health_check", "oauth_health_check", "render_health_check"}
    # git_pull_syncã¯ç‹¬è‡ªã®é »åº¦åˆ¶é™ä»˜ãé€šçŸ¥ã‚’å®Ÿè£…ï¼ˆ_run_git_pull_syncå‚ç…§ï¼‰

    async def _execute_tool(self, task_name: str, tool_fn, **kwargs) -> tools.ToolResult:
        task_id = self.memory.log_task_start(task_name, metadata=kwargs)
        try:
            result = tool_fn(**kwargs)
            status = "success" if result.success else "error"
            self.memory.log_task_end(
                task_id, status,
                result_summary=result.output[:500] if result.output else None,
                error_message=result.error[:500] if result.error else None
            )
            if result.success:
                logger.info(f"Task '{task_name}' completed successfully")
                self.memory.set_state(f"last_success_{task_name}", datetime.now().isoformat())
            else:
                logger.error(f"Task '{task_name}' failed: {result.error[:200]}")
                if task_name not in self._NO_FAILURE_NOTIFY:
                    self._maybe_notify_task_failure(task_name, result.error or "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
            return result
        except Exception as e:
            self.memory.log_task_end(task_id, "error", error_message=str(e))
            logger.exception(f"Task '{task_name}' raised an exception")
            if task_name not in self._NO_FAILURE_NOTIFY:
                self._maybe_notify_task_failure(task_name, str(e))
            raise

    def _maybe_notify_task_failure(self, task_name: str, error_msg: str):
        """ã‚¿ã‚¹ã‚¯å¤±æ•—ã‚’LINE+Slacké€šçŸ¥ï¼ˆ2æ™‚é–“ä»¥å†…ã«åŒã‚¿ã‚¹ã‚¯ã®é€šçŸ¥æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼‰"""
        from .notifier import notify_ai_team
        now = datetime.now()
        state_key = f"failure_notified_{task_name}"
        last_notified = self.memory.get_state(state_key)
        if last_notified:
            try:
                last_dt = datetime.fromisoformat(last_notified)
                if (now - last_dt).total_seconds() < 7200:
                    return  # 2æ™‚é–“ä»¥å†…ã¯é€šçŸ¥æ¸ˆã¿
            except (ValueError, TypeError):
                pass
        ok = notify_ai_team(
            f"\nâš ï¸ ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {task_name}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"{error_msg[:250]}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”"
        )
        if ok:
            self.memory.set_state(state_key, now.isoformat())

    async def _run_addness_fetch(self):
        result = await self._execute_tool("addness_fetch", tools.addness_fetch)
        if result.success:
            ctx_result = await self._execute_tool("addness_to_context", tools.addness_to_context)
            from .notifier import send_line_notify
            send_line_notify(f"âœ… Addnessã‚´ãƒ¼ãƒ«åŒæœŸå®Œäº†ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ{'æ›´æ–°æ¸ˆã¿' if ctx_result.success else 'æ›´æ–°å¤±æ•—'}ï¼‰")
        else:
            await self._execute_tool("addness_to_context", tools.addness_to_context)

    async def _run_ai_news(self):
        result = await self._execute_tool("ai_news", tools.ai_news_notify)
        if result.success and result.output:
            from .notifier import send_line_notify
            # ai_news_notifyã¯è‡ªå‰ã§LINEé€šçŸ¥ã™ã‚‹ã®ã§ã€ã“ã“ã§ã¯è¿½åŠ é€šçŸ¥ã—ãªã„
            logger.info(f"AI news completed: {result.output[:100]}")

    async def _run_mail_personal(self):
        result = await self._execute_tool("mail_inbox_personal", tools.mail_run, account="personal")
        await self._notify_mail_result(result, "personal")

    async def _run_mail_kohara(self):
        result = await self._execute_tool("mail_inbox_kohara", tools.mail_run, account="kohara")
        await self._notify_mail_result(result, "kohara")

    async def _notify_mail_result(self, result: tools.ToolResult, account: str):
        """ãƒ¡ãƒ¼ãƒ«å‡¦ç†çµæœã‚’LINE+Slacké€šçŸ¥ï¼ˆè¿”ä¿¡å¾…ã¡ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰"""
        if not result.success or not result.output:
            return
        from .notifier import notify_ai_team as send_line_notify  # LINE+SlackåŒæ™‚é€ä¿¡

        waiting_m = re.search(r"è¿”ä¿¡å¾…ã¡[ï¼š:]\s*(\d+)\s*ä»¶", result.output)
        delete_m = re.search(r"å‰Šé™¤ç¢ºèª[ï¼š:]\s*(\d+)\s*ä»¶", result.output)

        waiting = int(waiting_m.group(1)) if waiting_m else 0
        delete = int(delete_m.group(1)) if delete_m else 0

        if waiting <= 0:
            return

        account_label = "personal" if account == "personal" else "kohara"
        message = (
            f"\nğŸ“¬ ãƒ¡ãƒ¼ãƒ«ç¢ºèª ({account_label})\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"è¿”ä¿¡å¾…ã¡: {waiting}ä»¶"
            + (f" / å‰Šé™¤ç¢ºèª: {delete}ä»¶" if delete > 0 else "")
            + f"\nâ”â”â”â”â”â”â”â”â”â”â”â”"
        )
        ok = send_line_notify(message)
        if ok:
            logger.info(f"Mail notification sent for {account}: waiting={waiting}")
        else:
            logger.warning(f"Mail notification failed for {account}")

    async def _run_addness_goal_check(self):
        result = await self._execute_tool("addness_to_context", tools.addness_to_context)
        if result.success:
            logger.info("Addness goal context updated for daily review")

    async def _run_daily_report(self):
        from .notifier import send_line_notify
        from datetime import date
        summary = self.memory.get_daily_summary()
        stats = self.memory.get_task_stats(since_hours=24)

        total = summary["tasks_total"]
        success = summary["tasks_success"]
        errors = summary["tasks_errors"]
        success_rate = round(100 * success / total) if total > 0 else 0

        error_tasks = [name for name, s in stats.items() if s.get("error", 0) > 0]

        report_lines = [
            f"\nğŸ“Š æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ ({date.today().strftime('%m/%d')})",
            "â”â”â”â”â”â”â”â”â”â”â”â”",
            f"ã‚¿ã‚¹ã‚¯: {success}/{total}ä»¶æˆåŠŸ ({success_rate}%)",
            f"APIã‚³ãƒ¼ãƒ«: {summary['api_calls']}å›",
        ]
        if error_tasks:
            report_lines.append(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {', '.join(error_tasks[:5])}")
        report_lines.append("â”â”â”â”â”â”â”â”â”â”â”â”")

        send_line_notify("\n".join(report_lines))

        report_text = (
            f"--- Daily Agent Report ---\n"
            f"Tasks: {total} total, {success} success, {errors} errors\n"
            f"API calls: {summary['api_calls']} (tokens: {summary['api_tokens']})\n"
            f"Task breakdown: {stats}"
        )
        logger.info(report_text)
        self.memory.set_state("last_daily_report", report_text)

    async def _run_health_check(self):
        import json as _json
        from .notifier import send_line_notify
        api_calls = self.memory.get_api_calls_last_hour()
        limit = self.config.get("safety", {}).get("api_call_limit_per_hour", 100)
        if api_calls > limit * 0.9:
            logger.warning(f"API call rate critical: {api_calls}/{limit} in last hour")
            send_line_notify(
                f"\nâš ï¸ APIä½¿ç”¨é‡è­¦å‘Š\nç›´è¿‘1æ™‚é–“: {api_calls}/{limit}å›\n"
                f"APIåˆ¶é™ã«è¿‘ã¥ã„ã¦ã„ã¾ã™ã€‚Anthropicãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            )
        elif api_calls > limit * 0.8:
            logger.warning(f"API call rate high: {api_calls}/{limit} in last hour")

        # Q&Aãƒ¢ãƒ‹ã‚¿ãƒ¼ã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯æ™‚åˆ»ã‚’ç¢ºèªï¼ˆ2æ™‚é–“ä»¥ä¸Šæœªæ›´æ–°ãªã‚‰è­¦å‘Šï¼‰
        qa_state_path = os.path.expanduser("~/agents/line_bot_local/qa_monitor_state.json")
        if os.path.exists(qa_state_path):
            try:
                with open(qa_state_path) as f:
                    qa_state = _json.load(f)
                last_check = qa_state.get("last_check")
                if last_check:
                    dt = datetime.fromisoformat(last_check.replace("Z", "+00:00"))
                    age_hours = (datetime.now().astimezone() - dt).total_seconds() / 3600
                    if age_hours > 4:
                        logger.warning(f"Q&A monitor stale: last check {age_hours:.1f}h ago")
                        state_key = "qa_monitor_stale_notified"
                        last_n = self.memory.get_state(state_key)
                        if not last_n or (datetime.now() - datetime.fromisoformat(last_n)).total_seconds() > 14400:
                            send_line_notify(
                                f"\nâš ï¸ Q&Aãƒ¢ãƒ‹ã‚¿ãƒ¼åœæ­¢ã®å¯èƒ½æ€§\næœ€çµ‚ãƒã‚§ãƒƒã‚¯: {age_hours:.0f}æ™‚é–“å‰\n"
                                f"local_agent.py ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
                            )
                            self.memory.set_state(state_key, datetime.now().isoformat())
            except Exception as e:
                logger.debug(f"Q&A state check error: {e}")

        # local_agent.py ã®ç”Ÿå­˜ç¢ºèªï¼ˆãƒ—ãƒ­ã‚»ã‚¹å­˜åœ¨ãƒã‚§ãƒƒã‚¯ â†’ ãƒ­ã‚°æ›´æ–°æ™‚åˆ»ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        try:
            import time
            agent_alive = False
            try:
                result = subprocess.run(
                    ["launchctl", "list", "com.linebot.localagent"],
                    capture_output=True, text=True, timeout=5
                )
                # launchctl list ãŒæˆåŠŸ & PID ãŒæ•°å­—ãªã‚‰ãƒ—ãƒ­ã‚»ã‚¹ç”Ÿå­˜
                if result.returncode == 0 and result.stdout.strip():
                    parts = result.stdout.strip().split()
                    agent_alive = parts[0].isdigit() if parts else False
            except Exception:
                pass

            if not agent_alive:
                logger.warning("local_agent process not found via launchctl")
                state_key = "local_agent_stale_notified"
                last_n = self.memory.get_state(state_key)
                if not last_n or (datetime.now() - datetime.fromisoformat(last_n)).total_seconds() > 3600:
                    send_line_notify(
                        "\nâš ï¸ local_agent åœæ­¢\nãƒ—ãƒ­ã‚»ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n"
                        "com.linebot.localagent ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                    )
                    self.memory.set_state(state_key, datetime.now().isoformat())
        except Exception as e:
            logger.debug(f"local_agent check error: {e}")

        # KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥é®®åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆ48æ™‚é–“è¶…ã§è­¦å‘Šï¼‰
        kpi_cache = os.path.expanduser("~/agents/System/data/kpi_summary.json")
        if os.path.exists(kpi_cache):
            try:
                import time
                cache_age_hours = (time.time() - os.path.getmtime(kpi_cache)) / 3600
                if cache_age_hours > 48:
                    state_key = "kpi_cache_stale_notified"
                    last_n = self.memory.get_state(state_key)
                    if not last_n or (datetime.now() - datetime.fromisoformat(last_n)).total_seconds() > 21600:  # 6æ™‚é–“ã«1å›
                        send_line_notify(
                            f"âš ï¸ KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥æœªæ›´æ–°\n"
                            f"æœ€çµ‚æ›´æ–°: {cache_age_hours:.0f}æ™‚é–“å‰\n"
                            f"AIç§˜æ›¸ã®KPIãƒ‡ãƒ¼ã‚¿ãŒå¤ããªã£ã¦ã„ã¾ã™"
                        )
                        self.memory.set_state(state_key, datetime.now().isoformat())
            except Exception as e:
                logger.debug(f"KPI cache check error: {e}")

        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯ï¼ˆ90%è¶…ã§è­¦å‘Šï¼‰
        try:
            import shutil
            usage = shutil.disk_usage(os.path.expanduser("~"))
            used_pct = usage.used / usage.total * 100
            if used_pct > 90:
                state_key = "disk_critical_notified"
                last_n = self.memory.get_state(state_key)
                if not last_n or (datetime.now() - datetime.fromisoformat(last_n)).total_seconds() > 21600:
                    free_gb = usage.free / (1024**3)
                    send_line_notify(
                        f"âš ï¸ Mac Mini ãƒ‡ã‚£ã‚¹ã‚¯æ®‹é‡è­¦å‘Š\n"
                        f"ä½¿ç”¨ç‡: {used_pct:.1f}% / æ®‹ã‚Š: {free_gb:.1f}GB\n"
                        f"ãƒ­ã‚°ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ•´ç†ãŒå¿…è¦ã§ã™"
                    )
                    self.memory.set_state(state_key, datetime.now().isoformat())
        except Exception as e:
            logger.debug(f"Disk check error: {e}")

        # Orchestratorã‚¯ãƒ©ãƒƒã‚·ãƒ¥ãƒ«ãƒ¼ãƒ—æ¤œçŸ¥ï¼ˆèµ·å‹•ã‹ã‚‰5åˆ†ä»¥å†…ã®å†ãƒã‚§ãƒƒã‚¯ãŒçŸ­æ™‚é–“ã«ç¹°ã‚Šè¿”ã•ã‚Œã‚‹ï¼‰
        try:
            uptime_key = "orchestrator_boot_time"
            boot_time = self.memory.get_state(uptime_key)
            now = datetime.now()
            if not boot_time:
                self.memory.set_state(uptime_key, now.isoformat())
            else:
                boot_dt = datetime.fromisoformat(boot_time)
                uptime_min = (now - boot_dt).total_seconds() / 60
                # èµ·å‹•5åˆ†ä»¥å†…ã«health_checkãŒèµ°ã‚‹ï¼å†èµ·å‹•ç›´å¾Œ
                if uptime_min < 5:
                    crash_key = "orchestrator_recent_boots"
                    recent = int(self.memory.get_state(crash_key) or "0") + 1
                    self.memory.set_state(crash_key, str(recent))
                    if recent >= 3:
                        state_key = "crash_loop_notified"
                        last_n = self.memory.get_state(state_key)
                        if not last_n or (datetime.now() - datetime.fromisoformat(last_n)).total_seconds() > 3600:
                            send_line_notify(
                                f"ğŸš¨ Orchestratorã‚¯ãƒ©ãƒƒã‚·ãƒ¥ãƒ«ãƒ¼ãƒ—æ¤œçŸ¥\n"
                                f"çŸ­æ™‚é–“ã«{recent}å›å†èµ·å‹•ã—ã¦ã„ã¾ã™\n"
                                f"ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                            )
                            self.memory.set_state(state_key, datetime.now().isoformat())
                elif uptime_min > 10:
                    # å®‰å®šç¨¼åƒä¸­ â†’ ã‚«ã‚¦ãƒ³ã‚¿ãƒªã‚»ãƒƒãƒˆ
                    self.memory.set_state("orchestrator_recent_boots", "0")
        except Exception as e:
            logger.debug(f"Crash loop check error: {e}")

        running_jobs = len(self.scheduler.get_jobs())
        self.memory.set_state("health_status", "ok")
        self.memory.set_state("running_jobs", str(running_jobs))
        logger.debug(f"Health check OK: {running_jobs} jobs scheduled, {api_calls} API calls/hour")

    async def _run_weekly_idea_proposal(self):
        """æ¯é€±æœˆæ›œ: agent_ideas.md ã‹ã‚‰æœªç€æ‰‹P0/P1ã‚’1ä»¶ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¦LINEé€šçŸ¥"""
        from .notifier import send_line_notify

        ideas_path = os.path.expanduser(
            os.path.join(self.config.get("paths", {}).get("repo_root", "~/Desktop/cursor"),
                         "System/mac_mini/agent_ideas.md")
        )
        if not os.path.exists(ideas_path):
            logger.warning("agent_ideas.md not found")
            return

        with open(ideas_path, encoding="utf-8") as f:
            content = f.read()

        # P0ãƒ»P1ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æœ€åˆã®æœªç€æ‰‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’å–å¾—
        current_priority = ""
        candidate = None
        for line in content.splitlines():
            if re.match(r"^## ğŸ”´ P0", line):
                current_priority = "P0"
            elif re.match(r"^## ğŸŸ  P1", line):
                current_priority = "P1"
            elif re.match(r"^## ğŸŸ¡ P2", line):
                break  # P0/P1ã ã‘å¯¾è±¡

            m = re.match(r"^- \[ \] (.+)", line)
            if m and current_priority in ("P0", "P1"):
                candidate = (current_priority, m.group(1).strip())
                break

        if not candidate:
            logger.info("No pending P0/P1 ideas found")
            return

        priority, task_text = candidate
        # èª¬æ˜è¡Œï¼ˆ*æ ¹æ‹ *ï¼‰ãŒã‚ã‚Œã°å–å¾—
        reason = ""
        lines = content.splitlines()
        for i, line in enumerate(lines):
            if task_text in line and i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                if next_line.startswith("- *æ ¹æ‹ *"):
                    reason = "\n" + next_line
                break

        message = (
            f"\nğŸ’¡ ä»Šé€±ã®ãŠã™ã™ã‚ã‚¿ã‚¹ã‚¯ï¼ˆ{priority}ï¼‰\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"{task_text}{reason}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"â†’ agent_ideas.md ã§ç®¡ç†ä¸­"
        )
        task_id = self.memory.log_task_start("weekly_idea_proposal")
        ok = send_line_notify(message)
        self.memory.log_task_end(task_id, "success" if ok else "error",
                                 result_summary=task_text[:100])
        logger.info(f"Weekly idea proposal sent: {task_text[:80]}")

    async def _run_daily_addness_digest(self):
        """æ¯æœ8:30: actionable-tasks.mdï¼ˆã‚¿ã‚¹ã‚¯ï¼‰+ ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼ˆä»Šæ—¥ã®äºˆå®šï¼‰ã‚’LINE+Slacké€šçŸ¥"""
        from .notifier import notify_ai_team as send_line_notify  # LINE+SlackåŒæ™‚é€ä¿¡
        from datetime import date

        master_dir = self.config.get("paths", {}).get("master_dir", "~/agents/Master")
        actionable_path = os.path.expanduser(os.path.join(master_dir, "addness", "actionable-tasks.md"))
        goal_tree_path = os.path.expanduser(os.path.join(master_dir, "addness", "goal-tree.md"))

        # actionable-tasks.md ã‚’å„ªå…ˆä½¿ç”¨ã€ãªã‘ã‚Œã°æ—§æ–¹å¼ goal-tree ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if os.path.exists(actionable_path):
            await self._digest_from_actionable(actionable_path, send_line_notify)
        elif os.path.exists(goal_tree_path):
            await self._digest_from_goal_tree(goal_tree_path, send_line_notify)
        else:
            logger.warning("Neither actionable-tasks.md nor addness-goal-tree.md found")

        # ä»Šæ—¥ã®ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚’åˆ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§é€šçŸ¥ï¼ˆç‹¬ç«‹ã—ã¦å‹•ä½œï¼‰
        await self._notify_today_calendar(send_line_notify)

        # ç‰¹æ®Šãªç· ã‚åˆ‡ã‚Šãƒ»ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼ãƒã‚§ãƒƒã‚¯ï¼ˆ90/30/7æ—¥å‰ã«é€šçŸ¥ï¼‰
        await self._check_special_reminders(send_line_notify)

    async def _notify_today_calendar(self, send_line_notify):
        """ä»Šæ—¥ã®ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼äºˆå®šã‚’LINEé€šçŸ¥ï¼ˆäºˆå®šãŒãªã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ï¼‰"""
        import json as _json
        from datetime import date
        try:
            result = tools.calendar_list(account="personal", days=1)
            if not result.success or not result.output or "äºˆå®šã¯ã‚ã‚Šã¾ã›ã‚“" in result.output:
                return

            today_str = date.today().strftime("%Y/%m/%d")
            # people-profiles.json ã‚’èª­ã¿è¾¼ã‚“ã§åå‰â†’ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®è¾æ›¸ã‚’ä½œæˆ
            master_dir = os.path.expanduser(
                self.config.get("paths", {}).get("master_dir", "~/agents/Master")
            )
            profiles_path = os.path.join(master_dir, "people", "profiles.json")
            profiles = {}
            try:
                if os.path.exists(profiles_path):
                    with open(profiles_path, encoding="utf-8") as pf:
                        raw = _json.load(pf)
                    for key, val in raw.items():
                        entry = val.get("latest", val)
                        name = entry.get("name", key)
                        email = entry.get("email", "")
                        category = entry.get("category", "")
                        summary = entry.get("capability_summary", "")[:60]
                        profiles[key] = {"name": name, "email": email, "category": category, "summary": summary}
                        if email:
                            profiles[email] = profiles[key]
            except Exception:
                pass

            # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹
            # å„è¡Œ: "  [id] 2026-02-21T10:00:00+09:00 ~ ...  ã‚¿ã‚¤ãƒˆãƒ«"
            # æ¬¡è¡Œ: "    å‚åŠ è€…: ä¸‰ä¸Š åŠŸå¤ª, ..."
            events = []
            lines = result.output.splitlines()
            i = 0
            while i < len(lines):
                line = lines[i]
                m = re.match(r"\s*\[.+?\]\s+(\S+)\s*~\s*\S+\s+(.+)", line)
                if m:
                    dt_str = m.group(1)
                    title = m.group(2).strip()
                    time_part = dt_str.split("T")[1][:5] if "T" in dt_str else "çµ‚æ—¥"
                    # æ¬¡è¡ŒãŒå‚åŠ è€…è¡Œã‹ãƒã‚§ãƒƒã‚¯
                    attendee_info = ""
                    if i + 1 < len(lines) and "å‚åŠ è€…:" in lines[i + 1]:
                        att_str = lines[i + 1].split("å‚åŠ è€…:", 1)[1].strip()
                        att_names = [a.strip() for a in att_str.split(",")]
                        matched = []
                        for att in att_names[:4]:
                            # emailã¾ãŸã¯åå‰ã§ãƒãƒƒãƒãƒ³ã‚°
                            prof = profiles.get(att)
                            if not prof:
                                # éƒ¨åˆ†ä¸€è‡´
                                for k, v in profiles.items():
                                    if att in k or att in v.get("name", ""):
                                        prof = v
                                        break
                            if prof and prof.get("category"):
                                matched.append(f"{prof['name']}({prof['category']})")
                            elif att and "@" not in att:
                                matched.append(att)
                        if matched:
                            attendee_info = f" [{', '.join(matched[:3])}]"
                        i += 1  # å‚åŠ è€…è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    events.append(f"  {time_part} {title}{attendee_info}")
                i += 1

            if not events:
                return

            message = (
                f"\nğŸ“… ä»Šæ—¥ã®äºˆå®š ({today_str})\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”\n"
                + "\n".join(events[:8])
                + "\nâ”â”â”â”â”â”â”â”â”â”â”â”"
            )
            ok = send_line_notify(message)
            if ok:
                logger.info(f"Calendar digest sent: {len(events)} events")
            else:
                logger.warning("Calendar digest notification failed")
        except Exception as e:
            logger.debug(f"Calendar digest error: {e}")

    async def _digest_from_actionable(self, path: str, send_line_notify):
        """actionable-tasks.md ã‹ã‚‰æ—¥æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        from datetime import date
        today_str = date.today().strftime("%Y/%m/%d")

        with open(path, encoding="utf-8") as f:
            content = f.read()

        # ãƒ‡ãƒ¼ã‚¿æ›´æ–°æ—¥æ™‚ã®å–å¾—
        update_m = re.search(r"æ›´æ–°æ—¥æ™‚[^\|]*\|\s*(.+)", content)
        data_date = update_m.group(1).strip().rstrip("|").strip() if update_m else "ä¸æ˜"

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ãƒ‘ãƒ¼ã‚¹ï¼ˆğŸ”´æœŸé™è¶…é / ğŸ”„å®Ÿè¡Œä¸­ï¼‰
        overdue_items = []
        in_progress_items = []
        current_section = ""

        for line in content.splitlines():
            if "ğŸ”´ æœŸé™è¶…é" in line:
                current_section = "overdue"
            elif "ğŸ”„ å®Ÿè¡Œä¸­" in line:
                current_section = "in_progress"
            elif re.match(r"^## ", line):
                current_section = "other"

            if current_section == "overdue":
                m = re.match(r"^\d+\.\s+\*\*(.+?)\*\*", line)
                if m:
                    title = m.group(1).strip()[:50]
                    # æœŸé™æƒ…å ±ã‚’å«ã‚ã‚‹
                    deadline_m = re.search(r"æœŸé™[ï¼š:]\s*(\d{4}/\d{2}/\d{2})", line)
                    if deadline_m:
                        title += f"ï¼ˆæœŸé™: {deadline_m.group(1)}ï¼‰"
                    overdue_items.append(title)

            elif current_section == "in_progress":
                m = re.match(r"^\d+\.\s+\*\*(.+?)\*\*", line)
                if m:
                    in_progress_items.append(m.group(1).strip()[:50])

        if not overdue_items and not in_progress_items:
            logger.info("No urgent Addness tasks for today")
            return

        parts = [f"\nğŸ“‹ ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ï¼ˆ{today_str}ï¼‰\nâ”â”â”â”â”â”â”â”â”â”â”â”"]
        if overdue_items:
            parts.append(f"ğŸ”´ æœŸé™è¶…é ({len(overdue_items)}ä»¶):")
            parts.extend(f"  ãƒ»{t}" for t in overdue_items[:4])
        if in_progress_items:
            parts.append(f"ğŸ”„ å®Ÿè¡Œä¸­:")
            parts.extend(f"  ãƒ»{t}" for t in in_progress_items[:3])
        parts.append(f"â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ“… ãƒ‡ãƒ¼ã‚¿: {data_date}")

        message = "\n".join(parts)
        task_id = self.memory.log_task_start("daily_addness_digest")
        ok = send_line_notify(message)
        self.memory.log_task_end(task_id, "success" if ok else "error")
        logger.info(f"Daily digest sent: {len(overdue_items)} overdue, {len(in_progress_items)} in_progress")

    async def _digest_from_goal_tree(self, path: str, send_line_notify):
        """goal-tree.md ã‹ã‚‰æ—¥æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆfallbackï¼‰"""
        from datetime import date
        today = date.today()
        today_str = today.strftime("%Y/%m/%d")

        with open(path, encoding="utf-8") as f:
            lines = f.readlines()

        overdue, due_today, due_soon = [], [], []
        for line in lines:
            if "ç”²åŸ" not in line and "kohara" not in line.lower() and "koa" not in line.lower():
                continue
            m = re.search(r"æœŸé™[ï¼š:]\s*(\d{4}/\d{2}/\d{2})", line)
            if not m:
                continue
            deadline_str = m.group(1)
            try:
                deadline = date.fromisoformat(deadline_str.replace("/", "-"))
            except ValueError:
                continue
            title_m = re.search(r"\*\*(.+?)\*\*", line)
            title = title_m.group(1) if title_m else line.strip()[:60]
            delta = (deadline - today).days
            if delta < 0:
                overdue.append(f"ğŸ”´ {title}ï¼ˆ{deadline_str}ï¼‰")
            elif delta == 0:
                due_today.append(f"ğŸŸ¡ {title}ï¼ˆæœ¬æ—¥æœŸé™ï¼‰")
            elif delta <= 7:
                due_soon.append(f"ğŸŸ  {title}ï¼ˆæ®‹{delta}æ—¥ï¼‰")

        if not overdue and not due_today and not due_soon:
            logger.info("No urgent Addness goals for today")
            return

        parts = [f"\nğŸ“‹ Addness æ—¥æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆï¼ˆ{today_str}ï¼‰\nâ”â”â”â”â”â”â”â”â”â”â”â”"]
        if overdue:
            parts.append("ã€æœŸé™è¶…éã€‘\n" + "\n".join(overdue[:5]))
        if due_today:
            parts.append("ã€æœ¬æ—¥æœŸé™ã€‘\n" + "\n".join(due_today[:3]))
        if due_soon:
            parts.append("ã€ä»Šé€±æœŸé™ã€‘\n" + "\n".join(due_soon[:5]))
        parts.append("â”â”â”â”â”â”â”â”â”â”â”â”")

        task_id = self.memory.log_task_start("daily_addness_digest")
        ok = send_line_notify("\n".join(parts))
        self.memory.log_task_end(task_id, "success" if ok else "error")
        logger.info("Daily Addness digest sent (from goal tree)")

    async def _run_render_health_check(self):
        """Renderã‚µãƒ¼ãƒãƒ¼ã®æ­»æ´»ç›£è¦–ï¼ˆ30åˆ†ã”ã¨ï¼‰"""
        import json as _json
        import urllib.request
        from .notifier import send_line_notify

        server_url = os.environ.get("LINE_BOT_SERVER_URL", "https://line-mention-bot-mmzu.onrender.com")
        try:
            req = urllib.request.Request(server_url + "/", headers={"Accept": "application/json"})
            with urllib.request.urlopen(req, timeout=45) as resp:
                body = resp.read().decode("utf-8", errors="replace")
                if resp.status == 200:
                    self.memory.set_state("render_last_ok", datetime.now().isoformat())
                    logger.debug(f"Render health OK: {body[:100]}")
                    return
                else:
                    raise Exception(f"HTTP {resp.status}")
        except Exception as e:
            err_str = str(e)[:150]
            logger.warning(f"Render health check failed: {err_str}")

            # ç›´è¿‘30åˆ†ä»¥å†…ã«é€šçŸ¥æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
            last_notified = self.memory.get_state("render_health_notified")
            if last_notified:
                try:
                    if (datetime.now() - datetime.fromisoformat(last_notified)).total_seconds() < 1800:
                        return
                except (ValueError, TypeError):
                    pass

            ok = send_line_notify(
                f"\nâš ï¸ Renderã‚µãƒ¼ãƒãƒ¼å¿œç­”ãªã—\n{server_url}\n\nã‚¨ãƒ©ãƒ¼: {err_str}\n"
                f"LINEç§˜æ›¸ãŒå¿œç­”ã§ãã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
            )
            if ok:
                self.memory.set_state("render_health_notified", datetime.now().isoformat())

    async def _run_oauth_health_check(self):
        """Google OAuthãƒˆãƒ¼ã‚¯ãƒ³ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¥æ¬¡ï¼‰"""
        import json
        from .notifier import send_line_notify

        token_path = os.path.expanduser("~/agents/token.json")

        # token.jsonã®å­˜åœ¨ç¢ºèª
        if not os.path.exists(token_path):
            send_line_notify(
                "\nâš ï¸ OAuthè­¦å‘Š\ntoken.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n"
                "Q&Aç›£è¦–ãƒ»ãƒ¡ãƒ¼ãƒ«ãƒ»ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãŒå‹•ä½œã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\n"
                "MacBookã‹ã‚‰å†ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦ã§ã™"
            )
            logger.error("token.json not found")
            return

        # refresh_tokenã®å­˜åœ¨ç¢ºèª
        try:
            with open(token_path) as f:
                token_data = json.load(f)
        except Exception as e:
            send_line_notify(f"\nâš ï¸ OAuthè­¦å‘Š\ntoken.jsonèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)[:150]}")
            logger.error(f"Failed to read token.json: {e}")
            return

        if not token_data.get("refresh_token"):
            send_line_notify(
                "\nâš ï¸ OAuthè­¦å‘Š\nrefresh_tokenãŒå­˜åœ¨ã—ã¾ã›ã‚“\nå†èªè¨¼ãŒå¿…è¦ã§ã™"
            )
            logger.error("No refresh_token in token.json")
            return

        # å®Ÿéš›ã«Google APIã‚’å‘¼ã³å‡ºã—ã¦èªè¨¼ãŒé€šã‚‹ã‹ç¢ºèª
        result = await self._execute_tool("oauth_health_check", tools.qa_stats)
        if not result.success:
            err_lower = (result.error or "").lower()
            auth_keywords = ["auth", "token", "credential", "403", "401", "permission", "access"]
            if any(k in err_lower for k in auth_keywords):
                send_line_notify(
                    f"\nâš ï¸ Google OAuth ã‚¨ãƒ©ãƒ¼\nGoogle APIèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ\n"
                    f"MacBookã§å†èªè¨¼ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™\n\nã‚¨ãƒ©ãƒ¼:\n{result.error[:200]}"
                )
                logger.error(f"OAuth health check: auth error: {result.error[:200]}")
            else:
                logger.info(f"OAuth health check: QA stats failed (non-auth): {result.error[:100]}")
        else:
            logger.info("OAuth health check OK")

    async def _run_weekly_stats(self):
        """æ¯é€±æœˆæ›œ9:30: å…ˆé€±ã®ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒã‚µãƒãƒªãƒ¼ã‚’LINE+Slacké€šçŸ¥"""
        import json as _json
        from .notifier import notify_ai_team as send_line_notify  # LINE+SlackåŒæ™‚é€ä¿¡
        from datetime import date

        stats = self.memory.get_task_stats(since_hours=168)  # 7æ—¥é–“
        total = sum(sum(v.values()) for v in stats.values())
        success = sum(v.get("success", 0) for v in stats.values())
        error = sum(v.get("error", 0) for v in stats.values())
        success_rate = round(100 * success / total) if total > 0 else 0
        error_tasks = [name for name, s in stats.items() if s.get("error", 0) > 0]

        # Q&Aé€šçŸ¥æ¸ˆã¿ä»¶æ•°
        qa_state_path = os.path.expanduser("~/agents/line_bot_local/qa_monitor_state.json")
        qa_count = 0
        if os.path.exists(qa_state_path):
            try:
                with open(qa_state_path) as f:
                    qa_count = len(_json.load(f).get("sent_ids", []))
            except Exception:
                pass

        # Addnessãƒ‡ãƒ¼ã‚¿é®®åº¦
        actionable_path = os.path.expanduser(
            os.path.join(self.config.get("paths", {}).get("master_dir", "~/agents/Master"),
                         "addness", "actionable-tasks.md")
        )
        data_age_note = ""
        if os.path.exists(actionable_path):
            import time
            age_days = (time.time() - os.path.getmtime(actionable_path)) / 86400
            if age_days > 3:
                data_age_note = f"\nâš ï¸ Addnessãƒ‡ãƒ¼ã‚¿: {age_days:.0f}æ—¥å‰ï¼ˆè¦æ›´æ–°ï¼‰"

        parts = [
            f"\nğŸ“Š é€±æ¬¡ã‚µãƒãƒªãƒ¼ ({date.today().strftime('%m/%d')})",
            "â”â”â”â”â”â”â”â”â”â”â”â”",
            f"ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ: {success}/{total}ä»¶æˆåŠŸ ({success_rate}%)",
            f"Q&Aé€šçŸ¥æ¸ˆã¿: {qa_count}ä»¶ç´¯è¨ˆ",
        ]
        if error_tasks:
            parts.append(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {', '.join(error_tasks[:4])}")
        if data_age_note:
            parts.append(data_age_note)
        parts.append("â”â”â”â”â”â”â”â”â”â”â”â”")

        ok = send_line_notify("\n".join(parts))
        logger.info(f"Weekly stats sent: {total} tasks, {success_rate}% success, {qa_count} Q&As")

        # ä»Šé€±ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æï¼ˆactionable-tasks.md ã‹ã‚‰ Claude ã§åˆ†æï¼‰
        await self._notify_weekly_bottleneck(send_line_notify)

        # ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ææ¡ˆï¼ˆcontact_state.json ã‹ã‚‰é•·æœŸæœªæ¥è§¦ã®äººã‚’æ¤œå‡ºï¼‰
        await self._check_follow_up_suggestions(send_line_notify)

    async def _notify_weekly_bottleneck(self, send_line_notify):
        """ä»Šé€±ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’Claudeã§åˆ†æã—ã¦LINEé€šçŸ¥"""
        import anthropic as _anthropic
        from datetime import date

        master_dir = self.config.get("paths", {}).get("master_dir", "~/agents/Master")
        actionable_path = os.path.expanduser(os.path.join(master_dir, "addness", "actionable-tasks.md"))
        if not os.path.exists(actionable_path):
            return

        try:
            with open(actionable_path, encoding="utf-8") as f:
                content = f.read()[:3000]
        except Exception:
            return

        try:
            client = _anthropic.Anthropic()
            response = client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=400,
                system="ã‚ãªãŸã¯ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹äº‹æ¥­ã®æˆ¦ç•¥ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚ç°¡æ½”ã«è¦ç‚¹ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚",
                messages=[{"role": "user", "content": f"""ä»¥ä¸‹ã®Addnessã‚¿ã‚¹ã‚¯çŠ¶æ³ã‚’åˆ†æã—ã€
ä»Šé€±ã®æœ€å¤§ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’1ã€œ2ä»¶ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

ã€ã‚¿ã‚¹ã‚¯çŠ¶æ³ã€‘
{content}

ã€å‡ºåŠ›å½¢å¼ï¼ˆ200æ–‡å­—ä»¥å†…ï¼‰ã€‘
ğŸ” ä»Šé€±ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯:
ãƒ»[æœ€é‡è¦èª²é¡Œ] ã€œ ç†ç”±ã‚’1è¡Œã§
ãƒ»[æ¬¡ç‚¹] ã€œ ç†ç”±ã‚’1è¡Œã§ï¼ˆã‚ã‚Œã°ï¼‰

å…·ä½“çš„ã§è¡Œå‹•ã«ã¤ãªãŒã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚"""}]
            )
            analysis = response.content[0].text.strip()
            ok = send_line_notify(
                f"\n{analysis}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”"
            )
            if ok:
                logger.info("Weekly bottleneck analysis sent")
        except Exception as e:
            logger.debug(f"Weekly bottleneck analysis error: {e}")

    async def _run_weekly_content_suggestions(self):
        """æ¯é€±æ°´æ›œ10:00: æœ€æ–°AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åˆ†æã—ã¦ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ›´æ–°ææ¡ˆã‚’LINEé€šçŸ¥"""
        from .notifier import send_line_notify
        from datetime import date
        import anthropic as _anthropic

        today_str = date.today().strftime("%Y/%m/%d")

        # ai_news.log ã‹ã‚‰æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ï¼ˆç›´è¿‘50è¡Œï¼‰
        news_log = os.path.expanduser("~/agents/System/ai_news.log")
        news_content = ""
        if os.path.exists(news_log):
            try:
                with open(news_log, encoding="utf-8", errors="replace") as f:
                    lines = f.readlines()
                # ç›´è¿‘50è¡Œï¼ˆæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰
                news_content = "".join(lines[-50:])[:2000]
            except Exception:
                pass

        if not news_content:
            logger.debug("weekly_content_suggestions: ai_news.log not found or empty")
            return

        try:
            client = _anthropic.Anthropic()
            response = client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=500,
                system="ã‚ãªãŸã¯ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹ï¼ˆAIå‰¯æ¥­æ•™è‚²ã‚³ãƒ¼ã‚¹ï¼‰ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚",
                messages=[{"role": "user", "content": f"""ä»¥ä¸‹ã®æœ€æ–°AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¸ã¾ãˆã¦ã€ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹ã®ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ãƒ»æ•™æã®æ›´æ–°ææ¡ˆã‚’ã—ã¦ãã ã•ã„ã€‚

ã€æœ€æ–°AIãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆç›´è¿‘ï¼‰ã€‘
{news_content}

ã€å‡ºåŠ›å½¢å¼ã€‘ï¼ˆ400æ–‡å­—ä»¥å†…ãƒ»LINEã§èª­ã¿ã‚„ã™ã„å½¢å¼ï¼‰
ğŸ“š ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ›´æ–°ææ¡ˆ ({today_str})

æ›´æ–°å„ªå…ˆåº¦ãŒé«˜ã„ã‚‚ã®ï¼ˆ2ã€œ3ä»¶ï¼‰:
1. [ã‚»ã‚¯ã‚·ãƒ§ãƒ³/æ•™æå]: [è¿½åŠ ãƒ»ä¿®æ­£å†…å®¹ã‚’1è¡Œã§]
   â†’ ç†ç”±: [ãã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ã®é–¢é€£ã‚’1è¡Œã§]

å—è¬›ç”Ÿã«ã¨ã£ã¦ä»Šã™ãä¾¡å€¤ãŒã‚ã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚"""}]
            )
            suggestions = response.content[0].text.strip()
            message = (
                f"\n{suggestions}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"ğŸ’¡ è©³ç´°ã¯Cursorã§å±•é–‹ã§ãã¾ã™"
            )
            task_id = self.memory.log_task_start("weekly_content_suggestions")
            ok = send_line_notify(message)
            self.memory.log_task_end(task_id, "success" if ok else "error",
                                     result_summary=suggestions[:100])
            logger.info("Weekly content suggestions sent")
        except Exception as e:
            logger.error(f"Weekly content suggestions failed: {e}")

    async def _check_follow_up_suggestions(self, send_line_notify):
        """é•·æœŸæœªæ¥è§¦ã®äººã‚’people-profiles.jsonã¨contact_state.jsonã§æ¤œå‡ºã—LINEé€šçŸ¥"""
        import json as _json
        from datetime import datetime as _dt, timedelta

        contact_state_path = os.path.expanduser("~/agents/line_bot_local/contact_state.json")
        profiles_path = os.path.expanduser(
            os.path.join(self.config.get("paths", {}).get("master_dir", "~/agents/Master"),
                         "people", "profiles.json")
        )
        if not os.path.exists(contact_state_path) or not os.path.exists(profiles_path):
            logger.debug("Follow-up check: missing contact_state.json or people/profiles.json")
            return

        try:
            with open(contact_state_path, encoding="utf-8") as f:
                contact_state = _json.load(f)
            with open(profiles_path, encoding="utf-8") as f:
                profiles = _json.load(f)
        except Exception as e:
            logger.debug(f"Follow-up check: load error: {e}")
            return

        now = _dt.now()
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é–¾å€¤ï¼ˆæ—¥æ•°ï¼‰
        THRESHOLDS = {
            "ä¸Šå¸": 30,
            "æ¨ªï¼ˆä¸¦åˆ—ï¼‰": 21,
            "ç›´ä¸‹ãƒ¡ãƒ³ãƒãƒ¼": 14,
            "ãƒ¡ãƒ³ãƒãƒ¼": 14,
        }
        suggestions = []
        for key, val in profiles.items():
            entry = val.get("latest", val)
            name = entry.get("name", key)
            category = entry.get("category", "")
            threshold_days = THRESHOLDS.get(category)
            if not threshold_days:
                continue  # é–¾å€¤æœªå®šç¾©ã®ã‚«ãƒ†ã‚´ãƒªã¯ã‚¹ã‚­ãƒƒãƒ—
            last_contact_str = contact_state.get(name)
            if not last_contact_str:
                continue  # æ¥è§¦è¨˜éŒ²ãªã—ï¼ˆåˆå›ã¯ææ¡ˆã—ãªã„ï¼‰
            try:
                last_contact = _dt.fromisoformat(last_contact_str)
                days_since = (now - last_contact).days
                if days_since >= threshold_days:
                    suggestions.append((days_since, name, category))
            except (ValueError, TypeError):
                pass

        if not suggestions:
            logger.debug("Follow-up check: no overdue contacts")
            return

        # æœ€ã‚‚å¤ã„é †ã§æœ€å¤§5ä»¶
        suggestions.sort(reverse=True)
        parts = [f"\nğŸ’¬ ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ææ¡ˆ\nâ”â”â”â”â”â”â”â”â”â”â”â”"]
        for days, name, category in suggestions[:5]:
            parts.append(f"  {name}({category}) â€” {days}æ—¥æœªé€£çµ¡")
        parts.append("â”â”â”â”â”â”â”â”â”â”â”â”")

        ok = send_line_notify("\n".join(parts))
        logger.info(f"Follow-up suggestions sent: {len(suggestions[:5])} people")

    async def _check_special_reminders(self, send_line_notify):
        """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸé‡è¦æœŸé™ã®ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼ï¼ˆ90/30/7æ—¥å‰ã«é€šçŸ¥ï¼‰"""
        from datetime import date
        today = date.today()

        # é‡è¦ãªç‰¹æ®ŠæœŸé™ãƒªã‚¹ãƒˆ: (æ—¥ä»˜, ãƒ©ãƒ™ãƒ«, è©³ç´°)
        SPECIAL_DEADLINES = [
            (date(2026, 8, 31), "æ±åŒ—å¤§å­¦ç ”ç©¶ã‚³ãƒ©ãƒœ", "ç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæœŸé™ã€‚é€²æ—ç¢ºèªãƒ»è«–æ–‡æº–å‚™ãŒå¿…è¦ã§ã™ã€‚"),
        ]

        for deadline, label, detail in SPECIAL_DEADLINES:
            delta = (deadline - today).days
            if delta < 0:
                continue  # è¶…éæ¸ˆã¿ã¯ã‚¹ã‚­ãƒƒãƒ—
            if delta not in (90, 30, 7, 3, 1):
                continue  # é€šçŸ¥å¯¾è±¡æ—¥ã®ã¿

            urgency = "ğŸ”´" if delta <= 7 else "ğŸŸ " if delta <= 30 else "ğŸŸ¡"
            ok = send_line_notify(
                f"\n{urgency} ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼: {label}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"æœŸé™: {deadline.strftime('%Y/%m/%d')} (æ®‹{delta}æ—¥)\n"
                f"{detail}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”"
            )
            if ok:
                logger.info(f"Special reminder sent: {label} in {delta} days")

    async def _run_kpi_daily_import(self):
        """æ¯æ—¥12:00: å…ƒãƒ‡ãƒ¼ã‚¿ã®å®Œäº†ãƒã‚§ãƒƒã‚¯ â†’ æŠ•å…¥ or ãƒªãƒã‚¤ãƒ³ãƒ‰"""
        from .notifier import send_line_notify
        from datetime import date, timedelta

        target_date = (date.today() - timedelta(days=2)).isoformat()

        # ã¾ãšå®Œäº†ãƒã‚§ãƒƒã‚¯
        check = await self._execute_tool("kpi_check_today", tools.kpi_check_today)
        if check.success and check.output.startswith("ok:"):
            # å®Œäº† â†’ æ—¥åˆ¥/æœˆåˆ¥ã«æŠ•å…¥
            result = await self._execute_tool("kpi_process", tools.kpi_process)
            if result.success and "æŠ•å…¥å®Œäº†" in result.output:
                # KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚å†ç”Ÿæˆï¼ˆAIç§˜æ›¸ãŒæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã§ãã‚‹ã‚ˆã†ã«ï¼‰
                cache_result = await self._execute_tool("kpi_cache_build", tools.kpi_cache_build)
                cache_status = ""
                if cache_result.success:
                    logger.info(f"KPI cache rebuilt after import: {cache_result.output[:200]}")
                else:
                    cache_status = "\nâš ï¸ KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥å†ç”Ÿæˆã«å¤±æ•—ï¼ˆAIç§˜æ›¸ã®ãƒ‡ãƒ¼ã‚¿ãŒå¤ã„å¯èƒ½æ€§ã‚ã‚Šï¼‰"
                    logger.warning(f"KPI cache build failed after import: {cache_result.error[:200] if cache_result.error else 'unknown'}")
                send_line_notify(
                    f"\nğŸ“Š KPIãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†\n"
                    f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    f"{result.output[:200]}{cache_status}\n"
                    f"â”â”â”â”â”â”â”â”â”â”â”â”"
                )
            elif result.success and "æŠ•å…¥å¯¾è±¡ãªã—" in result.output:
                logger.info(f"KPI process: already up to date for {target_date}")
            else:
                # æŠ•å…¥å¤±æ•—ã‚’é€šçŸ¥
                logger.warning(f"KPI process result: {result.output[:200]}")
                send_line_notify(
                    f"\nâš ï¸ KPIãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã‚¨ãƒ©ãƒ¼\n"
                    f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    f"å¯¾è±¡æ—¥: {target_date}\n"
                    f"{(result.error or result.output or 'unknown')[:200]}\n"
                    f"â”â”â”â”â”â”â”â”â”â”â”â”"
                )
        else:
            # æœªå®Œäº† â†’ ãƒªãƒã‚¤ãƒ³ãƒ‰é€ä¿¡
            status = check.output if check.success else "ãƒã‚§ãƒƒã‚¯å¤±æ•—"
            send_line_notify(
                f"\nâ° KPIãƒ‡ãƒ¼ã‚¿æœªæŠ•å…¥ãƒªãƒã‚¤ãƒ³ãƒ‰\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"å¯¾è±¡æ—¥: {target_date}\n"
                f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}\n"
                f"\nLooker Studioã‹ã‚‰CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ãŠé¡˜ã„ã—ã¾ã™\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”"
            )
            logger.warning(f"KPI data not ready for {target_date}: {status}")

    async def _run_sheets_sync(self):
        """æ¯æ—¥6:30: ç®¡ç†ã‚·ãƒ¼ãƒˆã®CSVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–° â†’ KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚å†æ§‹ç¯‰"""
        result = await self._execute_tool("sheets_sync", tools.sheets_sync)
        if result.success:
            logger.info(f"Sheets sync completed: {result.output[:200]}")
            cache_result = await self._execute_tool("kpi_cache_build", tools.kpi_cache_build)
            if cache_result.success:
                logger.info(f"KPI cache rebuilt: {cache_result.output[:200]}")
                from .notifier import send_line_notify
                send_line_notify(f"âœ… ç®¡ç†ã‚·ãƒ¼ãƒˆåŒæœŸ+KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°å®Œäº†")
            else:
                logger.warning(f"KPI cache build failed: {cache_result.error[:200] if cache_result.error else 'unknown'}")
                from .notifier import send_line_notify
                send_line_notify(
                    f"âš ï¸ KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥å†ç”Ÿæˆå¤±æ•—\n"
                    f"SheetsåŒæœŸã¯æˆåŠŸã—ã¾ã—ãŸãŒã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"
                    f"AIç§˜æ›¸ã®KPIãƒ‡ãƒ¼ã‚¿ãŒå¤ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                )

    async def _run_kpi_nightly_cache(self):
        """æ¯æ™©22:00: KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å†ç”Ÿæˆï¼ˆAIç§˜æ›¸ãŒå¤œé–“ã‚‚æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã§ãã‚‹ã‚ˆã†ã«ï¼‰"""
        result = await self._execute_tool("kpi_cache_build", tools.kpi_cache_build)
        if result.success:
            logger.info(f"Nightly KPI cache rebuilt: {result.output[:200]}")
        else:
            logger.warning(f"Nightly KPI cache build failed: {result.error[:200] if result.error else 'unknown'}")
            from .notifier import send_line_notify
            send_line_notify(
                f"âš ï¸ å¤œé–“KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥å†ç”Ÿæˆå¤±æ•—\n"
                f"{(result.error or 'unknown')[:150]}"
            )

    async def _run_log_rotate(self):
        """æ¯æ—¥3:00: ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"""
        result = await self._execute_tool("log_rotate", tools.log_rotate)
        if result.success:
            logger.info(f"Log rotate completed: {result.output[:200]}")

    _git_pull_consecutive_failures = 0

    async def _run_git_pull_sync(self):
        result = await self._execute_tool("git_pull_sync", tools.git_pull_sync)
        if result.success:
            if self._git_pull_consecutive_failures >= 6:
                # å¾©æ—§é€šçŸ¥
                from .notifier import send_line_notify
                send_line_notify(f"âœ… GitåŒæœŸå¾©æ—§ï¼ˆ{self._git_pull_consecutive_failures}å›é€£ç¶šå¤±æ•—å¾Œã«å¾©æ—§ï¼‰")
            self._git_pull_consecutive_failures = 0
        else:
            self._git_pull_consecutive_failures += 1
            # 6å›é€£ç¶šå¤±æ•—ï¼ˆ=30åˆ†ï¼‰ã§åˆå›é€šçŸ¥ã€ä»¥é™1æ™‚é–“ã”ã¨
            if self._git_pull_consecutive_failures == 6 or (self._git_pull_consecutive_failures > 6 and self._git_pull_consecutive_failures % 12 == 0):
                from .notifier import send_line_notify
                send_line_notify(
                    f"âš ï¸ GitåŒæœŸ {self._git_pull_consecutive_failures}å›é€£ç¶šå¤±æ•—\n"
                    f"Mac MiniãŒãƒªãƒã‚¸ãƒˆãƒªã¨åŒæœŸã§ãã¦ã„ã¾ã›ã‚“ã€‚\n"
                    f"ã‚¨ãƒ©ãƒ¼: {(result.error or 'unknown')[:150]}"
                )

    async def _run_daily_group_digest(self):
        """æ¯æ—¥21:00: ã‚°ãƒ«ãƒ¼ãƒ—LINEã®1æ—¥åˆ†ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’Claudeåˆ†æâ†’ç§˜æ›¸ã‚°ãƒ«ãƒ¼ãƒ—ã«å ±å‘Š"""
        import json as _json
        import anthropic as _anthropic
        from .notifier import send_line_notify
        from datetime import date

        today_str = date.today().isoformat()
        result = await self._execute_tool("fetch_group_log", tools.fetch_group_log, date=today_str)
        if not result.success or not result.output:
            logger.warning(f"daily_group_digest: failed to fetch group log: {result.error}")
            return

        try:
            data = _json.loads(result.output)
        except _json.JSONDecodeError:
            logger.error("daily_group_digest: invalid JSON from group log")
            return

        groups = data.get("groups", {})
        if not groups:
            logger.info("daily_group_digest: no group messages today")
            return

        # people-profiles.json ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼åâ†’ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç…§åˆ
        master_dir = os.path.expanduser(
            self.config.get("paths", {}).get("master_dir", "~/agents/Master")
        )
        profiles_path = os.path.join(master_dir, "people", "profiles.json")
        profiles = {}
        try:
            if os.path.exists(profiles_path):
                with open(profiles_path, encoding="utf-8") as pf:
                    raw = _json.load(pf)
                for key, val in raw.items():
                    entry = val.get("latest", val)
                    name = entry.get("name", key)
                    category = entry.get("category", "")
                    profiles[name] = category
        except Exception:
            pass

        # ã‚°ãƒ«ãƒ¼ãƒ—ãƒ­ã‚°ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ï¼ˆClaudeå…¥åŠ›ç”¨ï¼‰
        log_lines = []
        total_messages = 0
        for gid, ginfo in groups.items():
            gname = ginfo.get("group_name") or gid[-8:]
            msgs = ginfo.get("messages", [])
            total_messages += len(msgs)
            if not msgs:
                continue
            log_lines.append(f"\nã€{gname}ã€‘({len(msgs)}ä»¶)")
            for m in msgs:
                uname = m.get("user_name", "ä¸æ˜")
                cat = profiles.get(uname, "")
                cat_label = f"({cat})" if cat else ""
                time_part = m.get("timestamp", "")[-8:-3]  # HH:MM
                log_lines.append(f"  [{time_part}] {uname}{cat_label}: {m.get('text', '')[:100]}")

        if total_messages == 0:
            logger.info("daily_group_digest: 0 messages across all groups")
            return

        log_text = "\n".join(log_lines)
        # å…¥åŠ›ãŒé•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
        if len(log_text) > 4000:
            log_text = log_text[:4000] + "\n...(ä»¥ä¸‹çœç•¥)"

        try:
            client = _anthropic.Anthropic()
            response = client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=600,
                system=(
                    "ã‚ãªãŸã¯ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹äº‹æ¥­ã®AIç§˜æ›¸ã§ã™ã€‚"
                    "ç”²åŸæµ·äººï¼ˆä»£è¡¨ãƒ»ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°è²¬ä»»è€…ï¼‰å‘ã‘ã«ã€"
                    "LINEã‚°ãƒ«ãƒ¼ãƒ—ã®1æ—¥ã®ä¼šè©±ã‚’ç°¡æ½”ã«å ±å‘Šã—ã¦ãã ã•ã„ã€‚"
                ),
                messages=[{"role": "user", "content": f"""ä»¥ä¸‹ã¯ä»Šæ—¥ã®LINEã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ­ã‚°ã§ã™ã€‚
ç”²åŸã•ã‚“ãŒæŠŠæ¡ã™ã¹ãå†…å®¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

{log_text}

ã€å‡ºåŠ›å½¢å¼ã€‘ï¼ˆ500æ–‡å­—ä»¥å†…ãƒ»LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§èª­ã¿ã‚„ã™ã„å½¢å¼ï¼‰
ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«:
ãƒ»è¦ç´„ï¼ˆèª°ãŒä½•ã«ã¤ã„ã¦è©±ã—ãŸã‹ï¼‰
ãƒ»ãƒ¡ãƒ³ãƒãƒ¼ã®æ´»å‹•åº¦ã‚„ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆæ°—ã«ãªã‚‹ç‚¹ãŒã‚ã‚Œã°ï¼‰
ãƒ»ç”²åŸã•ã‚“ãŒã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã™ã¹ãäº‹é …ï¼ˆã‚ã‚Œã°ï¼‰

ç‰¹ã«å ±å‘Šã™ã¹ãå†…å®¹ãŒãªã„ã‚°ãƒ«ãƒ¼ãƒ—ã¯çœç•¥ã—ã¦OKã§ã™ã€‚"""}],
            )
            analysis = response.content[0].text.strip()
        except Exception as e:
            logger.error(f"daily_group_digest: Claude analysis failed: {e}")
            # Claudeå¤±æ•—æ™‚ã¯ç°¡æ˜“ã‚µãƒãƒªãƒ¼ã§ä»£æ›¿
            parts = [f"ğŸ“‹ ã‚°ãƒ«ãƒ¼ãƒ—ä¼šè©±ãƒ­ã‚° ({today_str})"]
            for gid, ginfo in groups.items():
                gname = ginfo.get("group_name") or gid[-8:]
                count = len(ginfo.get("messages", []))
                if count > 0:
                    parts.append(f"  {gname}: {count}ä»¶")
            analysis = "\n".join(parts)

        message = (
            f"\nğŸ“‹ ã‚°ãƒ«ãƒ¼ãƒ—LINEãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ ({date.today().strftime('%m/%d')})\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"{analysis}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"è¨ˆ{total_messages}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"
        )
        ok = send_line_notify(message)
        if ok:
            logger.info(f"daily_group_digest sent: {total_messages} messages across {len(groups)} groups")
        else:
            logger.warning("daily_group_digest: LINE notification failed")

    async def _run_weekly_profile_learning(self):
        """æ¯é€±æ—¥æ›œ10:00: éå»7æ—¥é–“ã®ã‚°ãƒ«ãƒ¼ãƒ—ãƒ­ã‚°ã‹ã‚‰ãƒ¡ãƒ³ãƒãƒ¼ã®ä¼šè©±ã‚’åˆ†æâ†’profiles.jsonã«æ›¸ãè¾¼ã¿"""
        import json as _json
        import anthropic as _anthropic
        from .notifier import send_line_notify
        from datetime import date, timedelta

        task_id = self.memory.log_task_start("weekly_profile_learning")
        today = date.today()

        # 1. éå»7æ—¥é–“ã®ãƒ­ã‚°ã‚’æ—¥åˆ¥å–å¾—
        all_messages_by_person = {}  # {person_name: [{"group": ..., "text": ..., "ts": ...}, ...]}
        groups_seen = set()
        for i in range(7):
            target_date = (today - timedelta(days=i)).isoformat()
            result = tools.fetch_group_log(date=target_date)
            if not result.success or not result.output:
                continue
            try:
                data = _json.loads(result.output)
            except _json.JSONDecodeError:
                continue
            for gid, ginfo in data.get("groups", {}).items():
                gname = ginfo.get("group_name") or gid[-8:]
                groups_seen.add(gname)
                for msg in ginfo.get("messages", []):
                    uname = msg.get("user_name", "")
                    if not uname:
                        continue
                    all_messages_by_person.setdefault(uname, []).append({
                        "group": gname,
                        "text": msg.get("text", ""),
                        "ts": msg.get("timestamp", ""),
                    })

        if not all_messages_by_person:
            self.memory.log_task_end(task_id, "success", result_summary="No group messages in past 7 days")
            logger.info("weekly_profile_learning: no messages found")
            return

        # 2. profiles.json ã‚’èª­ã¿è¾¼ã¿ï¼ˆLINEè¡¨ç¤ºåâ†’ã‚­ãƒ¼åãƒãƒƒãƒãƒ³ã‚°ç”¨ï¼‰
        master_dir = os.path.expanduser(
            self.config.get("paths", {}).get("master_dir", "~/agents/Master")
        )
        profiles_path = os.path.join(master_dir, "people", "profiles.json")
        profiles = {}
        display_name_map = {}  # line_display_name â†’ profile_key
        try:
            if os.path.exists(profiles_path):
                with open(profiles_path, encoding="utf-8") as pf:
                    profiles = _json.load(pf)
                for key, val in profiles.items():
                    entry = val.get("latest", val)
                    ldn = entry.get("line_display_name", "")
                    name = entry.get("name", key)
                    if ldn:
                        display_name_map[ldn] = key
                    display_name_map[name] = key
                    # å§“ã®ã¿ãƒ»åã®ã¿ã‚‚ãƒãƒƒãƒãƒ³ã‚°å€™è£œã«
                    for part in name.split():
                        if len(part) >= 2:
                            display_name_map.setdefault(part, key)
        except Exception as e:
            logger.warning(f"weekly_profile_learning: failed to load profiles: {e}")

        # 3. LINEè¡¨ç¤ºåâ†’profileã‚­ãƒ¼ã®ãƒãƒƒãƒãƒ³ã‚° + äººç‰©ã”ã¨ã«Claudeåˆ†æ
        updated_count = 0
        skipped_count = 0
        try:
            client = _anthropic.Anthropic()
        except Exception as e:
            self.memory.log_task_end(task_id, "error", error_message=f"Anthropic init failed: {e}")
            logger.error(f"weekly_profile_learning: Anthropic client init failed: {e}")
            return

        for display_name, messages in all_messages_by_person.items():
            # 3ä»¶æœªæº€ã¯ã‚¹ã‚­ãƒƒãƒ—
            if len(messages) < 3:
                skipped_count += 1
                continue

            # profileã‚­ãƒ¼ã‚’è§£æ±º
            profile_key = display_name_map.get(display_name)
            if not profile_key:
                # éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢
                for map_name, map_key in display_name_map.items():
                    if display_name in map_name or map_name in display_name:
                        profile_key = map_key
                        break
            if not profile_key:
                skipped_count += 1
                logger.debug(f"weekly_profile_learning: no profile match for '{display_name}'")
                continue

            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
            active_groups = list(set(m["group"] for m in messages))
            msg_text = "\n".join(
                f"[{m['ts'][-11:-3] if len(m['ts']) > 11 else ''}] ({m['group']}) {m['text'][:150]}"
                for m in messages[:100]  # æœ€å¤§100ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            )
            if len(msg_text) > 3000:
                msg_text = msg_text[:3000] + "\n...(ä»¥ä¸‹çœç•¥)"

            entry = profiles.get(profile_key, {})
            person_entry = entry.get("latest", entry)
            person_name = person_entry.get("name", profile_key)
            category = person_entry.get("category", "")

            try:
                response = client.messages.create(
                    model="claude-haiku-4-5-20251001",
                    max_tokens=400,
                    system="ã‚ãªãŸã¯çµ„ç¹”ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚LINEã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰äººç‰©ã®ç‰¹å¾´ã‚’ç°¡æ½”ã«åˆ†æã—ã¦ãã ã•ã„ã€‚",
                    messages=[{"role": "user", "content": f"""ä»¥ä¸‹ã¯{person_name}ï¼ˆ{category}ï¼‰ã®éå»7æ—¥é–“ã®LINEã‚°ãƒ«ãƒ¼ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚

{msg_text}

ä»¥ä¸‹ã®JSONå½¢å¼ã§åˆ†æçµæœã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆå„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯æ—¥æœ¬èªã§ç°¡æ½”ã«ï¼‰:
{{
  "communication_style": "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«ã‚’1æ–‡ã§ï¼ˆä¾‹: çŸ­æ–‡ä¸­å¿ƒã€‚ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã€‚çµµæ–‡å­—å¤šç”¨ã€‚ï¼‰",
  "recent_topics": ["æœ€è¿‘ã®é–¢å¿ƒãƒˆãƒ”ãƒƒã‚¯ï¼ˆ3ã€œ5å€‹ï¼‰"],
  "collaboration_patterns": "èª°ã¨ã©ã‚“ãªã‚„ã‚Šå–ã‚ŠãŒå¤šã„ã‹1æ–‡ã§",
  "personality_notes": "æ€§æ ¼ãƒ»è¡Œå‹•ç‰¹æ€§ã‚’1æ–‡ã§",
  "activity_level": "high/medium/low ã®ã„ãšã‚Œã‹"
}}

JSONä»¥å¤–ã®æ–‡å­—ã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚"""}],
                )
                raw_text = response.content[0].text.strip()
                # JSONéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆå‰å¾Œã«ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã«å¯¾å¿œï¼‰
                json_start = raw_text.find("{")
                json_end = raw_text.rfind("}") + 1
                if json_start >= 0 and json_end > json_start:
                    analysis = _json.loads(raw_text[json_start:json_end])
                else:
                    logger.warning(f"weekly_profile_learning: non-JSON response for {person_name}")
                    continue

                # group_insightsã‚’æ§‹ç¯‰
                group_insights = {
                    "updated_at": today.isoformat(),
                    "message_count_7d": len(messages),
                    "active_groups": active_groups[:5],
                    "communication_style": analysis.get("communication_style", ""),
                    "recent_topics": analysis.get("recent_topics", []),
                    "collaboration_patterns": analysis.get("collaboration_patterns", ""),
                    "personality_notes": analysis.get("personality_notes", ""),
                    "activity_level": analysis.get("activity_level", "medium"),
                }

                # profiles.jsonã«æ›¸ãè¾¼ã¿
                write_result = tools.update_people_profiles(profile_key, group_insights)
                if write_result.success:
                    updated_count += 1
                    logger.info(f"weekly_profile_learning: updated {person_name} ({len(messages)} msgs)")
                else:
                    logger.warning(f"weekly_profile_learning: write failed for {person_name}: {write_result.error}")

            except Exception as e:
                logger.warning(f"weekly_profile_learning: analysis failed for {person_name}: {e}")
                continue

        # 4. çµæœã‚’LINEé€šçŸ¥
        message = (
            f"\nğŸ§  é€±æ¬¡ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å­¦ç¿’å®Œäº†\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"æ›´æ–°: {updated_count}å\n"
            f"ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}åï¼ˆ3ä»¶æœªæº€ or ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æœªç™»éŒ²ï¼‰\n"
            f"åˆ†æå¯¾è±¡: {len(all_messages_by_person)}å / {sum(len(m) for m in all_messages_by_person.values())}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”"
        )
        send_line_notify(message)
        self.memory.log_task_end(
            task_id, "success",
            result_summary=f"Updated {updated_count} profiles, skipped {skipped_count}"
        )
        logger.info(f"weekly_profile_learning completed: {updated_count} updated, {skipped_count} skipped")

    async def _run_repair_check(self):
        if _repair_agent_ref is None:
            logger.warning("Repair agent not initialized, skipping repair check")
            return

        from .notifier import notify_repair_proposal, notify_error_detected
        from .code_tools import _current_branch, git_show_branch_diff

        task_id = self.memory.log_task_start("repair_check")
        try:
            result = _repair_agent_ref.check_and_repair()
            if result is None:
                self.memory.log_task_end(task_id, "success", result_summary="No new errors")
                return

            if result.get("fixed"):
                branch = _current_branch()
                diff = git_show_branch_diff()
                desc = result.get("description", "auto-fix")
                port = self.config.get("webhook", {}).get("port", 8500)
                notify_repair_proposal(branch, desc, diff.result, f"http://localhost:{port}")
                self.memory.log_task_end(task_id, "success",
                                         result_summary=f"Fix proposed on {branch}")
            else:
                reason = result.get("reason", "unknown")
                self.memory.log_task_end(task_id, "needs_review",
                                         result_summary=f"Could not auto-fix: {reason[:200]}")
        except Exception as e:
            self.memory.log_task_end(task_id, "error", error_message=str(e))
            logger.exception("Repair check failed")

    async def _run_slack_ai_team_check(self):
        """å®šæœŸãƒã‚§ãƒƒã‚¯: Slack #ai-team ã®æ–°ç€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿å–ã‚Šâ†’LINEã«è»¢é€"""
        from .slack_reader import fetch_channel_messages
        from .notifier import send_line_notify

        AI_TEAM_CHANNEL = "C0AGLRJ8N3G"
        state_key = "slack_ai_team_last_ts"
        last_ts = self.memory.get_state(state_key)

        messages = fetch_channel_messages(
            AI_TEAM_CHANNEL,
            oldest=last_ts,
            limit=30,
        )

        if not messages:
            logger.debug("slack_ai_team_check: no new messages")
            return

        # AI Secretaryè‡ªèº«ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é™¤å¤–
        new_msgs = [m for m in messages if m["ts"] != last_ts]
        if not new_msgs:
            return

        # æœ€æ–°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä¿å­˜
        latest_ts = new_msgs[-1]["ts"]
        self.memory.set_state(state_key, latest_ts)

        # botè‡ªèº«ã®æŠ•ç¨¿ï¼ˆAI Secretary / webhookçµŒç”±ï¼‰ã¯é™¤å¤–
        human_msgs = [m for m in new_msgs if not m.get("user_id", "").startswith("B")]
        if not human_msgs:
            logger.debug("slack_ai_team_check: only bot messages, skipping LINE forward")
            return

        # LINEã«è»¢é€
        lines = [f"\nğŸ’¬ Slack #ai-team æ–°ç€ ({len(human_msgs)}ä»¶)\nâ”â”â”â”â”â”â”â”â”â”â”â”"]
        for msg in human_msgs[:10]:
            text_preview = msg["text"][:100]
            lines.append(f"[{msg['datetime']}] {msg['user']}: {text_preview}")
        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”")

        ok = send_line_notify("\n".join(lines))
        if ok:
            logger.info(f"Slack #ai-team: forwarded {len(human_msgs)} messages to LINE")
        else:
            logger.warning("Slack #ai-team: LINE forward failed")
