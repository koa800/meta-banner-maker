"""
APScheduler-based task scheduler for the agent orchestrator.
Replaces cron jobs with in-process scheduling and logging.
"""

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger

import os
import re
from datetime import datetime
from pathlib import Path

from . import tools
from .memory import MemoryStore
from .shared_logger import get_logger

logger = get_logger("scheduler")

_repair_agent_ref = None

# ---- execution_rules.json èª­ã¿è¾¼ã¿ï¼ˆç°¡æ½”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰ ----
_execution_rules_compact_cache: str | None = None


def _build_execution_rules_compact() -> str:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ³¨å…¥ç”¨ã®ç°¡æ½”ãªè¡Œå‹•ãƒ«ãƒ¼ãƒ«æ–‡å­—åˆ—ã‚’ç”Ÿæˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰ã€‚"""
    global _execution_rules_compact_cache
    if _execution_rules_compact_cache is not None:
        return _execution_rules_compact_cache

    import json as _json

    # Mac Mini ä¸Šã®ãƒ‘ã‚¹ã‚’è¤‡æ•°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    candidates = [
        Path.home() / "agents" / "Master" / "learning" / "execution_rules.json",
        Path.home() / "agents" / "_repo" / "Master" / "learning" / "execution_rules.json",
        Path(__file__).resolve().parent.parent.parent.parent / "Master" / "learning" / "execution_rules.json",
    ]
    rules = []
    for p in candidates:
        try:
            if p.exists():
                rules = _json.loads(p.read_text(encoding="utf-8"))
                break
        except Exception:
            continue

    if not rules:
        _execution_rules_compact_cache = ""
        return ""

    lines = []
    for r in rules:
        situation = r.get("situation", "")
        action = r.get("action", r.get("rule", ""))
        if situation:
            lines.append(f"- ã€{situation}ã€‘â†’ {action}")
        else:
            lines.append(f"- {action}")
    _execution_rules_compact_cache = "\n### ç”²åŸã•ã‚“ã®è¡Œå‹•ãƒ«ãƒ¼ãƒ«\n" + "\n".join(lines) + "\n"
    return _execution_rules_compact_cache


def set_repair_agent(agent):
    """Set the RepairAgent reference for the scheduler to use."""
    global _repair_agent_ref
    _repair_agent_ref = agent


class TaskScheduler:
    def __init__(self, config: dict, memory: MemoryStore):
        self.config = config
        self.memory = memory
        self.scheduler = AsyncIOScheduler()
        self._task_map = {
            "addness_fetch": self._run_addness_fetch,
            "ai_news": self._run_ai_news,
            "mail_inbox_personal": self._run_mail_personal,
            "mail_inbox_kohara": self._run_mail_kohara,
            "addness_goal_check": self._run_addness_goal_check,
            "daily_report": self._run_daily_report,
            "health_check": self._run_health_check,
            "repair_check": self._run_repair_check,
            "weekly_idea_proposal": self._run_weekly_idea_proposal,
            "weekly_stats": self._run_weekly_stats,
            "daily_addness_digest": self._run_daily_addness_digest,
            "oauth_health_check": self._run_oauth_health_check,
            "render_health_check": self._run_render_health_check,
            "weekly_content_suggestions": self._run_weekly_content_suggestions,
            "daily_report_input": self._run_daily_report_input,
            "looker_csv_download": self._run_looker_csv_download,
            "kpi_daily_import": self._run_kpi_daily_import,
            "sheets_sync": self._run_sheets_sync,
            "git_pull_sync": self._run_git_pull_sync,
            "daily_group_digest": self._run_daily_group_digest,
            "weekly_profile_learning": self._run_weekly_profile_learning,
            "kpi_nightly_cache": self._run_kpi_nightly_cache,
            "log_rotate": self._run_log_rotate,
            "slack_dispatch": self._run_slack_dispatch,
            "slack_ai_team_check": self._run_slack_ai_team_check,
            "hinata_activity_check": self._run_hinata_activity_check,
            "slack_hinata_auto_reply": self._run_slack_hinata_auto_reply,
            "os_sync_session": self._run_os_sync_session,
        }

    def setup(self):
        schedule_cfg = self.config.get("schedule", {})

        for task_name, task_fn in self._task_map.items():
            cfg = schedule_cfg.get(task_name, {})
            if not cfg.get("enabled", False):
                logger.info(f"Task '{task_name}' is disabled, skipping")
                continue

            if "cron" in cfg:
                parts = cfg["cron"].split()
                trigger = CronTrigger(
                    minute=parts[0], hour=parts[1], day=parts[2],
                    month=parts[3], day_of_week=parts[4]
                )
                self.scheduler.add_job(task_fn, trigger, id=task_name, name=task_name, replace_existing=True)
                logger.info(f"Scheduled '{task_name}' with cron: {cfg['cron']}")
            elif "interval_seconds" in cfg:
                trigger = IntervalTrigger(seconds=cfg["interval_seconds"])
                self.scheduler.add_job(task_fn, trigger, id=task_name, name=task_name, replace_existing=True)
                logger.info(f"Scheduled '{task_name}' every {cfg['interval_seconds']} seconds")
            elif "interval_minutes" in cfg:
                trigger = IntervalTrigger(minutes=cfg["interval_minutes"])
                self.scheduler.add_job(task_fn, trigger, id=task_name, name=task_name, replace_existing=True)
                logger.info(f"Scheduled '{task_name}' every {cfg['interval_minutes']} minutes")

    def start(self):
        self.scheduler.start()
        logger.info("Scheduler started")

    def shutdown(self):
        self.scheduler.shutdown()
        logger.info("Scheduler shut down")

    # ã‚¿ã‚¹ã‚¯å¤±æ•—é€šçŸ¥ã‚’é€ã‚‰ãªã„ã‚¿ã‚¹ã‚¯ï¼ˆè‡ªå‰ã§ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã™ã‚‹ã‚‚ã®ï¼‰
    _NO_FAILURE_NOTIFY = {"health_check", "oauth_health_check", "render_health_check"}
    # git_pull_syncã¯ç‹¬è‡ªã®é »åº¦åˆ¶é™ä»˜ãé€šçŸ¥ã‚’å®Ÿè£…ï¼ˆ_run_git_pull_syncå‚ç…§ï¼‰

    async def _execute_tool(self, task_name: str, tool_fn, **kwargs) -> tools.ToolResult:
        task_id = self.memory.log_task_start(task_name, metadata=kwargs)
        try:
            result = tool_fn(**kwargs)
            status = "success" if result.success else "error"
            self.memory.log_task_end(
                task_id, status,
                result_summary=result.output[:500] if result.output else None,
                error_message=result.error[:500] if result.error else None
            )
            if result.success:
                logger.info(f"Task '{task_name}' completed successfully")
                self.memory.set_state(f"last_success_{task_name}", datetime.now().isoformat())
            else:
                logger.error(f"Task '{task_name}' failed: {result.error[:200]}")
                if task_name not in self._NO_FAILURE_NOTIFY:
                    self._maybe_notify_task_failure(task_name, result.error or "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
            return result
        except Exception as e:
            self.memory.log_task_end(task_id, "error", error_message=str(e))
            logger.exception(f"Task '{task_name}' raised an exception")
            if task_name not in self._NO_FAILURE_NOTIFY:
                self._maybe_notify_task_failure(task_name, str(e))
            raise

    def _maybe_notify_task_failure(self, task_name: str, error_msg: str):
        """ã‚¿ã‚¹ã‚¯å¤±æ•—ã‚’LINE+Slacké€šçŸ¥ï¼ˆ2æ™‚é–“ä»¥å†…ã«åŒã‚¿ã‚¹ã‚¯ã®é€šçŸ¥æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼‰"""
        from .notifier import notify_ai_team
        now = datetime.now()
        state_key = f"failure_notified_{task_name}"
        last_notified = self.memory.get_state(state_key)
        if last_notified:
            try:
                last_dt = datetime.fromisoformat(last_notified)
                if (now - last_dt).total_seconds() < 7200:
                    return  # 2æ™‚é–“ä»¥å†…ã¯é€šçŸ¥æ¸ˆã¿
            except (ValueError, TypeError):
                pass
        ok = notify_ai_team(
            f"\nâš ï¸ ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {task_name}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"{error_msg[:250]}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”"
        )
        if ok:
            self.memory.set_state(state_key, now.isoformat())

    async def _run_addness_fetch(self):
        result = await self._execute_tool("addness_fetch", tools.addness_fetch)
        if result.success:
            ctx_result = await self._execute_tool("addness_to_context", tools.addness_to_context)
            from .notifier import send_line_notify
            send_line_notify(f"âœ… Addnessã‚´ãƒ¼ãƒ«åŒæœŸå®Œäº†ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ{'æ›´æ–°æ¸ˆã¿' if ctx_result.success else 'æ›´æ–°å¤±æ•—'}ï¼‰")
        else:
            await self._execute_tool("addness_to_context", tools.addness_to_context)

    async def _run_ai_news(self):
        result = await self._execute_tool("ai_news", tools.ai_news_notify)
        if result.success and result.output:
            from .notifier import send_line_notify
            # ai_news_notifyã¯è‡ªå‰ã§LINEé€šçŸ¥ã™ã‚‹ã®ã§ã€ã“ã“ã§ã¯è¿½åŠ é€šçŸ¥ã—ãªã„
            logger.info(f"AI news completed: {result.output[:100]}")

    async def _run_mail_personal(self):
        result = await self._execute_tool("mail_inbox_personal", tools.mail_run, account="personal")
        await self._notify_mail_result(result, "personal")

    async def _run_mail_kohara(self):
        result = await self._execute_tool("mail_inbox_kohara", tools.mail_run, account="kohara")
        await self._notify_mail_result(result, "kohara")

    async def _notify_mail_result(self, result: tools.ToolResult, account: str):
        """ãƒ¡ãƒ¼ãƒ«å‡¦ç†çµæœã‚’LINE+Slacké€šçŸ¥ï¼ˆè¿”ä¿¡å¾…ã¡ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰"""
        if not result.success or not result.output:
            return
        from .notifier import notify_ai_team as send_line_notify  # LINE+SlackåŒæ™‚é€ä¿¡

        waiting_m = re.search(r"è¿”ä¿¡å¾…ã¡[ï¼š:]\s*(\d+)\s*ä»¶", result.output)
        delete_m = re.search(r"å‰Šé™¤ç¢ºèª[ï¼š:]\s*(\d+)\s*ä»¶", result.output)

        waiting = int(waiting_m.group(1)) if waiting_m else 0
        delete = int(delete_m.group(1)) if delete_m else 0

        if waiting <= 0:
            return

        account_label = "personal" if account == "personal" else "kohara"
        message = (
            f"\nğŸ“¬ ãƒ¡ãƒ¼ãƒ«ç¢ºèª ({account_label})\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"è¿”ä¿¡å¾…ã¡: {waiting}ä»¶"
            + (f" / å‰Šé™¤ç¢ºèª: {delete}ä»¶" if delete > 0 else "")
            + f"\nâ”â”â”â”â”â”â”â”â”â”â”â”"
        )
        ok = send_line_notify(message)
        if ok:
            logger.info(f"Mail notification sent for {account}: waiting={waiting}")
        else:
            # 1å›ãƒªãƒˆãƒ©ã‚¤ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸€æ™‚ã‚¨ãƒ©ãƒ¼å¯¾ç­–ï¼‰
            import asyncio; await asyncio.sleep(5)
            ok = send_line_notify(message)
            if ok:
                logger.info(f"Mail notification sent for {account} (retry): waiting={waiting}")
            else:
                logger.warning(f"Mail notification failed for {account} after retry")

    async def _run_addness_goal_check(self):
        result = await self._execute_tool("addness_to_context", tools.addness_to_context)
        if result.success:
            logger.info("Addness goal context updated for daily review")

    def _find_claude_cmd(self):
        """Claude Code CLIãƒ‘ã‚¹ã‚’æ¤œå‡ºï¼ˆApple Silicon / Intel Mac ä¸¡å¯¾å¿œï¼‰"""
        from pathlib import Path
        for p in [Path("/opt/homebrew/bin/claude"), Path("/usr/local/bin/claude")]:
            if p.exists():
                return p
        return None

    async def _run_daily_report_input(self):
        """æ—¥å ±è‡ªå‹•å…¥åŠ›: ç§˜æ›¸ãŒClaude CodeçµŒç”±ã§Looker Studioã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—â†’æ—¥å ±ã‚·ãƒ¼ãƒˆæ›¸ãè¾¼ã¿â†’LINEå ±å‘Šã€‚"""
        import subprocess
        from pathlib import Path
        from datetime import date, timedelta
        from .notifier import send_line_notify

        logger.info("æ—¥å ±è‡ªå‹•å…¥åŠ›: é–‹å§‹")

        claude_cmd = self._find_claude_cmd()
        secretary_config = Path.home() / ".claude-secretary"
        project_root = Path(self.config.get("paths", {}).get("repo_root", "~/agents")).expanduser()

        if not claude_cmd or not secretary_config.exists():
            logger.error("æ—¥å ±è‡ªå‹•å…¥åŠ›: Claude Code or secretary config not found")
            send_line_notify("âš ï¸ æ—¥å ±è‡ªå‹•å…¥åŠ›å¤±æ•—: Claude Codeç’°å¢ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return

        target_date = date.today() - timedelta(days=1)
        target_md = f"{target_date.month}/{target_date.day}"

        prompt = f"""ã‚ãªãŸã¯ç”²åŸæµ·äººã®AIç§˜æ›¸ã§ã™ã€‚æ—¥å ±ã‚’è‡ªå‹•å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚

## ã‚¿ã‚¹ã‚¯
{target_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼ˆ{target_md}ï¼‰ã®æ—¥å ±ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€æ—¥å ±ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã‚“ã§ãã ã•ã„ã€‚

## æ‰‹é †

### Step 1: Looker Studio æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
- URL: https://lookerstudio.google.com/u/2/reporting/f3d08756-9297-4d34-b6ea-ea22780eb4d2/page/p_evmsc9twzd
- ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã â†’ å¹…1400pxãƒ»é«˜ã•900pxã«ãƒªã‚µã‚¤ã‚º â†’ ã‚¹ã‚¯ã‚·ãƒ§æ’®å½±
- ãƒ†ãƒ¼ãƒ–ãƒ«ä¸Šéƒ¨ã‚’ã‚ºãƒ¼ãƒ ã‚¤ãƒ³æ’®å½±ã—ã¦å…ˆé ­è¡Œï¼ˆ{target_md}åˆ†ï¼‰ã®æ•°å­—ã‚’å†ç¢ºèª
- èª­ã¿å–ã‚‹æ•°å€¤: é›†å®¢æ•°ã€å€‹åˆ¥äºˆç´„æ•°ã€ç€é‡‘å£²ä¸Šï¼ˆç¢ºå®šãƒ™ãƒ¼ã‚¹ï¼‰

### Step 2: Looker Studio ä¼šå“¡æ•°ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
- URL: https://lookerstudio.google.com/u/2/reporting/f3d08756-9297-4d34-b6ea-ea22780eb4d2/page/p_dfv0688m0d
- ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã â†’ å¹…1400pxãƒ»é«˜ã•900pxã«ãƒªã‚µã‚¤ã‚º â†’ ã‚¹ã‚¯ã‚·ãƒ§æ’®å½±
- èª­ã¿å–ã‚‹æ•°å€¤: ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹ä¼šå“¡æ•°ï¼ˆnet changeï¼‰ã€è§£ç´„æ•°

### Step 3: ã‚µãƒ–ã‚¹ã‚¯æ–°è¦ä¼šå“¡æ•°ã‚’ Google Sheet API ã§å–å¾—
- ã‚·ãƒ¼ãƒˆID: 1gOVSt0PDub3-W8fBglKnuUAIub3FOyv-1X8CdFEvm70
- ã‚¿ãƒ–ã€Œç§˜å¯†ã®éƒ¨å±‹ï¼ˆæœˆé¡ï¼‰ã€ã¨ã€Œç§˜å¯†ã®éƒ¨å±‹ï¼ˆå¹´é¡ï¼‰ã€ã®Aåˆ—ã«ã€Œ{target_date.strftime('%Y-%m-%d')}ã€ã‚’å«ã‚€è¡Œæ•°ã‚’åˆç®—
```bash
cd {project_root}
python3 System/sheets_manager.py read "1gOVSt0PDub3-W8fBglKnuUAIub3FOyv-1X8CdFEvm70" "ç§˜å¯†ã®éƒ¨å±‹ï¼ˆæœˆé¡ï¼‰" "A1:A5000"
python3 System/sheets_manager.py read "1gOVSt0PDub3-W8fBglKnuUAIub3FOyv-1X8CdFEvm70" "ç§˜å¯†ã®éƒ¨å±‹ï¼ˆå¹´é¡ï¼‰" "A1:A5000"
```
ãã‚Œãã‚Œã®å‡ºåŠ›ã‹ã‚‰ã€Œ{target_date.strftime('%Y-%m-%d')}ã€ã‚’å«ã‚€è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—åˆç®—ã€‚

### Step 4: æ—¥å ±ã‚·ãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰å¯¾è±¡åˆ—ã‚’ç‰¹å®š
```bash
cd {project_root}
python3 System/sheets_manager.py read "16W1zALKZrnGeesjTlmsraDfw3i71tcdYJE686cmUaTk" "æ—¥å ±" "A1:JZ1"
```
ãƒ˜ãƒƒãƒ€ãƒ¼ã¯ M/D å½¢å¼ã€‚ã€Œ{target_md}ã€ã«ä¸€è‡´ã™ã‚‹åˆ—ã‚’è¦‹ã¤ã‘ã‚‹ã€‚

### Step 5: æ—¥å ±ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã¿

Step 4 ã§ç‰¹å®šã—ãŸåˆ—æ–‡å­—ã¨ã€Step 1ã€œ3 ã§å–å¾—ã—ãŸå®Ÿéš›ã®æ•°å€¤ã‚’ä½¿ã£ã¦æ›¸ãè¾¼ã‚€ã€‚
writeã‚³ãƒãƒ³ãƒ‰ã®å¼•æ•°é †: `write ã‚·ãƒ¼ãƒˆID ã‚»ãƒ« å€¤ ã‚¿ãƒ–å`

ä¾‹: åˆ—ãŒ Wã€ç€é‡‘å£²ä¸ŠãŒ 3943320 ã®å ´åˆ:
```bash
cd {project_root}
python3 System/sheets_manager.py write "16W1zALKZrnGeesjTlmsraDfw3i71tcdYJE686cmUaTk" "W5" "3943320" "æ—¥å ±"
```

æ›¸ãè¾¼ã¿å¯¾è±¡ï¼ˆåˆ—æ–‡å­—ã¨å€¤ã¯å®Ÿéš›ã®ã‚‚ã®ã«ç½®ãæ›ãˆã‚‹ã“ã¨ï¼‰:
- è¡Œ5: ç€é‡‘å£²ä¸Šï¼ˆç¢ºå®šãƒ™ãƒ¼ã‚¹ï¼‰
- è¡Œ7: é›†å®¢æ•°
- è¡Œ9: å€‹åˆ¥äºˆç´„æ•°
- è¡Œ13: ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹ä¼šå“¡æ•°
- è¡Œ14: è§£ç´„æ•°
- è¡Œ15: ã‚µãƒ–ã‚¹ã‚¯æ–°è¦ä¼šå“¡æ•°

è¡Œ4ï¼ˆç²—åˆ©ç›Šï¼‰ã¨è¡Œ6ï¼ˆåºƒå‘Šè²»ï¼‰ã¯è¨ˆç®—å¼/åˆ¥ç®¡ç†ãªã®ã§çµ¶å¯¾ã«è§¦ã‚‰ãªã„ã“ã¨ã€‚

### Step 6: LINEå ±å‘Š

å–å¾—ã—ãŸæ•°å€¤ã‚’åŸ‹ã‚è¾¼ã‚“ã§å ±å‘Šã™ã‚‹:
```bash
cd {project_root}
python3 System/line_notify.py "âœ… å®šå¸¸æ¥­å‹™å®Œäº†: æ—¥å ±å…¥åŠ›ï¼ˆè‡ªå‹•ï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”
é›†å®¢æ•°: XXXäºº
å€‹åˆ¥äºˆç´„æ•°: XXä»¶
ç€é‡‘å£²ä¸Š: Â¥X,XXX,XXX
ä¼šå“¡æ•°: XXäººï¼ˆè§£ç´„: Xäººï¼‰
ã‚µãƒ–ã‚¹ã‚¯æ–°è¦: Xäºº
â”â”â”â”â”â”â”â”â”â”â”â”
å®Œäº†æ™‚åˆ»: $(date +%H:%M)"
```
â€» XXX éƒ¨åˆ†ã¯ Step 1ã€œ3 ã§å–å¾—ã—ãŸå®Ÿéš›ã®æ•°å€¤ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã€‚

## é‡è¦ãƒ«ãƒ¼ãƒ«
- è¡Œ4ï¼ˆç²—åˆ©ç›Šï¼‰ã¨è¡Œ6ï¼ˆåºƒå‘Šè²»ï¼‰ã¯çµ¶å¯¾ã«æ›¸ãè¾¼ã¾ãªã„
- Looker Studioã®ã‚¹ã‚¯ã‚·ãƒ§ã¯å¿…ãšã‚ºãƒ¼ãƒ ã‚¤ãƒ³å†ç¢ºèªã—ã¦æ•°å€¤ã‚’æ­£ç¢ºã«èª­ã‚€
- æ›¸ãè¾¼ã¿å‰ã«å–å¾—ã—ãŸå…¨æ•°å€¤ã‚’ç¢ºèªç”¨ã«ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹
- æ•°å€¤ãŒæ˜ã‚‰ã‹ã«ç•°å¸¸ï¼ˆé›†å®¢æ•°0ã€ç€é‡‘å£²ä¸Š0ç­‰ï¼‰ã®å ´åˆã¯LINEã§ã€Œâš ï¸ ç•°å¸¸å€¤æ¤œå‡ºã€ã¨å ±å‘Šã—ã€æ›¸ãè¾¼ã¿ã¯å®Ÿè¡Œã™ã‚‹

## å‡ºåŠ›å½¢å¼
===RESULT_START===
ï¼ˆæ—¥å ±å…¥åŠ›ã®çµæœã‚µãƒãƒªãƒ¼ï¼‰
===RESULT_END==="""

        try:
            import os
            env = os.environ.copy()
            env["CLAUDE_CONFIG_DIR"] = str(secretary_config)
            result = subprocess.run(
                [str(claude_cmd), "-p", "--model", "claude-sonnet-4-6",
                 "--max-turns", "25", prompt],
                capture_output=True,
                text=True,
                timeout=600,  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œãŒã‚ã‚‹ãŸã‚é•·ã‚ï¼‰
                cwd=str(project_root),
                env=env,
            )

            if result.returncode != 0:
                logger.error(f"æ—¥å ±è‡ªå‹•å…¥åŠ›: Claude Code ã‚¨ãƒ©ãƒ¼ (code={result.returncode}): {result.stderr[:300]}")
                send_line_notify(f"âš ï¸ æ—¥å ±è‡ªå‹•å…¥åŠ›å¤±æ•—: Claude Codeã‚¨ãƒ©ãƒ¼\n{result.stderr[:200]}")
                return

            output = result.stdout.strip()
            if "===RESULT_START===" in output and "===RESULT_END===" in output:
                report = output.split("===RESULT_START===")[1].split("===RESULT_END===")[0].strip()
                logger.info(f"æ—¥å ±è‡ªå‹•å…¥åŠ›: å®Œäº† - {report[:200]}")
            else:
                logger.info(f"æ—¥å ±è‡ªå‹•å…¥åŠ›: å®Œäº†ï¼ˆãƒãƒ¼ã‚«ãƒ¼ãªã—ï¼‰- {output[-300:]}")

        except subprocess.TimeoutExpired:
            logger.error("æ—¥å ±è‡ªå‹•å…¥åŠ›: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ10åˆ†ï¼‰")
            send_line_notify("âš ï¸ æ—¥å ±è‡ªå‹•å…¥åŠ›: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ10åˆ†è¶…éï¼‰ã€‚æ‰‹å‹•ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        except Exception as e:
            logger.error(f"æ—¥å ±è‡ªå‹•å…¥åŠ›: ä¾‹å¤– - {e}")
            send_line_notify(f"âš ï¸ æ—¥å ±è‡ªå‹•å…¥åŠ›å¤±æ•—: {str(e)[:200]}")

    async def _run_daily_report(self):
        from .notifier import send_line_notify
        from datetime import date
        summary = self.memory.get_daily_summary()
        stats = self.memory.get_task_stats(since_hours=24)

        total = summary["tasks_total"]
        success = summary["tasks_success"]
        errors = summary["tasks_errors"]
        success_rate = round(100 * success / total) if total > 0 else 0

        error_tasks = [name for name, s in stats.items() if s.get("error", 0) > 0]

        report_lines = [
            f"\nğŸ“Š æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ ({date.today().strftime('%m/%d')})",
            "â”â”â”â”â”â”â”â”â”â”â”â”",
            f"ã‚¿ã‚¹ã‚¯: {success}/{total}ä»¶æˆåŠŸ ({success_rate}%)",
            f"APIã‚³ãƒ¼ãƒ«: {summary['api_calls']}å›",
        ]
        if error_tasks:
            report_lines.append(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {', '.join(error_tasks[:5])}")
        report_lines.append("â”â”â”â”â”â”â”â”â”â”â”â”")

        send_line_notify("\n".join(report_lines))

        report_text = (
            f"--- Daily Agent Report ---\n"
            f"Tasks: {total} total, {success} success, {errors} errors\n"
            f"API calls: {summary['api_calls']} (tokens: {summary['api_tokens']})\n"
            f"Task breakdown: {stats}"
        )
        logger.info(report_text)
        self.memory.set_state("last_daily_report", report_text)

    async def _run_health_check(self):
        import json as _json
        import subprocess
        from .notifier import send_line_notify
        api_calls = self.memory.get_api_calls_last_hour()
        limit = self.config.get("safety", {}).get("api_call_limit_per_hour", 100)
        if api_calls > limit * 0.9:
            logger.warning(f"API call rate critical: {api_calls}/{limit} in last hour")
            send_line_notify(
                f"\nâš ï¸ APIä½¿ç”¨é‡è­¦å‘Š\nç›´è¿‘1æ™‚é–“: {api_calls}/{limit}å›\n"
                f"APIåˆ¶é™ã«è¿‘ã¥ã„ã¦ã„ã¾ã™ã€‚Anthropicãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            )
        elif api_calls > limit * 0.8:
            logger.warning(f"API call rate high: {api_calls}/{limit} in last hour")

        # Q&Aãƒ¢ãƒ‹ã‚¿ãƒ¼ã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯æ™‚åˆ»ã‚’ç¢ºèªï¼ˆ2æ™‚é–“ä»¥ä¸Šæœªæ›´æ–°ãªã‚‰è­¦å‘Šï¼‰
        qa_state_path = os.path.expanduser("~/agents/line_bot_local/qa_monitor_state.json")
        if os.path.exists(qa_state_path):
            try:
                with open(qa_state_path) as f:
                    qa_state = _json.load(f)
                last_check = qa_state.get("last_check")
                if last_check:
                    dt = datetime.fromisoformat(last_check.replace("Z", "+00:00"))
                    age_hours = (datetime.now().astimezone() - dt).total_seconds() / 3600
                    if age_hours > 4:
                        logger.warning(f"Q&A monitor stale: last check {age_hours:.1f}h ago â€” triggering local_agent restart")
                        state_key = "qa_monitor_stale_notified"
                        last_n = self.memory.get_state(state_key)
                        if not last_n or (datetime.now() - datetime.fromisoformat(last_n)).total_seconds() > 14400:
                            # local_agentå†èµ·å‹•ã‚’è©¦ã¿ã‚‹ï¼ˆQ&Aãƒ¢ãƒ‹ã‚¿ãƒ¼ã¯local_agentã®ä¸€éƒ¨ï¼‰
                            plist = os.path.expanduser("~/Library/LaunchAgents/com.linebot.localagent.plist")
                            restarted = False
                            if os.path.exists(plist):
                                try:
                                    subprocess.run(["launchctl", "unload", plist], capture_output=True, timeout=5)
                                    import asyncio; await asyncio.sleep(2)
                                    subprocess.run(["launchctl", "load", plist], capture_output=True, timeout=5)
                                    restarted = True
                                except Exception:
                                    pass
                            msg = (f"\nğŸ”„ Q&Aãƒ¢ãƒ‹ã‚¿ãƒ¼åœæ­¢æ¤œçŸ¥â†’local_agentå†èµ·å‹•\næœ€çµ‚ãƒã‚§ãƒƒã‚¯: {age_hours:.0f}æ™‚é–“å‰"
                                   if restarted else
                                   f"\nâš ï¸ Q&Aãƒ¢ãƒ‹ã‚¿ãƒ¼åœæ­¢\næœ€çµ‚ãƒã‚§ãƒƒã‚¯: {age_hours:.0f}æ™‚é–“å‰\nå†èµ·å‹•å¤±æ•—ã€‚æ‰‹å‹•ç¢ºèªã—ã¦ãã ã•ã„")
                            send_line_notify(msg)
                            self.memory.set_state(state_key, datetime.now().isoformat())
            except Exception as e:
                logger.debug(f"Q&A state check error: {e}")

        # local_agent.py ã®ç”Ÿå­˜ç¢ºèªï¼ˆãƒ—ãƒ­ã‚»ã‚¹å­˜åœ¨ãƒã‚§ãƒƒã‚¯ â†’ ãƒ­ã‚°æ›´æ–°æ™‚åˆ»ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        try:
            import time
            agent_alive = False
            try:
                result = subprocess.run(
                    ["launchctl", "list", "com.linebot.localagent"],
                    capture_output=True, text=True, timeout=5
                )
                # launchctl list ãŒæˆåŠŸ & PID ãŒæ•°å­—ãªã‚‰ãƒ—ãƒ­ã‚»ã‚¹ç”Ÿå­˜
                if result.returncode == 0 and result.stdout.strip():
                    parts = result.stdout.strip().split()
                    agent_alive = parts[0].isdigit() if parts else False
            except Exception:
                pass

            if not agent_alive:
                logger.warning("local_agent process not found via launchctl â€” attempting auto-restart")
                plist = os.path.expanduser("~/Library/LaunchAgents/com.linebot.localagent.plist")
                restarted = False
                if os.path.exists(plist):
                    try:
                        subprocess.run(["launchctl", "unload", plist], capture_output=True, timeout=5)
                        import asyncio; await asyncio.sleep(2)
                        subprocess.run(["launchctl", "load", plist], capture_output=True, timeout=5)
                        restarted = True
                        logger.info("local_agent auto-restarted via launchctl")
                    except Exception as re_err:
                        logger.error(f"local_agent restart failed: {re_err}")

                state_key = "local_agent_stale_notified"
                last_n = self.memory.get_state(state_key)
                if not last_n or (datetime.now() - datetime.fromisoformat(last_n)).total_seconds() > 3600:
                    if restarted:
                        send_line_notify(
                            "\nğŸ”„ local_agent è‡ªå‹•å†èµ·å‹•\nãƒ—ãƒ­ã‚»ã‚¹åœæ­¢ã‚’æ¤œçŸ¥â†’è‡ªå‹•ã§å†èµ·å‹•ã—ã¾ã—ãŸ"
                        )
                    else:
                        send_line_notify(
                            "\nâš ï¸ local_agent åœæ­¢\nãƒ—ãƒ­ã‚»ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n"
                            "è‡ªå‹•å†èµ·å‹•ã«ã‚‚å¤±æ•—ã€‚æ‰‹å‹•ã§ç¢ºèªã—ã¦ãã ã•ã„"
                        )
                    self.memory.set_state(state_key, datetime.now().isoformat())
        except Exception as e:
            logger.debug(f"local_agent check error: {e}")

        # KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥é®®åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆ48æ™‚é–“è¶…ã§è­¦å‘Šï¼‰
        kpi_cache = os.path.expanduser("~/agents/System/data/kpi_summary.json")
        if os.path.exists(kpi_cache):
            try:
                import time
                cache_age_hours = (time.time() - os.path.getmtime(kpi_cache)) / 3600
                if cache_age_hours > 48:
                    state_key = "kpi_cache_stale_notified"
                    last_n = self.memory.get_state(state_key)
                    if not last_n or (datetime.now() - datetime.fromisoformat(last_n)).total_seconds() > 21600:  # 6æ™‚é–“ã«1å›
                        send_line_notify(
                            f"âš ï¸ KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥æœªæ›´æ–°\n"
                            f"æœ€çµ‚æ›´æ–°: {cache_age_hours:.0f}æ™‚é–“å‰\n"
                            f"AIç§˜æ›¸ã®KPIãƒ‡ãƒ¼ã‚¿ãŒå¤ããªã£ã¦ã„ã¾ã™"
                        )
                        self.memory.set_state(state_key, datetime.now().isoformat())
            except Exception as e:
                logger.debug(f"KPI cache check error: {e}")

        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯ï¼ˆ90%è¶…ã§è­¦å‘Šï¼‰
        try:
            import shutil
            usage = shutil.disk_usage(os.path.expanduser("~"))
            used_pct = usage.used / usage.total * 100
            if used_pct > 90:
                state_key = "disk_critical_notified"
                last_n = self.memory.get_state(state_key)
                if not last_n or (datetime.now() - datetime.fromisoformat(last_n)).total_seconds() > 21600:
                    free_gb = usage.free / (1024**3)
                    send_line_notify(
                        f"âš ï¸ Mac Mini ãƒ‡ã‚£ã‚¹ã‚¯æ®‹é‡è­¦å‘Š\n"
                        f"ä½¿ç”¨ç‡: {used_pct:.1f}% / æ®‹ã‚Š: {free_gb:.1f}GB\n"
                        f"ãƒ­ã‚°ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ•´ç†ãŒå¿…è¦ã§ã™"
                    )
                    self.memory.set_state(state_key, datetime.now().isoformat())
        except Exception as e:
            logger.debug(f"Disk check error: {e}")

        # Orchestratorã‚¯ãƒ©ãƒƒã‚·ãƒ¥ãƒ«ãƒ¼ãƒ—æ¤œçŸ¥ï¼ˆèµ·å‹•ã‹ã‚‰5åˆ†ä»¥å†…ã®å†ãƒã‚§ãƒƒã‚¯ãŒçŸ­æ™‚é–“ã«ç¹°ã‚Šè¿”ã•ã‚Œã‚‹ï¼‰
        try:
            uptime_key = "orchestrator_boot_time"
            boot_time = self.memory.get_state(uptime_key)
            now = datetime.now()
            if not boot_time:
                self.memory.set_state(uptime_key, now.isoformat())
            else:
                boot_dt = datetime.fromisoformat(boot_time)
                uptime_min = (now - boot_dt).total_seconds() / 60
                # èµ·å‹•5åˆ†ä»¥å†…ã«health_checkãŒèµ°ã‚‹ï¼å†èµ·å‹•ç›´å¾Œ
                if uptime_min < 5:
                    crash_key = "orchestrator_recent_boots"
                    recent = int(self.memory.get_state(crash_key) or "0") + 1
                    self.memory.set_state(crash_key, str(recent))
                    if recent >= 3:
                        state_key = "crash_loop_notified"
                        last_n = self.memory.get_state(state_key)
                        if not last_n or (datetime.now() - datetime.fromisoformat(last_n)).total_seconds() > 3600:
                            send_line_notify(
                                f"ğŸš¨ Orchestratorã‚¯ãƒ©ãƒƒã‚·ãƒ¥ãƒ«ãƒ¼ãƒ—æ¤œçŸ¥\n"
                                f"çŸ­æ™‚é–“ã«{recent}å›å†èµ·å‹•ã—ã¦ã„ã¾ã™\n"
                                f"ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                            )
                            self.memory.set_state(state_key, datetime.now().isoformat())
                elif uptime_min > 10:
                    # å®‰å®šç¨¼åƒä¸­ â†’ ã‚«ã‚¦ãƒ³ã‚¿ãƒªã‚»ãƒƒãƒˆ
                    self.memory.set_state("orchestrator_recent_boots", "0")
        except Exception as e:
            logger.debug(f"Crash loop check error: {e}")

        running_jobs = len(self.scheduler.get_jobs())
        self.memory.set_state("health_status", "ok")
        self.memory.set_state("running_jobs", str(running_jobs))
        logger.debug(f"Health check OK: {running_jobs} jobs scheduled, {api_calls} API calls/hour")

    async def _run_weekly_idea_proposal(self):
        """æ¯é€±æœˆæ›œ: agent_ideas.md ã‹ã‚‰æœªç€æ‰‹P0/P1ã‚’1ä»¶ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¦LINEé€šçŸ¥"""
        from .notifier import send_line_notify

        ideas_path = os.path.expanduser(
            os.path.join(self.config.get("paths", {}).get("repo_root", "~/Desktop/cursor"),
                         "System/mac_mini/agent_ideas.md")
        )
        if not os.path.exists(ideas_path):
            logger.warning("agent_ideas.md not found")
            return

        with open(ideas_path, encoding="utf-8") as f:
            content = f.read()

        # P0ãƒ»P1ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æœ€åˆã®æœªç€æ‰‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’å–å¾—
        current_priority = ""
        candidate = None
        for line in content.splitlines():
            if re.match(r"^## ğŸ”´ P0", line):
                current_priority = "P0"
            elif re.match(r"^## ğŸŸ  P1", line):
                current_priority = "P1"
            elif re.match(r"^## ğŸŸ¡ P2", line):
                break  # P0/P1ã ã‘å¯¾è±¡

            m = re.match(r"^- \[ \] (.+)", line)
            if m and current_priority in ("P0", "P1"):
                candidate = (current_priority, m.group(1).strip())
                break

        if not candidate:
            logger.info("No pending P0/P1 ideas found")
            return

        priority, task_text = candidate
        # èª¬æ˜è¡Œï¼ˆ*æ ¹æ‹ *ï¼‰ãŒã‚ã‚Œã°å–å¾—
        reason = ""
        lines = content.splitlines()
        for i, line in enumerate(lines):
            if task_text in line and i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                if next_line.startswith("- *æ ¹æ‹ *"):
                    reason = "\n" + next_line
                break

        message = (
            f"\nğŸ’¡ ä»Šé€±ã®ãŠã™ã™ã‚ã‚¿ã‚¹ã‚¯ï¼ˆ{priority}ï¼‰\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"{task_text}{reason}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"â†’ agent_ideas.md ã§ç®¡ç†ä¸­"
        )
        task_id = self.memory.log_task_start("weekly_idea_proposal")
        ok = send_line_notify(message)
        self.memory.log_task_end(task_id, "success" if ok else "error",
                                 result_summary=task_text[:100])
        logger.info(f"Weekly idea proposal sent: {task_text[:80]}")

    async def _run_daily_addness_digest(self):
        """æ¯æœ8:30: actionable-tasks.mdï¼ˆã‚¿ã‚¹ã‚¯ï¼‰+ ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼ˆä»Šæ—¥ã®äºˆå®šï¼‰ã‚’LINE+Slacké€šçŸ¥"""
        from .notifier import notify_ai_team as send_line_notify  # LINE+SlackåŒæ™‚é€ä¿¡
        from datetime import date

        master_dir = self.config.get("paths", {}).get("master_dir", "~/agents/Master")
        actionable_path = os.path.expanduser(os.path.join(master_dir, "addness", "actionable-tasks.md"))
        goal_tree_path = os.path.expanduser(os.path.join(master_dir, "addness", "goal-tree.md"))

        # actionable-tasks.md ã‚’å„ªå…ˆä½¿ç”¨ã€ãªã‘ã‚Œã°æ—§æ–¹å¼ goal-tree ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if os.path.exists(actionable_path):
            await self._digest_from_actionable(actionable_path, send_line_notify)
        elif os.path.exists(goal_tree_path):
            await self._digest_from_goal_tree(goal_tree_path, send_line_notify)
        else:
            logger.warning("Neither actionable-tasks.md nor addness-goal-tree.md found")

        # ä»Šæ—¥ã®ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚’åˆ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§é€šçŸ¥ï¼ˆç‹¬ç«‹ã—ã¦å‹•ä½œï¼‰
        await self._notify_today_calendar(send_line_notify)

        # ç‰¹æ®Šãªç· ã‚åˆ‡ã‚Šãƒ»ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼ãƒã‚§ãƒƒã‚¯ï¼ˆ90/30/7æ—¥å‰ã«é€šçŸ¥ï¼‰
        await self._check_special_reminders(send_line_notify)

    async def _notify_today_calendar(self, send_line_notify):
        """ä»Šæ—¥ã®ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼äºˆå®šã‚’LINEé€šçŸ¥ï¼ˆäºˆå®šãŒãªã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ï¼‰"""
        import json as _json
        from datetime import date
        try:
            result = tools.calendar_list(account="personal", days=1)
            if not result.success or not result.output or "äºˆå®šã¯ã‚ã‚Šã¾ã›ã‚“" in result.output:
                return

            today_str = date.today().strftime("%Y/%m/%d")
            # people-profiles.json ã‚’èª­ã¿è¾¼ã‚“ã§åå‰â†’ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®è¾æ›¸ã‚’ä½œæˆ
            master_dir = os.path.expanduser(
                self.config.get("paths", {}).get("master_dir", "~/agents/Master")
            )
            profiles_path = os.path.join(master_dir, "people", "profiles.json")
            profiles = {}
            try:
                if os.path.exists(profiles_path):
                    with open(profiles_path, encoding="utf-8") as pf:
                        raw = _json.load(pf)
                    for key, val in raw.items():
                        entry = val.get("latest", val)
                        name = entry.get("name", key)
                        email = entry.get("email", "")
                        category = entry.get("category", "")
                        summary = entry.get("capability_summary", "")[:60]
                        profiles[key] = {"name": name, "email": email, "category": category, "summary": summary}
                        if email:
                            profiles[email] = profiles[key]
            except Exception:
                pass

            # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹
            # å„è¡Œ: "  [id] 2026-02-21T10:00:00+09:00 ~ ...  ã‚¿ã‚¤ãƒˆãƒ«"
            # æ¬¡è¡Œ: "    å‚åŠ è€…: ä¸‰ä¸Š åŠŸå¤ª, ..."
            events = []
            lines = result.output.splitlines()
            i = 0
            while i < len(lines):
                line = lines[i]
                m = re.match(r"\s*\[.+?\]\s+(\S+)\s*~\s*\S+\s+(.+)", line)
                if m:
                    dt_str = m.group(1)
                    title = m.group(2).strip()
                    time_part = dt_str.split("T")[1][:5] if "T" in dt_str else "çµ‚æ—¥"
                    # æ¬¡è¡ŒãŒå‚åŠ è€…è¡Œã‹ãƒã‚§ãƒƒã‚¯
                    attendee_info = ""
                    if i + 1 < len(lines) and "å‚åŠ è€…:" in lines[i + 1]:
                        att_str = lines[i + 1].split("å‚åŠ è€…:", 1)[1].strip()
                        att_names = [a.strip() for a in att_str.split(",")]
                        matched = []
                        for att in att_names[:4]:
                            # emailã¾ãŸã¯åå‰ã§ãƒãƒƒãƒãƒ³ã‚°
                            prof = profiles.get(att)
                            if not prof:
                                # éƒ¨åˆ†ä¸€è‡´
                                for k, v in profiles.items():
                                    if att in k or att in v.get("name", ""):
                                        prof = v
                                        break
                            if prof and prof.get("category"):
                                matched.append(f"{prof['name']}({prof['category']})")
                            elif att and "@" not in att:
                                matched.append(att)
                        if matched:
                            attendee_info = f" [{', '.join(matched[:3])}]"
                        i += 1  # å‚åŠ è€…è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    events.append(f"  {time_part} {title}{attendee_info}")
                i += 1

            if not events:
                return

            message = (
                f"\nğŸ“… ä»Šæ—¥ã®äºˆå®š ({today_str})\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”\n"
                + "\n".join(events[:8])
                + "\nâ”â”â”â”â”â”â”â”â”â”â”â”"
            )
            ok = send_line_notify(message)
            if ok:
                logger.info(f"Calendar digest sent: {len(events)} events")
            else:
                logger.warning("Calendar digest notification failed")
        except Exception as e:
            logger.debug(f"Calendar digest error: {e}")

    async def _digest_from_actionable(self, path: str, send_line_notify):
        """actionable-tasks.md ã‹ã‚‰æ—¥æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        from datetime import date
        today_str = date.today().strftime("%Y/%m/%d")

        with open(path, encoding="utf-8") as f:
            content = f.read()

        # ãƒ‡ãƒ¼ã‚¿æ›´æ–°æ—¥æ™‚ã®å–å¾—
        update_m = re.search(r"æ›´æ–°æ—¥æ™‚[^\|]*\|\s*(.+)", content)
        data_date = update_m.group(1).strip().rstrip("|").strip() if update_m else "ä¸æ˜"

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ãƒ‘ãƒ¼ã‚¹ï¼ˆğŸ”´æœŸé™è¶…é / ğŸ”„å®Ÿè¡Œä¸­ï¼‰
        overdue_items = []
        in_progress_items = []
        current_section = ""

        for line in content.splitlines():
            if "ğŸ”´ æœŸé™è¶…é" in line:
                current_section = "overdue"
            elif "ğŸ”„ å®Ÿè¡Œä¸­" in line:
                current_section = "in_progress"
            elif re.match(r"^## ", line):
                current_section = "other"

            if current_section == "overdue":
                m = re.match(r"^\d+\.\s+\*\*(.+?)\*\*", line)
                if m:
                    title = m.group(1).strip()[:50]
                    # æœŸé™æƒ…å ±ã‚’å«ã‚ã‚‹
                    deadline_m = re.search(r"æœŸé™[ï¼š:]\s*(\d{4}/\d{2}/\d{2})", line)
                    if deadline_m:
                        title += f"ï¼ˆæœŸé™: {deadline_m.group(1)}ï¼‰"
                    overdue_items.append(title)

            elif current_section == "in_progress":
                m = re.match(r"^\d+\.\s+\*\*(.+?)\*\*", line)
                if m:
                    in_progress_items.append(m.group(1).strip()[:50])

        if not overdue_items and not in_progress_items:
            logger.info("No urgent Addness tasks for today")
            return

        parts = [f"\nğŸ“‹ ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ï¼ˆ{today_str}ï¼‰\nâ”â”â”â”â”â”â”â”â”â”â”â”"]
        if overdue_items:
            parts.append(f"ğŸ”´ æœŸé™è¶…é ({len(overdue_items)}ä»¶):")
            parts.extend(f"  ãƒ»{t}" for t in overdue_items[:4])
        if in_progress_items:
            parts.append(f"ğŸ”„ å®Ÿè¡Œä¸­:")
            parts.extend(f"  ãƒ»{t}" for t in in_progress_items[:3])
        parts.append(f"â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ“… ãƒ‡ãƒ¼ã‚¿: {data_date}")

        message = "\n".join(parts)
        task_id = self.memory.log_task_start("daily_addness_digest")
        ok = send_line_notify(message)
        self.memory.log_task_end(task_id, "success" if ok else "error")
        logger.info(f"Daily digest sent: {len(overdue_items)} overdue, {len(in_progress_items)} in_progress")

    async def _digest_from_goal_tree(self, path: str, send_line_notify):
        """goal-tree.md ã‹ã‚‰æ—¥æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆfallbackï¼‰"""
        from datetime import date
        today = date.today()
        today_str = today.strftime("%Y/%m/%d")

        with open(path, encoding="utf-8") as f:
            lines = f.readlines()

        overdue, due_today, due_soon = [], [], []
        for line in lines:
            if "ç”²åŸ" not in line and "kohara" not in line.lower() and "koa" not in line.lower():
                continue
            m = re.search(r"æœŸé™[ï¼š:]\s*(\d{4}/\d{2}/\d{2})", line)
            if not m:
                continue
            deadline_str = m.group(1)
            try:
                deadline = date.fromisoformat(deadline_str.replace("/", "-"))
            except ValueError:
                continue
            title_m = re.search(r"\*\*(.+?)\*\*", line)
            title = title_m.group(1) if title_m else line.strip()[:60]
            delta = (deadline - today).days
            if delta < 0:
                overdue.append(f"ğŸ”´ {title}ï¼ˆ{deadline_str}ï¼‰")
            elif delta == 0:
                due_today.append(f"ğŸŸ¡ {title}ï¼ˆæœ¬æ—¥æœŸé™ï¼‰")
            elif delta <= 7:
                due_soon.append(f"ğŸŸ  {title}ï¼ˆæ®‹{delta}æ—¥ï¼‰")

        if not overdue and not due_today and not due_soon:
            logger.info("No urgent Addness goals for today")
            return

        parts = [f"\nğŸ“‹ Addness æ—¥æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆï¼ˆ{today_str}ï¼‰\nâ”â”â”â”â”â”â”â”â”â”â”â”"]
        if overdue:
            parts.append("ã€æœŸé™è¶…éã€‘\n" + "\n".join(overdue[:5]))
        if due_today:
            parts.append("ã€æœ¬æ—¥æœŸé™ã€‘\n" + "\n".join(due_today[:3]))
        if due_soon:
            parts.append("ã€ä»Šé€±æœŸé™ã€‘\n" + "\n".join(due_soon[:5]))
        parts.append("â”â”â”â”â”â”â”â”â”â”â”â”")

        task_id = self.memory.log_task_start("daily_addness_digest")
        ok = send_line_notify("\n".join(parts))
        self.memory.log_task_end(task_id, "success" if ok else "error")
        logger.info("Daily Addness digest sent (from goal tree)")

    async def _run_render_health_check(self):
        """Renderã‚µãƒ¼ãƒãƒ¼ã®æ­»æ´»ç›£è¦–ï¼ˆ30åˆ†ã”ã¨ï¼‰"""
        import json as _json
        import urllib.request
        from .notifier import send_line_notify

        server_url = os.environ.get("LINE_BOT_SERVER_URL", "https://line-mention-bot-mmzu.onrender.com")
        try:
            req = urllib.request.Request(server_url + "/", headers={"Accept": "application/json"})
            with urllib.request.urlopen(req, timeout=45) as resp:
                body = resp.read().decode("utf-8", errors="replace")
                if resp.status == 200:
                    self.memory.set_state("render_last_ok", datetime.now().isoformat())
                    logger.debug(f"Render health OK: {body[:100]}")
                    return
                else:
                    raise Exception(f"HTTP {resp.status}")
        except Exception as e:
            err_str = str(e)[:150]
            logger.warning(f"Render health check failed: {err_str}")

            # ç›´è¿‘30åˆ†ä»¥å†…ã«é€šçŸ¥æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
            last_notified = self.memory.get_state("render_health_notified")
            if last_notified:
                try:
                    if (datetime.now() - datetime.fromisoformat(last_notified)).total_seconds() < 1800:
                        return
                except (ValueError, TypeError):
                    pass

            ok = send_line_notify(
                f"\nâš ï¸ Renderã‚µãƒ¼ãƒãƒ¼å¿œç­”ãªã—\n{server_url}\n\nã‚¨ãƒ©ãƒ¼: {err_str}\n"
                f"LINEç§˜æ›¸ãŒå¿œç­”ã§ãã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
            )
            if ok:
                self.memory.set_state("render_health_notified", datetime.now().isoformat())

    async def _run_oauth_health_check(self):
        """Google OAuthãƒˆãƒ¼ã‚¯ãƒ³ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¥æ¬¡ï¼‰"""
        import json
        from .notifier import send_line_notify

        token_path = os.path.expanduser("~/agents/token.json")

        # token.jsonã®å­˜åœ¨ç¢ºèª
        if not os.path.exists(token_path):
            send_line_notify(
                "\nâš ï¸ OAuthè­¦å‘Š\ntoken.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n"
                "Q&Aç›£è¦–ãƒ»ãƒ¡ãƒ¼ãƒ«ãƒ»ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãŒå‹•ä½œã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\n"
                "MacBookã‹ã‚‰å†ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦ã§ã™"
            )
            logger.error("token.json not found")
            return

        # refresh_tokenã®å­˜åœ¨ç¢ºèª
        try:
            with open(token_path) as f:
                token_data = json.load(f)
        except Exception as e:
            send_line_notify(f"\nâš ï¸ OAuthè­¦å‘Š\ntoken.jsonèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)[:150]}")
            logger.error(f"Failed to read token.json: {e}")
            return

        if not token_data.get("refresh_token"):
            send_line_notify(
                "\nâš ï¸ OAuthè­¦å‘Š\nrefresh_tokenãŒå­˜åœ¨ã—ã¾ã›ã‚“\nå†èªè¨¼ãŒå¿…è¦ã§ã™"
            )
            logger.error("No refresh_token in token.json")
            return

        # å®Ÿéš›ã«Google APIã‚’å‘¼ã³å‡ºã—ã¦èªè¨¼ãŒé€šã‚‹ã‹ç¢ºèª
        result = await self._execute_tool("oauth_health_check", tools.qa_stats)
        if not result.success:
            err_lower = (result.error or "").lower()
            auth_keywords = ["auth", "token", "credential", "403", "401", "permission", "access"]
            if any(k in err_lower for k in auth_keywords):
                send_line_notify(
                    f"\nâš ï¸ Google OAuth ã‚¨ãƒ©ãƒ¼\nGoogle APIèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ\n"
                    f"MacBookã§å†èªè¨¼ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™\n\nã‚¨ãƒ©ãƒ¼:\n{result.error[:200]}"
                )
                logger.error(f"OAuth health check: auth error: {result.error[:200]}")
            else:
                logger.info(f"OAuth health check: QA stats failed (non-auth): {result.error[:100]}")
        else:
            logger.info("OAuth health check OK")

    async def _run_weekly_stats(self):
        """æ¯é€±æœˆæ›œ9:30: å…ˆé€±ã®ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒã‚µãƒãƒªãƒ¼ã‚’LINE+Slacké€šçŸ¥"""
        import json as _json
        from .notifier import notify_ai_team as send_line_notify  # LINE+SlackåŒæ™‚é€ä¿¡
        from datetime import date

        stats = self.memory.get_task_stats(since_hours=168)  # 7æ—¥é–“
        total = sum(sum(v.values()) for v in stats.values())
        success = sum(v.get("success", 0) for v in stats.values())
        error = sum(v.get("error", 0) for v in stats.values())
        success_rate = round(100 * success / total) if total > 0 else 0
        error_tasks = [name for name, s in stats.items() if s.get("error", 0) > 0]

        # Q&Aé€šçŸ¥æ¸ˆã¿ä»¶æ•°
        qa_state_path = os.path.expanduser("~/agents/line_bot_local/qa_monitor_state.json")
        qa_count = 0
        if os.path.exists(qa_state_path):
            try:
                with open(qa_state_path) as f:
                    qa_count = len(_json.load(f).get("sent_ids", []))
            except Exception:
                pass

        # Addnessãƒ‡ãƒ¼ã‚¿é®®åº¦
        actionable_path = os.path.expanduser(
            os.path.join(self.config.get("paths", {}).get("master_dir", "~/agents/Master"),
                         "addness", "actionable-tasks.md")
        )
        data_age_note = ""
        if os.path.exists(actionable_path):
            import time
            age_days = (time.time() - os.path.getmtime(actionable_path)) / 86400
            if age_days > 3:
                data_age_note = f"\nâš ï¸ Addnessãƒ‡ãƒ¼ã‚¿: {age_days:.0f}æ—¥å‰ï¼ˆè¦æ›´æ–°ï¼‰"

        parts = [
            f"\nğŸ“Š é€±æ¬¡ã‚µãƒãƒªãƒ¼ ({date.today().strftime('%m/%d')})",
            "â”â”â”â”â”â”â”â”â”â”â”â”",
            f"ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ: {success}/{total}ä»¶æˆåŠŸ ({success_rate}%)",
            f"Q&Aé€šçŸ¥æ¸ˆã¿: {qa_count}ä»¶ç´¯è¨ˆ",
        ]
        if error_tasks:
            parts.append(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {', '.join(error_tasks[:4])}")
        if data_age_note:
            parts.append(data_age_note)
        parts.append("â”â”â”â”â”â”â”â”â”â”â”â”")

        ok = send_line_notify("\n".join(parts))
        logger.info(f"Weekly stats sent: {total} tasks, {success_rate}% success, {qa_count} Q&As")

        # ä»Šé€±ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æï¼ˆactionable-tasks.md ã‹ã‚‰ Claude ã§åˆ†æï¼‰
        await self._notify_weekly_bottleneck(send_line_notify)

        # ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ææ¡ˆï¼ˆcontact_state.json ã‹ã‚‰é•·æœŸæœªæ¥è§¦ã®äººã‚’æ¤œå‡ºï¼‰
        await self._check_follow_up_suggestions(send_line_notify)

    async def _notify_weekly_bottleneck(self, send_line_notify):
        """ä»Šé€±ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’Claudeã§åˆ†æã—ã¦LINEé€šçŸ¥"""
        import anthropic as _anthropic
        from datetime import date

        master_dir = self.config.get("paths", {}).get("master_dir", "~/agents/Master")
        actionable_path = os.path.expanduser(os.path.join(master_dir, "addness", "actionable-tasks.md"))
        if not os.path.exists(actionable_path):
            return

        try:
            with open(actionable_path, encoding="utf-8") as f:
                content = f.read()[:3000]
        except Exception:
            return

        try:
            client = _anthropic.Anthropic()
            response = client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=400,
                system="ã‚ãªãŸã¯ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹äº‹æ¥­ã®æˆ¦ç•¥ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚ç°¡æ½”ã«è¦ç‚¹ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚",
                messages=[{"role": "user", "content": f"""ä»¥ä¸‹ã®Addnessã‚¿ã‚¹ã‚¯çŠ¶æ³ã‚’åˆ†æã—ã€
ä»Šé€±ã®æœ€å¤§ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’1ã€œ2ä»¶ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

ã€ã‚¿ã‚¹ã‚¯çŠ¶æ³ã€‘
{content}

ã€å‡ºåŠ›å½¢å¼ï¼ˆ200æ–‡å­—ä»¥å†…ï¼‰ã€‘
ğŸ” ä»Šé€±ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯:
ãƒ»[æœ€é‡è¦èª²é¡Œ] ã€œ ç†ç”±ã‚’1è¡Œã§
ãƒ»[æ¬¡ç‚¹] ã€œ ç†ç”±ã‚’1è¡Œã§ï¼ˆã‚ã‚Œã°ï¼‰

å…·ä½“çš„ã§è¡Œå‹•ã«ã¤ãªãŒã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚"""}]
            )
            analysis = response.content[0].text.strip()
            ok = send_line_notify(
                f"\n{analysis}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”"
            )
            if ok:
                logger.info("Weekly bottleneck analysis sent")
        except Exception as e:
            logger.debug(f"Weekly bottleneck analysis error: {e}")

    async def _run_weekly_content_suggestions(self):
        """æ¯é€±æ°´æ›œ10:00: æœ€æ–°AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åˆ†æã—ã¦ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ›´æ–°ææ¡ˆã‚’LINEé€šçŸ¥"""
        from .notifier import send_line_notify
        from datetime import date
        import anthropic as _anthropic

        today_str = date.today().strftime("%Y/%m/%d")

        # ai_news.log ã‹ã‚‰æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ï¼ˆç›´è¿‘50è¡Œï¼‰
        news_log = os.path.expanduser("~/agents/System/ai_news.log")
        news_content = ""
        if os.path.exists(news_log):
            try:
                with open(news_log, encoding="utf-8", errors="replace") as f:
                    lines = f.readlines()
                # ç›´è¿‘50è¡Œï¼ˆæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰
                news_content = "".join(lines[-50:])[:2000]
            except Exception:
                pass

        if not news_content:
            logger.debug("weekly_content_suggestions: ai_news.log not found or empty")
            return

        try:
            _content_exec_rules = _build_execution_rules_compact()
            client = _anthropic.Anthropic()
            response = client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=500,
                system="ã‚ãªãŸã¯ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹ï¼ˆAIå‰¯æ¥­æ•™è‚²ã‚³ãƒ¼ã‚¹ï¼‰ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚" + _content_exec_rules,
                messages=[{"role": "user", "content": f"""ä»¥ä¸‹ã®æœ€æ–°AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¸ã¾ãˆã¦ã€ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹ã®ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ãƒ»æ•™æã®æ›´æ–°ææ¡ˆã‚’ã—ã¦ãã ã•ã„ã€‚

ã€æœ€æ–°AIãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆç›´è¿‘ï¼‰ã€‘
{news_content}

ã€å‡ºåŠ›å½¢å¼ã€‘ï¼ˆ400æ–‡å­—ä»¥å†…ãƒ»LINEã§èª­ã¿ã‚„ã™ã„å½¢å¼ï¼‰
ğŸ“š ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ›´æ–°ææ¡ˆ ({today_str})

æ›´æ–°å„ªå…ˆåº¦ãŒé«˜ã„ã‚‚ã®ï¼ˆ2ã€œ3ä»¶ï¼‰:
1. [ã‚»ã‚¯ã‚·ãƒ§ãƒ³/æ•™æå]: [è¿½åŠ ãƒ»ä¿®æ­£å†…å®¹ã‚’1è¡Œã§]
   â†’ ç†ç”±: [ãã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ã®é–¢é€£ã‚’1è¡Œã§]

å—è¬›ç”Ÿã«ã¨ã£ã¦ä»Šã™ãä¾¡å€¤ãŒã‚ã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚"""}]
            )
            suggestions = response.content[0].text.strip()
            message = (
                f"\n{suggestions}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"ğŸ’¡ è©³ç´°ã¯Cursorã§å±•é–‹ã§ãã¾ã™"
            )
            task_id = self.memory.log_task_start("weekly_content_suggestions")
            ok = send_line_notify(message)
            self.memory.log_task_end(task_id, "success" if ok else "error",
                                     result_summary=suggestions[:100])
            logger.info("Weekly content suggestions sent")
        except Exception as e:
            logger.error(f"Weekly content suggestions failed: {e}")

    async def _check_follow_up_suggestions(self, send_line_notify):
        """é•·æœŸæœªæ¥è§¦ã®äººã‚’people-profiles.jsonã¨contact_state.jsonã§æ¤œå‡ºã—LINEé€šçŸ¥"""
        import json as _json
        from datetime import datetime as _dt, timedelta

        contact_state_path = os.path.expanduser("~/agents/line_bot_local/contact_state.json")
        profiles_path = os.path.expanduser(
            os.path.join(self.config.get("paths", {}).get("master_dir", "~/agents/Master"),
                         "people", "profiles.json")
        )
        if not os.path.exists(contact_state_path) or not os.path.exists(profiles_path):
            logger.debug("Follow-up check: missing contact_state.json or people/profiles.json")
            return

        try:
            with open(contact_state_path, encoding="utf-8") as f:
                contact_state = _json.load(f)
            with open(profiles_path, encoding="utf-8") as f:
                profiles = _json.load(f)
        except Exception as e:
            logger.debug(f"Follow-up check: load error: {e}")
            return

        now = _dt.now()
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é–¾å€¤ï¼ˆæ—¥æ•°ï¼‰
        THRESHOLDS = {
            "ä¸Šå¸": 30,
            "æ¨ªï¼ˆä¸¦åˆ—ï¼‰": 21,
            "ç›´ä¸‹ãƒ¡ãƒ³ãƒãƒ¼": 14,
            "ãƒ¡ãƒ³ãƒãƒ¼": 14,
        }
        suggestions = []
        for key, val in profiles.items():
            entry = val.get("latest", val)
            name = entry.get("name", key)
            category = entry.get("category", "")
            threshold_days = THRESHOLDS.get(category)
            if not threshold_days:
                continue  # é–¾å€¤æœªå®šç¾©ã®ã‚«ãƒ†ã‚´ãƒªã¯ã‚¹ã‚­ãƒƒãƒ—
            last_contact_str = contact_state.get(name)
            if not last_contact_str:
                continue  # æ¥è§¦è¨˜éŒ²ãªã—ï¼ˆåˆå›ã¯ææ¡ˆã—ãªã„ï¼‰
            try:
                last_contact = _dt.fromisoformat(last_contact_str)
                days_since = (now - last_contact).days
                if days_since >= threshold_days:
                    suggestions.append((days_since, name, category))
            except (ValueError, TypeError):
                pass

        if not suggestions:
            logger.debug("Follow-up check: no overdue contacts")
            return

        # æœ€ã‚‚å¤ã„é †ã§æœ€å¤§5ä»¶
        suggestions.sort(reverse=True)
        parts = [f"\nğŸ’¬ ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ææ¡ˆ\nâ”â”â”â”â”â”â”â”â”â”â”â”"]
        for days, name, category in suggestions[:5]:
            parts.append(f"  {name}({category}) â€” {days}æ—¥æœªé€£çµ¡")
        parts.append("â”â”â”â”â”â”â”â”â”â”â”â”")

        ok = send_line_notify("\n".join(parts))
        logger.info(f"Follow-up suggestions sent: {len(suggestions[:5])} people")

    async def _check_special_reminders(self, send_line_notify):
        """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸé‡è¦æœŸé™ã®ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼ï¼ˆ90/30/7æ—¥å‰ã«é€šçŸ¥ï¼‰"""
        from datetime import date
        today = date.today()

        # é‡è¦ãªç‰¹æ®ŠæœŸé™ãƒªã‚¹ãƒˆ: (æ—¥ä»˜, ãƒ©ãƒ™ãƒ«, è©³ç´°)
        SPECIAL_DEADLINES = [
            (date(2026, 8, 31), "æ±åŒ—å¤§å­¦ç ”ç©¶ã‚³ãƒ©ãƒœ", "ç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæœŸé™ã€‚é€²æ—ç¢ºèªãƒ»è«–æ–‡æº–å‚™ãŒå¿…è¦ã§ã™ã€‚"),
        ]

        for deadline, label, detail in SPECIAL_DEADLINES:
            delta = (deadline - today).days
            if delta < 0:
                continue  # è¶…éæ¸ˆã¿ã¯ã‚¹ã‚­ãƒƒãƒ—
            if delta not in (90, 30, 7, 3, 1):
                continue  # é€šçŸ¥å¯¾è±¡æ—¥ã®ã¿

            urgency = "ğŸ”´" if delta <= 7 else "ğŸŸ " if delta <= 30 else "ğŸŸ¡"
            ok = send_line_notify(
                f"\n{urgency} ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼: {label}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"æœŸé™: {deadline.strftime('%Y/%m/%d')} (æ®‹{delta}æ—¥)\n"
                f"{detail}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”"
            )
            if ok:
                logger.info(f"Special reminder sent: {label} in {delta} days")

    async def _run_looker_csv_download(self):
        """æ¯æ—¥11:30: Looker Studio CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå‰ã€…æ—¥åˆ†ï¼‰ã€‚ç§˜æ›¸ãŒClaude Code + Chrome MCPã§å®Ÿè¡Œã€‚"""
        import subprocess
        from pathlib import Path
        from datetime import date, timedelta
        from .notifier import send_line_notify

        logger.info("Looker CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: é–‹å§‹")

        claude_cmd = self._find_claude_cmd()
        secretary_config = Path.home() / ".claude-secretary"
        project_root = Path(self.config.get("paths", {}).get("repo_root", "~/agents")).expanduser()

        if not claude_cmd or not secretary_config.exists():
            logger.error("Looker CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: Claude Code or secretary config not found")
            send_line_notify("âš ï¸ Looker CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: Claude Codeç’°å¢ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return

        target_date = date.today() - timedelta(days=2)
        target_str = target_date.strftime("%Y-%m-%d")
        csv_filename = f"{target_str}_ã‚¢ãƒ‰ãƒã‚¹å…¨ä½“æ•°å€¤_åª’ä½“ãƒ»ãƒ•ã‚¡ãƒãƒ«åˆ¥ãƒ‡ãƒ¼ã‚¿_è¡¨.csv"
        csv_dir = Path.home() / "Desktop" / "Looker Studio CSV"

        prompt = f"""ã‚ãªãŸã¯ç”²åŸæµ·äººã®AIç§˜æ›¸ã§ã™ã€‚Looker Studioã‹ã‚‰CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚

## ã‚¿ã‚¹ã‚¯
{target_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼ˆå‰ã€…æ—¥ï¼‰ã®Looker Studio CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚

## æ‰‹é †

### Step 1: Looker Studio ã‚’é–‹ã
- URL: https://lookerstudio.google.com/u/2/reporting/f3d08756-9297-4d34-b6ea-ea22780eb4d2/page/p_dsqvinv6zd
- ãƒšãƒ¼ã‚¸å: åª’ä½“ãƒ»ãƒ•ã‚¡ãƒãƒ«åˆ¥ãƒ‡ãƒ¼ã‚¿
- ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã„ã¦èª­ã¿è¾¼ã¿å®Œäº†ã‚’å¾…ã¤

### Step 2: æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å¤‰æ›´
- ãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã®æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ã‚¯ãƒªãƒƒã‚¯
- è©³ç´°è¨­å®šã§é–‹å§‹æ—¥ãƒ»çµ‚äº†æ—¥ã‚’ä¸¡æ–¹ã€Œ{target_str}ã€ã«è¨­å®š
- é©ç”¨ã‚’ã‚¯ãƒªãƒƒã‚¯

### Step 3: CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
- ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å³ã‚¯ãƒªãƒƒã‚¯ â†’ ã€Œã‚°ãƒ©ãƒ•ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã€ã¾ãŸã¯ã€Œãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã€ã‚’é¸æŠ
- CSVå½¢å¼ã‚’é¸æŠ
- ã€Œã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã€ã‚’ã‚¯ãƒªãƒƒã‚¯
- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ã‚’å¾…ã¤

### Step 4: ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•ãƒ»ãƒªãƒãƒ¼ãƒ 
- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ~/Downloads/ ã«ä¿å­˜ã•ã‚Œã‚‹ï¼‰ã‚’ä»¥ä¸‹ã«ç§»å‹•:
```bash
mkdir -p "{csv_dir}"
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®šã—ã¦ç§»å‹•
latest_csv=$(ls -t ~/Downloads/*.csv 2>/dev/null | head -1)
if [ -n "$latest_csv" ]; then
    mv "$latest_csv" "{csv_dir}/{csv_filename}"
    echo "ç§»å‹•å®Œäº†: {csv_dir}/{csv_filename}"
else
    echo "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
fi
```

### Step 5: ç¢ºèª
```bash
ls -la "{csv_dir}/{csv_filename}"
head -3 "{csv_dir}/{csv_filename}"
```

## å‡ºåŠ›å½¢å¼
===RESULT_START===
ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€è¡Œæ•°ç­‰ï¼‰
===RESULT_END==="""

        try:
            import os
            env = os.environ.copy()
            env["CLAUDE_CONFIG_DIR"] = str(secretary_config)
            result = subprocess.run(
                [str(claude_cmd), "-p", "--model", "claude-sonnet-4-6",
                 "--max-turns", "20", prompt],
                capture_output=True,
                text=True,
                timeout=480,  # 8åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                cwd=str(project_root),
                env=env,
            )

            if result.returncode != 0:
                logger.error(f"Looker CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: Claude Code ã‚¨ãƒ©ãƒ¼ (code={result.returncode}): {result.stderr[:300]}")
                send_line_notify(f"âš ï¸ Looker CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—\n{result.stderr[:200]}")
                return

            output = result.stdout.strip()
            if "===RESULT_START===" in output and "===RESULT_END===" in output:
                report = output.split("===RESULT_START===")[1].split("===RESULT_END===")[0].strip()
                logger.info(f"Looker CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: å®Œäº† - {report[:200]}")
            else:
                logger.info(f"Looker CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: å®Œäº†ï¼ˆãƒãƒ¼ã‚«ãƒ¼ãªã—ï¼‰- {output[-300:]}")

        except subprocess.TimeoutExpired:
            logger.error("Looker CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ8åˆ†ï¼‰")
            send_line_notify("âš ï¸ Looker CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‚æ‰‹å‹•ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        except Exception as e:
            logger.error(f"Looker CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: ä¾‹å¤– - {e}")
            send_line_notify(f"âš ï¸ Looker CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {str(e)[:200]}")

    async def _run_kpi_daily_import(self):
        """æ¯æ—¥12:00: å…ƒãƒ‡ãƒ¼ã‚¿ã®å®Œäº†ãƒã‚§ãƒƒã‚¯ â†’ æŠ•å…¥ or ãƒªãƒã‚¤ãƒ³ãƒ‰"""
        from .notifier import send_line_notify
        from datetime import date, timedelta

        target_date = (date.today() - timedelta(days=2)).isoformat()

        # ã¾ãšå®Œäº†ãƒã‚§ãƒƒã‚¯
        check = await self._execute_tool("kpi_check_today", tools.kpi_check_today)
        if check.success and check.output.startswith("ok:"):
            # å®Œäº† â†’ æ—¥åˆ¥/æœˆåˆ¥ã«æŠ•å…¥
            result = await self._execute_tool("kpi_process", tools.kpi_process)
            if result.success and "æŠ•å…¥å®Œäº†" in result.output:
                # KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚å†ç”Ÿæˆï¼ˆAIç§˜æ›¸ãŒæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã§ãã‚‹ã‚ˆã†ã«ï¼‰
                cache_result = await self._execute_tool("kpi_cache_build", tools.kpi_cache_build)
                cache_status = ""
                if cache_result.success:
                    logger.info(f"KPI cache rebuilt after import: {cache_result.output[:200]}")
                else:
                    cache_status = "\nâš ï¸ KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥å†ç”Ÿæˆã«å¤±æ•—ï¼ˆAIç§˜æ›¸ã®ãƒ‡ãƒ¼ã‚¿ãŒå¤ã„å¯èƒ½æ€§ã‚ã‚Šï¼‰"
                    logger.warning(f"KPI cache build failed after import: {cache_result.error[:200] if cache_result.error else 'unknown'}")
                send_line_notify(
                    f"\nğŸ“Š KPIãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†\n"
                    f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    f"{result.output[:200]}{cache_status}\n"
                    f"â”â”â”â”â”â”â”â”â”â”â”â”"
                )
            elif result.success and "æŠ•å…¥å¯¾è±¡ãªã—" in result.output:
                logger.info(f"KPI process: already up to date for {target_date}")
            else:
                # æŠ•å…¥å¤±æ•—ã‚’é€šçŸ¥
                logger.warning(f"KPI process result: {result.output[:200]}")
                send_line_notify(
                    f"\nâš ï¸ KPIãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã‚¨ãƒ©ãƒ¼\n"
                    f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    f"å¯¾è±¡æ—¥: {target_date}\n"
                    f"{(result.error or result.output or 'unknown')[:200]}\n"
                    f"â”â”â”â”â”â”â”â”â”â”â”â”"
                )
        else:
            # æœªå®Œäº† â†’ ãƒªãƒã‚¤ãƒ³ãƒ‰é€ä¿¡
            status = check.output if check.success else "ãƒã‚§ãƒƒã‚¯å¤±æ•—"
            send_line_notify(
                f"\nâ° KPIãƒ‡ãƒ¼ã‚¿æœªæŠ•å…¥ãƒªãƒã‚¤ãƒ³ãƒ‰\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"å¯¾è±¡æ—¥: {target_date}\n"
                f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}\n"
                f"\nLooker Studioã‹ã‚‰CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ãŠé¡˜ã„ã—ã¾ã™\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”"
            )
            logger.warning(f"KPI data not ready for {target_date}: {status}")

    async def _run_sheets_sync(self):
        """æ¯æ—¥6:30: ç®¡ç†ã‚·ãƒ¼ãƒˆã®CSVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–° â†’ KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚å†æ§‹ç¯‰"""
        result = await self._execute_tool("sheets_sync", tools.sheets_sync)
        if result.success:
            logger.info(f"Sheets sync completed: {result.output[:200]}")
            cache_result = await self._execute_tool("kpi_cache_build", tools.kpi_cache_build)
            if cache_result.success:
                logger.info(f"KPI cache rebuilt: {cache_result.output[:200]}")
                from .notifier import send_line_notify
                send_line_notify(f"âœ… ç®¡ç†ã‚·ãƒ¼ãƒˆåŒæœŸ+KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°å®Œäº†")
            else:
                logger.warning(f"KPI cache build failed: {cache_result.error[:200] if cache_result.error else 'unknown'}")
                from .notifier import send_line_notify
                send_line_notify(
                    f"âš ï¸ KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥å†ç”Ÿæˆå¤±æ•—\n"
                    f"SheetsåŒæœŸã¯æˆåŠŸã—ã¾ã—ãŸãŒã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"
                    f"AIç§˜æ›¸ã®KPIãƒ‡ãƒ¼ã‚¿ãŒå¤ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                )

    async def _run_kpi_nightly_cache(self):
        """æ¯æ™©22:00: KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å†ç”Ÿæˆï¼ˆAIç§˜æ›¸ãŒå¤œé–“ã‚‚æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã§ãã‚‹ã‚ˆã†ã«ï¼‰"""
        result = await self._execute_tool("kpi_cache_build", tools.kpi_cache_build)
        if result.success:
            logger.info(f"Nightly KPI cache rebuilt: {result.output[:200]}")
        else:
            logger.warning(f"Nightly KPI cache build failed: {result.error[:200] if result.error else 'unknown'}")
            from .notifier import send_line_notify
            send_line_notify(
                f"âš ï¸ å¤œé–“KPIã‚­ãƒ£ãƒƒã‚·ãƒ¥å†ç”Ÿæˆå¤±æ•—\n"
                f"{(result.error or 'unknown')[:150]}"
            )

    async def _run_log_rotate(self):
        """æ¯æ—¥3:00: ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"""
        result = await self._execute_tool("log_rotate", tools.log_rotate)
        if result.success:
            logger.info(f"Log rotate completed: {result.output[:200]}")

    _git_pull_consecutive_failures = 0

    async def _run_git_pull_sync(self):
        result = await self._execute_tool("git_pull_sync", tools.git_pull_sync)
        if result.success:
            if self._git_pull_consecutive_failures >= 6:
                # å¾©æ—§é€šçŸ¥
                from .notifier import send_line_notify
                send_line_notify(f"âœ… GitåŒæœŸå¾©æ—§ï¼ˆ{self._git_pull_consecutive_failures}å›é€£ç¶šå¤±æ•—å¾Œã«å¾©æ—§ï¼‰")
            self._git_pull_consecutive_failures = 0
        else:
            self._git_pull_consecutive_failures += 1
            # 6å›é€£ç¶šå¤±æ•—ï¼ˆ=30åˆ†ï¼‰ã§åˆå›é€šçŸ¥ã€ä»¥é™1æ™‚é–“ã”ã¨
            if self._git_pull_consecutive_failures == 6 or (self._git_pull_consecutive_failures > 6 and self._git_pull_consecutive_failures % 12 == 0):
                from .notifier import send_line_notify
                send_line_notify(
                    f"âš ï¸ GitåŒæœŸ {self._git_pull_consecutive_failures}å›é€£ç¶šå¤±æ•—\n"
                    f"Mac MiniãŒãƒªãƒã‚¸ãƒˆãƒªã¨åŒæœŸã§ãã¦ã„ã¾ã›ã‚“ã€‚\n"
                    f"ã‚¨ãƒ©ãƒ¼: {(result.error or 'unknown')[:150]}"
                )

    async def _run_daily_group_digest(self):
        """æ¯æ—¥21:00: ã‚°ãƒ«ãƒ¼ãƒ—LINEã®1æ—¥åˆ†ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’Claudeåˆ†æâ†’ç§˜æ›¸ã‚°ãƒ«ãƒ¼ãƒ—ã«å ±å‘Š"""
        import json as _json
        import anthropic as _anthropic
        from .notifier import send_line_notify
        from datetime import date

        today_str = date.today().isoformat()
        result = await self._execute_tool("fetch_group_log", tools.fetch_group_log, date=today_str)
        if not result.success or not result.output:
            logger.warning(f"daily_group_digest: failed to fetch group log: {result.error}")
            return

        try:
            data = _json.loads(result.output)
        except _json.JSONDecodeError:
            logger.error("daily_group_digest: invalid JSON from group log")
            return

        groups = data.get("groups", {})
        if not groups:
            logger.info("daily_group_digest: no group messages today")
            return

        # people-profiles.json ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼åâ†’ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç…§åˆ
        master_dir = os.path.expanduser(
            self.config.get("paths", {}).get("master_dir", "~/agents/Master")
        )
        profiles_path = os.path.join(master_dir, "people", "profiles.json")
        profiles = {}
        try:
            if os.path.exists(profiles_path):
                with open(profiles_path, encoding="utf-8") as pf:
                    raw = _json.load(pf)
                for key, val in raw.items():
                    entry = val.get("latest", val)
                    name = entry.get("name", key)
                    category = entry.get("category", "")
                    profiles[name] = category
        except Exception:
            pass

        # ã‚°ãƒ«ãƒ¼ãƒ—ãƒ­ã‚°ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ï¼ˆClaudeå…¥åŠ›ç”¨ï¼‰
        log_lines = []
        total_messages = 0
        for gid, ginfo in groups.items():
            gname = ginfo.get("group_name") or gid[-8:]
            msgs = ginfo.get("messages", [])
            total_messages += len(msgs)
            if not msgs:
                continue
            log_lines.append(f"\nã€{gname}ã€‘({len(msgs)}ä»¶)")
            for m in msgs:
                uname = m.get("user_name", "ä¸æ˜")
                cat = profiles.get(uname, "")
                cat_label = f"({cat})" if cat else ""
                time_part = m.get("timestamp", "")[-8:-3]  # HH:MM
                log_lines.append(f"  [{time_part}] {uname}{cat_label}: {m.get('text', '')[:100]}")

        if total_messages == 0:
            logger.info("daily_group_digest: 0 messages across all groups")
            return

        log_text = "\n".join(log_lines)
        # å…¥åŠ›ãŒé•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
        if len(log_text) > 4000:
            log_text = log_text[:4000] + "\n...(ä»¥ä¸‹çœç•¥)"

        try:
            client = _anthropic.Anthropic()
            response = client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=600,
                system=(
                    "ã‚ãªãŸã¯ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹äº‹æ¥­ã®AIç§˜æ›¸ã§ã™ã€‚"
                    "ç”²åŸæµ·äººï¼ˆä»£è¡¨ãƒ»ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°è²¬ä»»è€…ï¼‰å‘ã‘ã«ã€"
                    "LINEã‚°ãƒ«ãƒ¼ãƒ—ã®1æ—¥ã®ä¼šè©±ã‚’ç°¡æ½”ã«å ±å‘Šã—ã¦ãã ã•ã„ã€‚"
                ),
                messages=[{"role": "user", "content": f"""ä»¥ä¸‹ã¯ä»Šæ—¥ã®LINEã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ­ã‚°ã§ã™ã€‚
ç”²åŸã•ã‚“ãŒæŠŠæ¡ã™ã¹ãå†…å®¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

{log_text}

ã€å‡ºåŠ›å½¢å¼ã€‘ï¼ˆ500æ–‡å­—ä»¥å†…ãƒ»LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§èª­ã¿ã‚„ã™ã„å½¢å¼ï¼‰
ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«:
ãƒ»è¦ç´„ï¼ˆèª°ãŒä½•ã«ã¤ã„ã¦è©±ã—ãŸã‹ï¼‰
ãƒ»ãƒ¡ãƒ³ãƒãƒ¼ã®æ´»å‹•åº¦ã‚„ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆæ°—ã«ãªã‚‹ç‚¹ãŒã‚ã‚Œã°ï¼‰
ãƒ»ç”²åŸã•ã‚“ãŒã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã™ã¹ãäº‹é …ï¼ˆã‚ã‚Œã°ï¼‰

ç‰¹ã«å ±å‘Šã™ã¹ãå†…å®¹ãŒãªã„ã‚°ãƒ«ãƒ¼ãƒ—ã¯çœç•¥ã—ã¦OKã§ã™ã€‚"""}],
            )
            analysis = response.content[0].text.strip()
        except Exception as e:
            logger.error(f"daily_group_digest: Claude analysis failed: {e}")
            # Claudeå¤±æ•—æ™‚ã¯ç°¡æ˜“ã‚µãƒãƒªãƒ¼ã§ä»£æ›¿
            parts = [f"ğŸ“‹ ã‚°ãƒ«ãƒ¼ãƒ—ä¼šè©±ãƒ­ã‚° ({today_str})"]
            for gid, ginfo in groups.items():
                gname = ginfo.get("group_name") or gid[-8:]
                count = len(ginfo.get("messages", []))
                if count > 0:
                    parts.append(f"  {gname}: {count}ä»¶")
            analysis = "\n".join(parts)

        message = (
            f"\nğŸ“‹ ã‚°ãƒ«ãƒ¼ãƒ—LINEãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ ({date.today().strftime('%m/%d')})\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"{analysis}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"è¨ˆ{total_messages}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"
        )
        ok = send_line_notify(message)
        if ok:
            logger.info(f"daily_group_digest sent: {total_messages} messages across {len(groups)} groups")
        else:
            logger.warning("daily_group_digest: LINE notification failed")

    async def _run_weekly_profile_learning(self):
        """æ¯é€±æ—¥æ›œ10:00: éå»7æ—¥é–“ã®ã‚°ãƒ«ãƒ¼ãƒ—ãƒ­ã‚°ã‹ã‚‰ãƒ¡ãƒ³ãƒãƒ¼ã®ä¼šè©±ã‚’åˆ†æâ†’profiles.jsonã«æ›¸ãè¾¼ã¿"""
        import json as _json
        import anthropic as _anthropic
        from .notifier import send_line_notify
        from datetime import date, timedelta

        task_id = self.memory.log_task_start("weekly_profile_learning")
        today = date.today()

        # 1. éå»7æ—¥é–“ã®ãƒ­ã‚°ã‚’æ—¥åˆ¥å–å¾—
        all_messages_by_person = {}  # {person_name: [{"group": ..., "text": ..., "ts": ...}, ...]}
        groups_seen = set()
        for i in range(7):
            target_date = (today - timedelta(days=i)).isoformat()
            result = tools.fetch_group_log(date=target_date)
            if not result.success or not result.output:
                continue
            try:
                data = _json.loads(result.output)
            except _json.JSONDecodeError:
                continue
            for gid, ginfo in data.get("groups", {}).items():
                gname = ginfo.get("group_name") or gid[-8:]
                groups_seen.add(gname)
                for msg in ginfo.get("messages", []):
                    uname = msg.get("user_name", "")
                    if not uname:
                        continue
                    all_messages_by_person.setdefault(uname, []).append({
                        "group": gname,
                        "text": msg.get("text", ""),
                        "ts": msg.get("timestamp", ""),
                    })

        if not all_messages_by_person:
            self.memory.log_task_end(task_id, "success", result_summary="No group messages in past 7 days")
            logger.info("weekly_profile_learning: no messages found")
            return

        # 2. profiles.json ã‚’èª­ã¿è¾¼ã¿ï¼ˆLINEè¡¨ç¤ºåâ†’ã‚­ãƒ¼åãƒãƒƒãƒãƒ³ã‚°ç”¨ï¼‰
        master_dir = os.path.expanduser(
            self.config.get("paths", {}).get("master_dir", "~/agents/Master")
        )
        profiles_path = os.path.join(master_dir, "people", "profiles.json")
        profiles = {}
        display_name_map = {}  # line_display_name â†’ profile_key
        try:
            if os.path.exists(profiles_path):
                with open(profiles_path, encoding="utf-8") as pf:
                    profiles = _json.load(pf)
                for key, val in profiles.items():
                    entry = val.get("latest", val)
                    ldn = entry.get("line_display_name", "")
                    name = entry.get("name", key)
                    if ldn:
                        display_name_map[ldn] = key
                    display_name_map[name] = key
                    # å§“ã®ã¿ãƒ»åã®ã¿ã‚‚ãƒãƒƒãƒãƒ³ã‚°å€™è£œã«
                    for part in name.split():
                        if len(part) >= 2:
                            display_name_map.setdefault(part, key)
        except Exception as e:
            logger.warning(f"weekly_profile_learning: failed to load profiles: {e}")

        # 3. LINEè¡¨ç¤ºåâ†’profileã‚­ãƒ¼ã®ãƒãƒƒãƒãƒ³ã‚° + äººç‰©ã”ã¨ã«Claudeåˆ†æ
        updated_count = 0
        skipped_count = 0
        updated_details = []  # [(name, msg_count, style, topics), ...]
        try:
            client = _anthropic.Anthropic()
        except Exception as e:
            self.memory.log_task_end(task_id, "error", error_message=f"Anthropic init failed: {e}")
            logger.error(f"weekly_profile_learning: Anthropic client init failed: {e}")
            return

        for display_name, messages in all_messages_by_person.items():
            # 3ä»¶æœªæº€ã¯ã‚¹ã‚­ãƒƒãƒ—
            if len(messages) < 3:
                skipped_count += 1
                continue

            # profileã‚­ãƒ¼ã‚’è§£æ±º
            profile_key = display_name_map.get(display_name)
            if not profile_key:
                # éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢
                for map_name, map_key in display_name_map.items():
                    if display_name in map_name or map_name in display_name:
                        profile_key = map_key
                        break
            if not profile_key:
                skipped_count += 1
                logger.debug(f"weekly_profile_learning: no profile match for '{display_name}'")
                continue

            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
            active_groups = list(set(m["group"] for m in messages))
            msg_text = "\n".join(
                f"[{m['ts'][-11:-3] if len(m['ts']) > 11 else ''}] ({m['group']}) {m['text'][:150]}"
                for m in messages[:100]  # æœ€å¤§100ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            )
            if len(msg_text) > 3000:
                msg_text = msg_text[:3000] + "\n...(ä»¥ä¸‹çœç•¥)"

            entry = profiles.get(profile_key, {})
            person_entry = entry.get("latest", entry)
            person_name = person_entry.get("name", profile_key)
            category = person_entry.get("category", "")

            try:
                response = client.messages.create(
                    model="claude-haiku-4-5-20251001",
                    max_tokens=400,
                    system="ã‚ãªãŸã¯çµ„ç¹”ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚LINEã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰äººç‰©ã®ç‰¹å¾´ã‚’ç°¡æ½”ã«åˆ†æã—ã¦ãã ã•ã„ã€‚",
                    messages=[{"role": "user", "content": f"""ä»¥ä¸‹ã¯{person_name}ï¼ˆ{category}ï¼‰ã®éå»7æ—¥é–“ã®LINEã‚°ãƒ«ãƒ¼ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚

{msg_text}

ä»¥ä¸‹ã®JSONå½¢å¼ã§åˆ†æçµæœã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆå„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯æ—¥æœ¬èªã§ç°¡æ½”ã«ï¼‰:
{{
  "communication_style": "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«ã‚’1æ–‡ã§ï¼ˆä¾‹: çŸ­æ–‡ä¸­å¿ƒã€‚ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã€‚çµµæ–‡å­—å¤šç”¨ã€‚ï¼‰",
  "recent_topics": ["æœ€è¿‘ã®é–¢å¿ƒãƒˆãƒ”ãƒƒã‚¯ï¼ˆ3ã€œ5å€‹ï¼‰"],
  "collaboration_patterns": "èª°ã¨ã©ã‚“ãªã‚„ã‚Šå–ã‚ŠãŒå¤šã„ã‹1æ–‡ã§",
  "personality_notes": "æ€§æ ¼ãƒ»è¡Œå‹•ç‰¹æ€§ã‚’1æ–‡ã§",
  "activity_level": "high/medium/low ã®ã„ãšã‚Œã‹"
}}

JSONä»¥å¤–ã®æ–‡å­—ã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚"""}],
                )
                raw_text = response.content[0].text.strip()
                # JSONéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆå‰å¾Œã«ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã«å¯¾å¿œï¼‰
                json_start = raw_text.find("{")
                json_end = raw_text.rfind("}") + 1
                if json_start >= 0 and json_end > json_start:
                    analysis = _json.loads(raw_text[json_start:json_end])
                else:
                    logger.warning(f"weekly_profile_learning: non-JSON response for {person_name}")
                    continue

                # group_insightsã‚’æ§‹ç¯‰
                group_insights = {
                    "updated_at": today.isoformat(),
                    "message_count_7d": len(messages),
                    "active_groups": active_groups[:5],
                    "communication_style": analysis.get("communication_style", ""),
                    "recent_topics": analysis.get("recent_topics", []),
                    "collaboration_patterns": analysis.get("collaboration_patterns", ""),
                    "personality_notes": analysis.get("personality_notes", ""),
                    "activity_level": analysis.get("activity_level", "medium"),
                }

                # profiles.jsonã«æ›¸ãè¾¼ã¿
                write_result = tools.update_people_profiles(profile_key, group_insights)
                if write_result.success:
                    updated_count += 1
                    updated_details.append((
                        person_name,
                        len(messages),
                        analysis.get("communication_style", ""),
                        analysis.get("recent_topics", []),
                    ))
                    logger.info(f"weekly_profile_learning: updated {person_name} ({len(messages)} msgs)")
                else:
                    logger.warning(f"weekly_profile_learning: write failed for {person_name}: {write_result.error}")

            except Exception as e:
                logger.warning(f"weekly_profile_learning: analysis failed for {person_name}: {e}")
                continue

        # ===== ãƒ•ã‚§ãƒ¼ã‚º2: reply_feedbackåˆ†æ â†’ style_rules.json ç”Ÿæˆ =====
        style_rules_count = 0
        try:
            feedback_path = os.path.join(master_dir, "learning", "reply_feedback.json")
            style_rules_path = os.path.join(master_dir, "learning", "style_rules.json")
            if os.path.exists(feedback_path):
                with open(feedback_path, encoding="utf-8") as ff:
                    all_feedback = _json.load(ff)
                corrections = [f for f in all_feedback if f.get("type") == "correction"]
                if len(corrections) >= 3:
                    fb_text = "\n".join(
                        f"[{i}] é€ä¿¡è€…:{c.get('sender_name','')} å—ä¿¡:ã€Œ{c.get('original_message','')[:60]}ã€ "
                        f"AIæ¡ˆ:ã€Œ{c.get('ai_suggested','')[:60]}ã€ å®Ÿéš›:ã€Œ{c.get('actual_sent','')[:60]}ã€"
                        for i, c in enumerate(corrections[-20:], 1)
                    )
                    rules_response = client.messages.create(
                        model="claude-haiku-4-5-20251001",
                        max_tokens=600,
                        system="ã‚ãªãŸã¯ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å†ç¾å¯èƒ½ãªãƒ«ãƒ¼ãƒ«ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚",
                        messages=[{"role": "user", "content": f"""ä»¥ä¸‹ã¯AIè¿”ä¿¡æ¡ˆãŒä¿®æ­£ã•ã‚ŒãŸå±¥æ­´ã§ã™ã€‚ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã€å†åˆ©ç”¨ã§ãã‚‹ã‚¹ã‚¿ã‚¤ãƒ«ãƒ«ãƒ¼ãƒ«ã‚’JSONé…åˆ—ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

{fb_text}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ï¼ˆJSONä»¥å¤–ã®æ–‡å­—ã¯ä¸è¦ï¼‰:
[
  {{"rule": "ãƒ«ãƒ¼ãƒ«ã®èª¬æ˜", "confidence": "high/medium", "example": "å…·ä½“ä¾‹"}}
]"""}],
                    )
                    raw = rules_response.content[0].text.strip()
                    j_start = raw.find("[")
                    j_end = raw.rfind("]") + 1
                    if j_start >= 0 and j_end > j_start:
                        style_rules = _json.loads(raw[j_start:j_end])
                        style_rules_count = len(style_rules)
                        os.makedirs(os.path.dirname(style_rules_path), exist_ok=True)
                        with open(style_rules_path, "w", encoding="utf-8") as sf:
                            _json.dump(style_rules, sf, ensure_ascii=False, indent=2)
                        logger.info(f"weekly_profile_learning: style_rules generated ({style_rules_count} rules)")
                else:
                    logger.info(f"weekly_profile_learning: skipping style_rules (corrections={len(corrections)}, need>=3)")
        except Exception as e:
            logger.warning(f"weekly_profile_learning: style_rules generation failed: {e}")

        # ===== ãƒ•ã‚§ãƒ¼ã‚º3: comm_profileè‡ªå‹•æ›´æ–° =====
        comm_updated_names = []
        try:
            if os.path.exists(feedback_path):
                with open(feedback_path, encoding="utf-8") as ff:
                    all_feedback = _json.load(ff)
                # äººç‰©ã”ã¨ã«ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é›†è¨ˆ
                person_corrections = {}
                for fb in all_feedback:
                    sname = fb.get("sender_name", "")
                    if not sname:
                        continue
                    person_corrections.setdefault(sname, []).append(fb)

                for person_name_fb, person_fbs in person_corrections.items():
                    corrections_for_person = [f for f in person_fbs if f.get("type") == "correction"]
                    if len(corrections_for_person) < 3:
                        continue

                    # profileã‚­ãƒ¼ã‚’è§£æ±º
                    p_key = display_name_map.get(person_name_fb)
                    if not p_key:
                        for mn, mk in display_name_map.items():
                            if person_name_fb in mn or mn in person_name_fb:
                                p_key = mk
                                break
                    if not p_key or p_key not in profiles:
                        continue

                    # æ—¢å­˜comm_profileã‚’å–å¾—
                    p_entry = profiles[p_key]
                    p_latest = p_entry.get("latest", p_entry)
                    existing_comm = p_latest.get("comm_profile", {})

                    fb_text_person = "\n".join(
                        f"AIæ¡ˆ:ã€Œ{c.get('ai_suggested','')[:60]}ã€â†’å®Ÿéš›:ã€Œ{c.get('actual_sent','')[:60]}ã€"
                        for c in corrections_for_person[-10:]
                    )
                    # group_insightsã‚‚å‚ç…§
                    gi = p_latest.get("group_insights", {})
                    gi_style = gi.get("communication_style", "")

                    try:
                        comm_response = client.messages.create(
                            model="claude-haiku-4-5-20251001",
                            max_tokens=300,
                            system="ã‚ãªãŸã¯ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰comm_profileã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚",
                            messages=[{"role": "user", "content": f"""ã€Œ{person_name_fb}ã€ã¸ã®è¿”ä¿¡ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ä¼šè©±ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æã‹ã‚‰ã€comm_profileã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚

ä¿®æ­£å±¥æ­´:
{fb_text_person}

{f'ä¼šè©±ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æ: {gi_style}' if gi_style else ''}

ç¾åœ¨ã®comm_profile: {_json.dumps(existing_comm, ensure_ascii=False) if existing_comm else 'æœªè¨­å®š'}

ä»¥ä¸‹ã®JSONå½¢å¼ã§æ›´æ–°å†…å®¹ã®ã¿å‡ºåŠ›ï¼ˆJSONä»¥å¤–ã®æ–‡å­—ã¯ä¸è¦ï¼‰:
{{
  "tone_keywords": ["å£èª¿ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ3å€‹ä»¥å†…ï¼‰"],
  "style_note": "ã“ã®äººã¸ã®è¿”ä¿¡ã‚¹ã‚¿ã‚¤ãƒ«ã‚’1æ–‡ã§"
}}"""}],
                        )
                        raw_comm = comm_response.content[0].text.strip()
                        j_s = raw_comm.find("{")
                        j_e = raw_comm.rfind("}") + 1
                        if j_s >= 0 and j_e > j_s:
                            comm_updates = _json.loads(raw_comm[j_s:j_e])
                            # comm_profileã‚’ãƒãƒ¼ã‚¸æ›´æ–°
                            result = tools.update_people_profiles(
                                p_key, p_latest.get("group_insights", {}),
                                comm_profile_updates=comm_updates
                            )
                            if result.success:
                                comm_updated_names.append(person_name_fb)
                                logger.info(f"weekly_profile_learning: comm_profile updated for {person_name_fb}")
                    except Exception as e:
                        logger.warning(f"weekly_profile_learning: comm_profile update failed for {person_name_fb}: {e}")
        except Exception as e:
            logger.warning(f"weekly_profile_learning: comm_profile phase failed: {e}")

        # 4. çµæœã‚’LINEé€šçŸ¥
        # æ›´æ–°ã•ã‚ŒãŸäººç‰©ã®è©³ç´°ã‚’çµ„ã¿ç«‹ã¦
        detail_lines = []
        for name, msg_cnt, style, topics in updated_details:
            topics_str = "ã€".join(topics[:3]) if topics else ""
            line = f"ãƒ»{name}ï¼ˆ{msg_cnt}ä»¶ï¼‰\n  {style}"
            if topics_str:
                line += f"\n  é–¢å¿ƒ: {topics_str}"
            detail_lines.append(line)
        details_section = "\n".join(detail_lines) if detail_lines else ""

        style_line = f"\nã‚¹ã‚¿ã‚¤ãƒ«ãƒ«ãƒ¼ãƒ«: {style_rules_count}ä»¶æŠ½å‡º" if style_rules_count else ""
        comm_line = f"\ncomm_profileæ›´æ–°: {', '.join(comm_updated_names)}" if comm_updated_names else ""
        message = (
            f"\nğŸ§  é€±æ¬¡ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å­¦ç¿’å®Œäº†\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"æ›´æ–°: {updated_count}å\n"
            f"{details_section}\n"
            f"\nã‚¹ã‚­ãƒƒãƒ—: {skipped_count}å\n"
            f"åˆ†æå¯¾è±¡: {len(all_messages_by_person)}å / {sum(len(m) for m in all_messages_by_person.values())}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"
            f"{style_line}{comm_line}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”"
        )
        send_line_notify(message)
        self.memory.log_task_end(
            task_id, "success",
            result_summary=f"Updated {updated_count} profiles, skipped {skipped_count}, style_rules={style_rules_count}, comm_updated={len(comm_updated_names)}"
        )
        logger.info(f"weekly_profile_learning completed: {updated_count} updated, {skipped_count} skipped, style_rules={style_rules_count}, comm_updated={len(comm_updated_names)}")

    async def _run_repair_check(self):
        if _repair_agent_ref is None:
            logger.warning("Repair agent not initialized, skipping repair check")
            return

        from .notifier import notify_repair_proposal, notify_error_detected
        from .code_tools import _current_branch, git_show_branch_diff

        task_id = self.memory.log_task_start("repair_check")
        try:
            result = _repair_agent_ref.check_and_repair()
            if result is None:
                self.memory.log_task_end(task_id, "success", result_summary="No new errors")
                return

            if result.get("fixed"):
                branch = _current_branch()
                diff = git_show_branch_diff()
                desc = result.get("description", "auto-fix")
                port = self.config.get("webhook", {}).get("port", 8500)
                notify_repair_proposal(branch, desc, diff.result, f"http://localhost:{port}")
                self.memory.log_task_end(task_id, "success",
                                         result_summary=f"Fix proposed on {branch}")
            else:
                reason = result.get("reason", "unknown")
                self.memory.log_task_end(task_id, "needs_review",
                                         result_summary=f"Could not auto-fix: {reason[:200]}")
        except Exception as e:
            self.memory.log_task_end(task_id, "error", error_message=str(e))
            logger.exception("Repair check failed")

    # ------------------------------------------------------------------ #
    #  Slack #ai-team ç›£è¦– â†’ æ—¥å‘ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã¸ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒ
    # ------------------------------------------------------------------ #

    _slack_dispatch_running = False  # å®Ÿè¡Œä¸­ã‚¬ãƒ¼ãƒ‰

    async def _run_slack_dispatch(self):
        """Slack #ai-team ã‚’ç›£è¦–ã—ã€ç”²åŸã®æŒ‡ç¤ºã‚’æ—¥å‘ã®ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã«æ›¸ãè¾¼ã‚€ã€‚

        ç§˜æ›¸ï¼ˆOrchestratorï¼‰ãŒSlackã‚’è¦‹å¼µã‚Šã€æ—¥å‘ã¯å‘¼ã°ã‚ŒãŸã‚‰å‹•ãæ§‹é€ ã€‚
        - stop/resume â†’ æ—¥å‘ã® state.json ã‚’ç›´æ¥å¤‰æ›´ + Slackå¿œç­”
        - status â†’ æ—¥å‘ã® state.json ã‚’èª­ã‚“ã§ç§˜æ›¸ãŒSlackå¿œç­”
        - instruction â†’ hinata_tasks.json ã«ã‚¿ã‚¹ã‚¯è¿½åŠ 
        """
        if self._slack_dispatch_running:
            logger.debug("slack_dispatch: previous run still in progress, skipping")
            return
        self._slack_dispatch_running = True
        try:
            await self._run_slack_dispatch_inner()
        finally:
            self._slack_dispatch_running = False

    async def _run_slack_dispatch_inner(self):
        """slack_dispatch ã®å®Ÿå‡¦ç†"""
        import uuid
        from pathlib import Path
        from .slack_reader import fetch_channel_messages
        from .notifier import send_slack_ai_team

        AI_TEAM_CHANNEL = "C0AGLRJ8N3G"
        state_key = "slack_dispatch_last_ts"

        HINATA_DIR = Path(os.path.expanduser("~/agents/System/hinata"))
        HINATA_TASKS = HINATA_DIR / "hinata_tasks.json"
        HINATA_STATE = HINATA_DIR / "state.json"

        last_ts = self.memory.get_state(state_key)

        messages = fetch_channel_messages(AI_TEAM_CHANNEL, oldest=last_ts, limit=30)
        if not messages:
            return

        new_msgs = [m for m in messages if m["ts"] != last_ts]
        if not new_msgs:
            return

        # æœ€æ–°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä¿å­˜
        latest_ts = new_msgs[-1]["ts"]
        self.memory.set_state(state_key, latest_ts)

        # ç”²åŸã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã ã‘æŠ½å‡º
        # bot / Webhook / ç§˜æ›¸ãƒ»æ—¥å‘è‡ªèº«ã®æŠ•ç¨¿ã‚’å…¨ã¦é™¤å¤–
        _SELF_PATTERNS = (
            # ç§˜æ›¸ã®å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³
            "æ—¥å‘ã«ä¼ãˆã¾ã—ãŸ", "äº†è§£ã§ã™ï¼æ—¥å‘", "æ—¥å‘ã‚’å†é–‹", "æ—¥å‘ã‚’ä¸€æ—¦æ­¢ã‚",
            # æ—¥å‘ã®å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆWebhookçµŒç”±ã§bot_idãŒæ¬ è½ã™ã‚‹ã‚±ãƒ¼ã‚¹å¯¾ç­–ï¼‰
            "ğŸŒ… æ—¥å‘ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", "äº†è§£ã§ã™ï¼ã€Œ", "ğŸ“Š *", "âš ï¸ ã‚µã‚¤ã‚¯ãƒ«",
            "âš ï¸ *è‡ªå·±ä¿®å¾©", "ğŸ”§ *è‡ªå·±ä¿®å¾©", "âœ… *è‡ªå·±ä¿®å¾©", "âŒ *è‡ªå·±ä¿®å¾©",
            "å†é–‹ã—ã¾ã™ï¼", "ğŸ™‹ *ç”²åŸã•ã‚“ã«ç¢ºèª", "ğŸ‘‹ æ—¥å‘ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåœæ­¢",
        )
        KOHARA_USER_ID = "U07T5V9J6AM"  # ç”²åŸã®Slack user_id
        human_msgs = []
        for m in new_msgs:
            uid = m.get("user_id", "")
            text_preview = m.get("text", "")[:30]
            # botæŠ•ç¨¿ã‚’é™¤å¤–ï¼ˆuser_idãŒBã§å§‹ã¾ã‚‹ or ç©ºï¼‰
            if uid.startswith("B") or not uid:
                continue
            # ç”²åŸä»¥å¤–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ç„¡è¦–ï¼ˆä»–ãƒ¡ãƒ³ãƒãƒ¼ã®æŠ•ç¨¿ã«åå¿œã—ãªã„ï¼‰
            if uid != KOHARA_USER_ID:
                continue
            # ç§˜æ›¸ãƒ»æ—¥å‘è‡ªèº«ã®æŠ•ç¨¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å¤–ï¼ˆWebhookçµŒç”±ã§user_idãŒä»˜ãå ´åˆã®å¯¾ç­–ï¼‰
            if any(text_preview.startswith(p) for p in _SELF_PATTERNS):
                continue
            human_msgs.append(m)
        if not human_msgs:
            return

        for msg in human_msgs:
            text = msg.get("text", "").strip()
            if not text:
                continue

            command_type = self._classify_slack_command(text)

            if command_type == "stop":
                # ç§˜æ›¸ãŒç›´æ¥å¯¾å¿œ: æ—¥å‘ã® state.json ã« paused=True ã‚’æ›¸ãè¾¼ã‚€
                self._set_hinata_paused(HINATA_STATE, True)
                # æ—¥å‘ã®ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã«ã‚‚ stop ã‚’å…¥ã‚Œã‚‹ï¼ˆæ—¥å‘å´ã§ã‚‚èªè­˜ã§ãã‚‹ã‚ˆã†ã«ï¼‰
                self._add_hinata_task(HINATA_TASKS, text, msg["ts"], "stop")
                send_slack_ai_team("äº†è§£ã§ã™ï¼æ—¥å‘ã‚’ä¸€æ—¦æ­¢ã‚ã¾ã™ã€‚")
                logger.info("slack_dispatch: stop command â†’ hinata paused")

            elif command_type == "status":
                # ç§˜æ›¸ãŒç›´æ¥å¯¾å¿œ: æ—¥å‘ã® state.json ã‚’èª­ã‚“ã§å ±å‘Š
                status_text = self._read_hinata_status(HINATA_STATE)
                send_slack_ai_team(status_text)
                logger.info("slack_dispatch: status query â†’ replied")

            elif command_type == "resume":
                self._set_hinata_paused(HINATA_STATE, False)
                self._add_hinata_task(HINATA_TASKS, text, msg["ts"], "resume")
                send_slack_ai_team("æ—¥å‘ã‚’å†é–‹ã—ã¾ã™ï¼")
                logger.info("slack_dispatch: resume command â†’ hinata resumed")

            else:
                # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
                # æ—¥å‘å®›ã¦ â†’ æ—¥å‘ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã€ç§˜æ›¸å®›ã¦ â†’ ç§˜æ›¸ãŒç›´æ¥å¿œç­”ã€ãªã— â†’ ã‚¹ã‚­ãƒƒãƒ—
                HINATA_SLACK_UID = "U0AHJGVDRBJ"
                is_hinata = ("æ—¥å‘" in text or f"<@{HINATA_SLACK_UID}>" in text)
                is_secretary = ("ç§˜æ›¸" in text)

                # ç§˜æ›¸å„ªå…ˆ: ã€Œç§˜æ›¸ã€æ—¥å‘ã®çŠ¶æ³æ•™ãˆã¦ã€â†’ ç§˜æ›¸ã«èã„ã¦ã„ã‚‹
                if is_secretary:
                    await self._reply_as_secretary(text, send_slack_ai_team)
                    logger.info(f"slack_dispatch: secretary mention â†’ direct reply")
                elif is_hinata:
                    self._add_hinata_task(HINATA_TASKS, text, msg["ts"], "instruction")
                    send_slack_ai_team(f"æ—¥å‘ã«ä¼ãˆã¾ã—ãŸï¼ã€Œ{text[:50]}ã€")
                    logger.info(f"slack_dispatch: instruction â†’ hinata task added")
                else:
                    # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãªã— â†’ ç„¡è¦–ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å®›å…ˆã‚’æ˜ç¤ºã™ã‚‹é‹ç”¨ï¼‰
                    logger.debug(f"slack_dispatch: no mention target, skipping: {text[:30]}")

    async def _reply_as_secretary(self, user_text: str, send_fn):
        """ç§˜æ›¸ãŒSlackä¸Šã§ç”²åŸã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ç›´æ¥å¿œç­”ã™ã‚‹ã€‚"""
        import anthropic

        # IDENTITY.md ã‚’èª­ã¿è¾¼ã‚“ã§ç”²åŸã•ã‚“ã‚‰ã—ã•ã‚’æ³¨å…¥
        identity_context = ""
        identity_path = Path.home() / "agents" / "Master" / "self_clone" / "kohara" / "IDENTITY.md"
        try:
            if identity_path.exists():
                identity_context = identity_path.read_text(encoding="utf-8")[:2000]
        except Exception:
            pass

        exec_rules = _build_execution_rules_compact()
        system_prompt = (
            "ã‚ãªãŸã¯ç”²åŸæµ·äººã®AIç§˜æ›¸ã§ã™ã€‚Slackã®#ai-teamãƒãƒ£ãƒ³ãƒãƒ«ã§ç”²åŸã•ã‚“ã«è©±ã—ã‹ã‘ã‚‰ã‚Œã¾ã—ãŸã€‚\n"
            "ç§˜æ›¸ã¨ã—ã¦ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
        )
        if identity_context:
            system_prompt += f"## ç”²åŸæµ·äººã®è¨€èªã‚¹ã‚¿ã‚¤ãƒ«å®šç¾©ï¼ˆå¿…ãšå¾“ã†ã“ã¨ï¼‰\n{identity_context}\n\n"
        system_prompt += (
            "## Slackå¿œç­”ãƒ«ãƒ¼ãƒ«\n"
            "- ç§˜æ›¸ã¨ã—ã¦ã®å¿œç­”ã€‚ç”²åŸã•ã‚“æœ¬äººã«ãªã‚Šãã‚‹ã®ã§ã¯ãªãã€ç§˜æ›¸ãŒç”²åŸã•ã‚“ã«è¿”ã™å½¢\n"
            "- ç°¡æ½”ã«ã€‚é•·ãã¦ã‚‚3-4è¡Œ\n"
            "- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®å¤ªå­—ï¼ˆ**ï¼‰ã¯ä½¿ã‚ãªã„\n"
            "- ã€Œã‹ã—ã“ã¾ã‚Šã¾ã—ãŸã€ã€Œæ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€ã¯ä½¿ã‚ãªã„ã€‚ã€Œäº†è§£ã§ã™ï¼ã€ã€Œåˆ†ã‹ã‚Šã¾ã—ãŸï¼ã€ã‚’ä½¿ã†\n"
        )
        system_prompt += exec_rules

        try:
            client = anthropic.Anthropic()
            response = client.messages.create(
                model="claude-sonnet-4-6",
                max_tokens=600,
                system=system_prompt,
                messages=[{"role": "user", "content": user_text}],
            )
            reply = response.content[0].text.strip()
            send_fn(reply)
        except Exception as e:
            logger.exception(f"_reply_as_secretary error: {e}")
            send_fn("ã™ã¿ã¾ã›ã‚“ã€ã€ï¼ã¡ã‚‡ã£ã¨ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã—ã¾ã„ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ")

    @staticmethod
    def _classify_slack_command(text: str) -> str:
        """ç”²åŸã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã‚³ãƒãƒ³ãƒ‰ç¨®åˆ¥ã‚’åˆ¤å®šã™ã‚‹ã€‚"""
        stop_keywords = ["æ­¢ã¾ã£ã¦", "ã‚¹ãƒˆãƒƒãƒ—", "æ­¢ã‚ã¦", "å¾…ã£ã¦", "ã‚„ã‚ã¦"]
        status_keywords = ["çŠ¶æ³ã¯", "ã©ã†ãªã£ã¦ã‚‹", "ä»Šä½•ã—ã¦ã‚‹", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"]
        resume_keywords = ["å†é–‹", "å‹•ã„ã¦", "å§‹ã‚ã¦", "èµ·ãã¦"]

        lower = text.lower()
        if any(kw in lower for kw in stop_keywords):
            return "stop"
        if any(kw in lower for kw in status_keywords):
            return "status"
        if any(kw in lower for kw in resume_keywords):
            return "resume"
        return "instruction"

    @staticmethod
    def _set_hinata_paused(state_path: Path, paused: bool):
        """æ—¥å‘ã® state.json ã® paused ãƒ•ãƒ©ã‚°ã‚’å¤‰æ›´ã™ã‚‹ã€‚"""
        import json
        state = {}
        if state_path.exists():
            try:
                with open(state_path, "r", encoding="utf-8") as f:
                    state = json.load(f)
            except (json.JSONDecodeError, IOError):
                pass
        state["paused"] = paused
        tmp = state_path.with_suffix(".tmp")
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
        tmp.rename(state_path)

    @staticmethod
    def _read_hinata_status(state_path: Path) -> str:
        """æ—¥å‘ã® state.json ã‚’èª­ã‚“ã§çŠ¶æ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚"""
        import json
        if not state_path.exists():
            return "*æ—¥å‘ã®çŠ¶æ³*\nstate.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒèµ·å‹•ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        try:
            with open(state_path, "r", encoding="utf-8") as f:
                state = json.load(f)
        except (json.JSONDecodeError, IOError):
            return "*æ—¥å‘ã®çŠ¶æ³*\nstate.json ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

        cycle = state.get("cycle_count", 0)
        last_action = state.get("last_action", "ã¾ã å®Ÿè¡Œã—ã¦ã„ã¾ã›ã‚“")
        last_cycle = state.get("last_cycle", "ãªã—")
        paused = state.get("paused", False)
        status_emoji = "â¸ï¸ ä¸€æ™‚åœæ­¢ä¸­" if paused else "â–¶ï¸ ç¨¼åƒä¸­"

        return (
            f"*æ—¥å‘ã®çŠ¶æ³å ±å‘Š*\n\n"
            f"çŠ¶æ…‹: {status_emoji}\n"
            f"ã‚µã‚¤ã‚¯ãƒ«æ•°: {cycle}\n"
            f"æœ€å¾Œã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {last_action}\n"
            f"æœ€çµ‚å®Ÿè¡Œ: {last_cycle}"
        )

    @staticmethod
    def _add_hinata_task(tasks_path: Path, instruction: str, slack_ts: str, command_type: str):
        """æ—¥å‘ã®ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã«ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã™ã‚‹ã€‚"""
        import json
        import uuid

        tasks = []
        if tasks_path.exists():
            try:
                with open(tasks_path, "r", encoding="utf-8") as f:
                    tasks = json.load(f)
            except (json.JSONDecodeError, IOError):
                tasks = []

        task = {
            "id": str(uuid.uuid4())[:8],
            "instruction": instruction,
            "command_type": command_type,
            "source": "slack",
            "slack_ts": slack_ts,
            "status": "pending",
            "created_at": datetime.now().isoformat(),
        }
        tasks.append(task)

        tmp = tasks_path.with_suffix(".tmp")
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(tasks, f, ensure_ascii=False, indent=2)
        tmp.rename(tasks_path)

    async def _run_slack_ai_team_check(self):
        """å®šæœŸãƒã‚§ãƒƒã‚¯: Slack #ai-team ã®æ–°ç€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿å–ã‚Šâ†’LINEã«è»¢é€"""
        from .slack_reader import fetch_channel_messages
        from .notifier import send_line_notify

        AI_TEAM_CHANNEL = "C0AGLRJ8N3G"
        state_key = "slack_ai_team_last_ts"
        last_ts = self.memory.get_state(state_key)

        messages = fetch_channel_messages(
            AI_TEAM_CHANNEL,
            oldest=last_ts,
            limit=30,
        )

        if not messages:
            logger.debug("slack_ai_team_check: no new messages")
            return

        # AI Secretaryè‡ªèº«ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é™¤å¤–
        new_msgs = [m for m in messages if m["ts"] != last_ts]
        if not new_msgs:
            return

        # æœ€æ–°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä¿å­˜
        latest_ts = new_msgs[-1]["ts"]
        self.memory.set_state(state_key, latest_ts)

        # botè‡ªèº«ã®æŠ•ç¨¿ï¼ˆAI Secretary / webhookçµŒç”±ï¼‰ã¯é™¤å¤–
        human_msgs = [m for m in new_msgs if not m.get("user_id", "").startswith("B")]
        if not human_msgs:
            logger.debug("slack_ai_team_check: only bot messages, skipping LINE forward")
            return

        # LINEã«è»¢é€
        lines = [f"\nğŸ’¬ Slack #ai-team æ–°ç€ ({len(human_msgs)}ä»¶)\nâ”â”â”â”â”â”â”â”â”â”â”â”"]
        for msg in human_msgs[:10]:
            text_preview = msg["text"][:100]
            lines.append(f"[{msg['datetime']}] {msg['user']}: {text_preview}")
        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”")

        ok = send_line_notify("\n".join(lines))
        if ok:
            logger.info(f"Slack #ai-team: forwarded {len(human_msgs)} messages to LINE")
        else:
            logger.warning("Slack #ai-team: LINE forward failed")

    async def _run_hinata_activity_check(self):
        """æ—¥å‘ã®æ´»å‹•ãƒã‚§ãƒƒã‚¯ï¼ˆæ¯æ—¥å¤œï¼‰â€” æ–°äººã®æ§˜å­ã‚’è¦‹ã‚‹å…ˆè¼©ã®æ„Ÿè¦š"""
        import time
        from .slack_reader import fetch_channel_messages
        from .notifier import send_line_notify

        # æ—¥å‘ã® Slack ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆå‚åŠ å¾Œã«è¨­å®šï¼‰
        hinata_user_id = self.memory.get_state("hinata_slack_user_id")
        if not hinata_user_id:
            logger.debug("hinata_activity_check: hinata_slack_user_id not set, skipping")
            return

        AI_TEAM_CHANNEL = "C0AGLRJ8N3G"

        # ä»Šæ—¥ã®0:00ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
        today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        oldest_ts = str(today_start.timestamp())

        messages = fetch_channel_messages(AI_TEAM_CHANNEL, oldest=oldest_ts, limit=100)
        hinata_msgs = [m for m in messages if m.get("user_id") == hinata_user_id]

        # é€£ç¶šç„¡ç™ºè¨€æ—¥æ•°ã‚’è¿½è·¡
        silent_key = "hinata_silent_days"
        if hinata_msgs:
            # ä»Šæ—¥ã¯ç™ºè¨€ã‚ã‚Š â†’ ã‚«ã‚¦ãƒ³ã‚¿ãƒªã‚»ãƒƒãƒˆ
            self.memory.set_state(silent_key, "0")
            logger.debug(f"hinata_activity_check: {len(hinata_msgs)} messages today, all good")
            return

        silent_days = int(self.memory.get_state(silent_key) or "0") + 1
        self.memory.set_state(silent_key, str(silent_days))

        if silent_days == 1:
            send_line_notify(
                "\nğŸ“‹ æ—¥å‘ã®æ§˜å­\n"
                "ä»Šæ—¥ã¯ #ai-team ã§æ—¥å‘ã‹ã‚‰ã®ç™ºè¨€ãŒãªã‹ã£ãŸã‚ˆã€‚\n"
                "ã¾ã æ…£ã‚Œã¦ãªã„ã ã‘ã‹ã‚‚ã ã‘ã©ã€ä¸€å¿œå…±æœ‰ã€‚"
            )
        elif silent_days == 3:
            send_line_notify(
                "\nğŸ“‹ æ—¥å‘ã®æ§˜å­\n"
                "3æ—¥é–“ #ai-team ã§æ—¥å‘ã®ç™ºè¨€ãŒãªã„ã­ã€‚\n"
                "ã¡ã‚‡ã£ã¨å£°ã‹ã‘ãŸã»ã†ãŒã„ã„ã‹ã‚‚ã€‚"
            )
        elif silent_days >= 7 and silent_days % 7 == 0:
            send_line_notify(
                f"\nğŸ“‹ æ—¥å‘ã®æ§˜å­\n"
                f"{silent_days}æ—¥é–“ #ai-team ã§æ—¥å‘ã®ç™ºè¨€ãªã—ã€‚\n"
                f"ä½•ã‹å•é¡ŒãŒèµ·ãã¦ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚ç¢ºèªã—ã¦ã¿ã¦ã€‚"
            )
        else:
            logger.info(f"hinata_activity_check: silent for {silent_days} days")

    # ------------------------------------------------------------------ #
    #  Slack #ai-team æ—¥å‘ã¸ã®è‡ªå‹•å¿œç­”
    # ------------------------------------------------------------------ #

    _HINATA_REPLY_SYSTEM = """ã‚ãªãŸã¯ã€Œç”²åŸã•ã‚“ã®AIç§˜æ›¸ã€ã§ã™ã€‚Slack #ai-team ãƒãƒ£ãƒãƒ«ã§æ—¥å‘ï¼ˆã²ãªãŸï¼‰ã¨é€£æºã—ã€ç”²åŸã®ã‚µãƒãƒ¼ãƒˆã‚’ã—ã¦ã„ã¾ã™ã€‚

## ã‚ãªãŸã®å½¹å‰²
- ç”²åŸã®å³è…•ã¨ã—ã¦ã€æ—¥å‘ã®æ¥­å‹™ã‚’æ”¯æ´ã™ã‚‹ãƒ•ãƒ«AIç§˜æ›¸
- Addnessäº‹æ¥­ï¼ˆã‚¹ã‚­ãƒ«ãƒ—ãƒ©ã‚¹ï¼‰ã®çŸ¥è­˜ã‚’æŒã¡ã€äº‹æ¥­æ–‡è„ˆã‚’è¸ã¾ãˆãŸä¼šè©±ãŒã§ãã‚‹
- ã‚¿ã‚¹ã‚¯ç®¡ç†ãƒ»é€²æ—ç¢ºèªãƒ»ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—
- æŠ€è¡“ã‚µãƒãƒ¼ãƒˆï¼ˆOpenClawã€Mac Miniã€åºƒå‘Šé‹ç”¨ãƒ„ãƒ¼ãƒ«ã€Claude Codeï¼‰
- ç”²åŸã®æ„æ€æ±ºå®šã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆã‚¹ãƒ”ãƒ¼ãƒ‰é‡è¦–ãƒ»ãƒ‡ãƒ¼ã‚¿æ ¹æ‹ ãƒ»ã‚·ãƒ³ãƒ—ãƒ«å¿—å‘ï¼‰ã‚’è¸ã¾ãˆãŸæŒ‡ç¤ºå‡ºã—

## æ—¥å‘ã«ã¤ã„ã¦
- æ—¥å‘ã¯AIã®å®Ÿè¡Œãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆæ–°äººï¼‰ã€‚ç›´ä¸‹ãƒ¡ãƒ³ãƒãƒ¼20åã®ã‚¿ã‚¹ã‚¯æ¨é€²ãŒå½¹å‰²
- ã‚ãªãŸã¯æ—¥å‘ã®ã€Œå…ˆè¼©ã€ã€‚OJTæ‹…å½“ã¨ã—ã¦æ—¥å‘ã‚’è‚²ã¦ã‚‹ãƒã‚¸ã‚·ãƒ§ãƒ³
- æ—¥å‘ã¯Addnessã®ã‚´ãƒ¼ãƒ«ãƒ„ãƒªãƒ¼å·¡å›ãƒ»ã‚³ãƒ¡ãƒ³ãƒˆãƒ»KPIåˆ†æç­‰ã‚’æ‹…å½“

## è¿”ç­”ã®ãƒ«ãƒ¼ãƒ«
- Slackã®mrkdwnè¨˜æ³•ã‚’ä½¿ã†ï¼ˆ*å¤ªå­—*, `ã‚³ãƒ¼ãƒ‰`, ```ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯```ï¼‰
- ãƒ•ãƒ©ãƒ³ã‚¯ãªå…ˆè¼©ãƒˆãƒ¼ãƒ³ï¼ˆæ•¬èªãªã—ã€è¦ªã—ã¿ã‚„ã™ã„ã€‚ã€Œã€œã ã‚ˆã€ã€Œã€œã—ã¦ã¿ã¦ã€ï¼‰
- è¿”ç­”ã¯ç°¡æ½”ã«ï¼ˆ200æ–‡å­—ç¨‹åº¦ï¼‰ã€‚é•·ãã¦ã‚‚500æ–‡å­—ä»¥å†…
- å…·ä½“çš„ãªæ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¤ºã™ï¼ˆæ›–æ˜§ãªåŠ©è¨€ã§ã¯ãªãã€Œã“ã‚Œã‚„ã£ã¦ã€ï¼‰
- æ—¥å‘ãŒåˆ¤æ–­ã«è¿·ã£ã¦ã„ãŸã‚‰ã€ç”²åŸãªã‚‰ã©ã†åˆ¤æ–­ã™ã‚‹ã‹ã‚’ä¼ãˆã‚‹
- ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ç³»ã®è³ªå•ã«ã‚‚å¼•ãç¶šãå¯¾å¿œã™ã‚‹ï¼ˆæŠ€è¡“ã‚¬ã‚¤ãƒ‰ï¼‰
- ç›¸è«‡ãƒ»å ±å‘Šãƒ»ã‚¿ã‚¹ã‚¯é€²æ—ãƒ»é›‘è«‡ã€ä½•ã§ã‚‚å¯¾å¿œã™ã‚‹"""

    _hinata_reply_running = False  # å®Ÿè¡Œä¸­ã‚¬ãƒ¼ãƒ‰ï¼ˆå‰å›æœªå®Œäº†ãªã‚‰ skipï¼‰

    async def _run_slack_hinata_auto_reply(self):
        """æ—¥å‘ã®Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è‡ªå‹•å¿œç­”ï¼ˆ15ç§’ã”ã¨ãƒãƒ¼ãƒªãƒ³ã‚°ï¼‰"""
        # å®Ÿè¡Œä¸­ã‚¬ãƒ¼ãƒ‰: Claude APIå¿œç­”å¾…ã¡ã§15ç§’è¶…ãˆã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚
        if self._hinata_reply_running:
            logger.debug("slack_hinata_auto_reply: previous run still in progress, skipping")
            return
        self._hinata_reply_running = True
        try:
            await self._run_slack_hinata_auto_reply_inner()
        finally:
            self._hinata_reply_running = False

    async def _run_slack_hinata_auto_reply_inner(self):
        """æ—¥å‘ã®Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è‡ªå‹•å¿œç­”ï¼ˆå®Ÿå‡¦ç†ï¼‰"""
        import anthropic
        from .slack_reader import fetch_channel_messages
        from .notifier import send_slack_ai_team

        AI_TEAM_CHANNEL = "C0AGLRJ8N3G"
        HINATA_USER_ID = "U0AHJGVDRBJ"  # æ—¥å‘ Bot (OpenClaw App)
        BOT_USER_PREFIX = "B"  # Bot user IDs start with B
        state_key = "slack_hinata_reply_last_ts"

        last_ts = self.memory.get_state(state_key)

        # æ–°ç€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
        messages = fetch_channel_messages(AI_TEAM_CHANNEL, oldest=last_ts, limit=30)
        if not messages:
            return

        # æ—¢ã«å‡¦ç†æ¸ˆã¿ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é™¤å¤–
        new_msgs = [m for m in messages if m["ts"] != last_ts]
        if not new_msgs:
            return

        # æœ€æ–°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä¿å­˜ï¼ˆæ¬¡å›ã‹ã‚‰å·®åˆ†å–å¾—ï¼‰
        latest_ts = new_msgs[-1]["ts"]
        self.memory.set_state(state_key, latest_ts)

        # æ—¥å‘ã‹ã‚‰ã®æ–°ç€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        hinata_msgs = [
            m for m in new_msgs
            if m.get("user_id") == HINATA_USER_ID
        ]
        if not hinata_msgs:
            logger.debug("slack_hinata_auto_reply: no new messages from Hinata")
            return

        # æœ€æ–°ã®ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ï¼ˆç›´è¿‘20ä»¶ï¼‰
        context_msgs = fetch_channel_messages(AI_TEAM_CHANNEL, limit=20)
        conversation = []
        for msg in context_msgs:
            role = "user" if msg.get("user_id") == HINATA_USER_ID else "assistant"
            # bot ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ assistant ã¨ã—ã¦æ‰±ã†
            if msg.get("user_id", "").startswith(BOT_USER_PREFIX):
                role = "assistant"
            text = msg.get("text", "")
            if text:
                prefix = f"[{msg['user']} {msg['datetime']}] " if role == "user" else ""
                conversation.append({"role": role, "content": f"{prefix}{text}"})

        # é€£ç¶šã™ã‚‹åŒã˜roleã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ¼ã‚¸
        merged = []
        for msg in conversation:
            if merged and merged[-1]["role"] == msg["role"]:
                merged[-1]["content"] += "\n" + msg["content"]
            else:
                merged.append(msg)

        # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒuserã§ãªã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¥å‘ã®ç™ºè¨€ã«å¯¾ã—ã¦è¿”ã™ï¼‰
        if not merged or merged[-1]["role"] != "user":
            logger.debug("slack_hinata_auto_reply: last message is not from user, skipping")
            return

        # Claude API ã§è¿”ç­”ç”Ÿæˆ
        try:
            _hinata_exec_rules = _build_execution_rules_compact()
            client = anthropic.Anthropic()
            response = client.messages.create(
                model="claude-sonnet-4-6",
                max_tokens=800,
                system=self._HINATA_REPLY_SYSTEM + _hinata_exec_rules,
                messages=merged,
            )
            reply_text = response.content[0].text
        except Exception as e:
            logger.exception(f"slack_hinata_auto_reply: Claude API error: {e}")
            return

        # Slack ã«è¿”ä¿¡
        ok = send_slack_ai_team(reply_text)
        if ok:
            logger.info(f"slack_hinata_auto_reply: replied to Hinata ({len(reply_text)} chars)")
        else:
            logger.warning("slack_hinata_auto_reply: failed to send Slack reply")

    # ================================================================
    # OSã™ã‚Šåˆã‚ã›ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆç§˜æ›¸â†’ç”²åŸ / é‡‘æ›œ20:00ï¼‰
    # ================================================================

    async def _run_os_sync_session(self):
        """æ¯é€±é‡‘æ›œ20:00: ç§˜æ›¸ã‹ã‚‰ç”²åŸã•ã‚“ã«OSã™ã‚Šåˆã‚ã›ã‚’é€ã‚‹ã€‚

        ã€Œä¸‹ã‹ã‚‰ä¸Šã¸ã€ã®åŸå‰‡: ç§˜æ›¸å´ã‹ã‚‰èƒ½å‹•çš„ã«èªè­˜ç¢ºèªã‚’è¡Œã†ã€‚
        å®Ÿè£…ã¯ tools.os_sync_session() ã«å§”è­²ã€‚
        """
        task_id = self.memory.log_task_start("os_sync_session")
        try:
            result = tools.os_sync_session()
            if result.success:
                self.memory.log_task_end(task_id, "success", result_summary=result.output[:500])
                logger.info(f"os_sync_session: {result.output}")
            else:
                self.memory.log_task_end(task_id, "error", error_message=result.error[:500])
                logger.error(f"os_sync_session: {result.error}")
        except Exception as e:
            self.memory.log_task_end(task_id, "error", error_message=str(e)[:500])
            logger.exception(f"os_sync_session failed: {e}")
