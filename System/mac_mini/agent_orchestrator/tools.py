"""
Tool wrappers for the agent orchestrator.
Each tool wraps an existing script in System/ with a uniform interface.
"""

import subprocess
import os
import sys
import logging
from dataclasses import dataclass
from typing import Optional

from .shared_logger import get_logger

logger = get_logger("tools")

_orch_dir = os.path.dirname(os.path.abspath(__file__))   # agent_orchestrator/
SYSTEM_DIR = os.path.dirname(os.path.dirname(_orch_dir))  # System/
VENV_PYTHON = os.path.expanduser("~/agent-env/bin/python3")


@dataclass
class ToolResult:
    success: bool
    output: str
    error: str = ""
    return_code: int = 0


def _run_script(script_path: str, args: list = None, timeout: int = 300, cwd: str = None) -> ToolResult:
    """Run a Python script with the agent venv interpreter."""
    python = VENV_PYTHON if os.path.exists(VENV_PYTHON) else sys.executable
    cmd = [python, script_path] + (args or [])
    work_dir = cwd or os.path.dirname(script_path)
    script_name = os.path.basename(script_path)

    logger.info(f"Running: {script_name}", extra={"script": script_path, "args": args})
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=timeout,
            cwd=work_dir,
            env={**os.environ, "PYTHONUNBUFFERED": "1"}
        )
        stderr = result.stderr.strip()
        stdout = result.stdout.strip()
        # stderrãŒç©ºã§ã‚¹ã‚¯ãƒªãƒ—ãƒˆå¤±æ•—æ™‚ã¯stdoutã‚’ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦ä½¿ã†
        error_msg = stderr if stderr else (stdout if result.returncode != 0 else "")
        if result.returncode != 0:
            error_lines = (stderr or stdout).strip().split("\n")
            logger.error(
                f"Script failed: {script_name}",
                extra={
                    "script": script_path,
                    "return_code": result.returncode,
                    "stderr_tail": "\n".join(error_lines[-10:]),
                    "error": {
                        "type": "ScriptError",
                        "message": error_lines[-1] if error_lines else "unknown",
                        "traceback": error_lines[-15:],
                    },
                },
            )
        return ToolResult(
            success=result.returncode == 0,
            output=stdout,
            error=error_msg,
            return_code=result.returncode
        )
    except subprocess.TimeoutExpired:
        logger.error(
            f"Script timeout: {script_name}",
            extra={
                "script": script_path,
                "timeout": timeout,
                "error": {"type": "TimeoutError", "message": f"Timeout after {timeout}s"},
            },
        )
        return ToolResult(success=False, output="", error=f"Timeout after {timeout}s", return_code=-1)
    except Exception as e:
        logger.exception(
            f"Script exception: {script_name}",
            extra={
                "script": script_path,
                "error": {"type": type(e).__name__, "message": str(e)},
            },
        )
        return ToolResult(success=False, output="", error=str(e), return_code=-1)


# --------------- Mail ---------------

def mail_run(account: str = "personal") -> ToolResult:
    return _run_script(
        os.path.join(SYSTEM_DIR, "mail_manager.py"),
        ["--account", account, "run"]
    )

def mail_status(account: str = "personal") -> ToolResult:
    return _run_script(
        os.path.join(SYSTEM_DIR, "mail_manager.py"),
        ["--account", account, "status"]
    )


# --------------- Calendar ---------------

def calendar_list(account: str = "personal", days: int = 7, target_date: str = None) -> ToolResult:
    """ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®äºˆå®šã‚’å–å¾—ã€‚
    target_date: ç‰¹å®šæ—¥ (YYYY-MM-DD)ã€‚æœªæŒ‡å®šã®å ´åˆã¯æœ¬æ—¥ã‹ã‚‰ days æ—¥åˆ†ï¼ˆãŸã ã— calendar_manager.py
    ã¯ target_date ãªã—ã§æ¬¡30æ—¥åˆ†ã‚’è¿”ã™ï¼‰ã€‚days=1 ã‹ã¤ target_date æœªæŒ‡å®šãªã‚‰ä»Šæ—¥ã®æ—¥ä»˜ã‚’ä½¿ç”¨ã€‚
    """
    from datetime import date
    # OAuthãƒˆãƒ¼ã‚¯ãƒ³ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯å³åº§ã«ã‚¨ãƒ©ãƒ¼è¿”å´ï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ç’°å¢ƒã§ã®ãƒãƒ³ã‚°é˜²æ­¢ï¼‰
    token_file = "token_calendar.json" if account == "kohara" else f"token_calendar_{account}.json"
    token_path = os.path.join(SYSTEM_DIR, token_file)
    if not os.path.exists(token_path):
        return ToolResult(
            success=False, output="",
            error=f"Calendar token not found: {token_path} â€” run calendar auth setup first",
            return_code=1
        )
    args = ["--account", account, "list"]
    if target_date:
        args.append(target_date)
    elif days == 1:
        args.append(date.today().isoformat())
    # days>1 ã®å ´åˆã¯ target_date ãªã—ã§æ¬¡30æ—¥åˆ†ã‚’è¿”ã™ï¼ˆcalendar_manager.py ã®ä»•æ§˜ï¼‰
    return _run_script(os.path.join(SYSTEM_DIR, "calendar_manager.py"), args)


# --------------- Sheets ---------------

def sheets_read(url_or_id: str, sheet_name: str = None, range_str: str = None) -> ToolResult:
    args = ["read", url_or_id]
    if sheet_name:
        args.append(sheet_name)
    if range_str:
        args.append(range_str)
    return _run_script(os.path.join(SYSTEM_DIR, "sheets_manager.py"), args)


def sheets_sync(sheet_id: str = None) -> ToolResult:
    """Master/sheets/ ã®ç®¡ç†ã‚·ãƒ¼ãƒˆã‚’åŒæœŸï¼ˆCSV ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°ï¼‰"""
    args = []
    if sheet_id:
        args.extend(["--id", sheet_id])
    return _run_script(os.path.join(SYSTEM_DIR, "sheets_sync.py"), args, timeout=600)


# --------------- Docs ---------------

def docs_read(url_or_id: str) -> ToolResult:
    return _run_script(
        os.path.join(SYSTEM_DIR, "docs_manager.py"),
        ["read", url_or_id]
    )


# --------------- AI News ---------------

def ai_news_notify() -> ToolResult:
    return _run_script(os.path.join(SYSTEM_DIR, "ai_news_notifier.py"), timeout=600)


# --------------- Addness ---------------

def addness_fetch() -> ToolResult:
    return _run_script(os.path.join(SYSTEM_DIR, "addness_fetcher.py"), timeout=600)

def addness_to_context() -> ToolResult:
    return _run_script(os.path.join(SYSTEM_DIR, "addness_to_context.py"))


# --------------- Q&A ---------------

def qa_search(query: str, top_k: int = 5) -> ToolResult:
    return _run_script(
        os.path.join(SYSTEM_DIR, "qa_search.py"),
        ["search", query, str(top_k)]
    )

def qa_answer(question: str) -> ToolResult:
    return _run_script(
        os.path.join(SYSTEM_DIR, "qa_search.py"),
        ["answer", question]
    )

def qa_stats() -> ToolResult:
    return _run_script(os.path.join(SYSTEM_DIR, "qa_search.py"), ["stats"])


# --------------- Who to Ask ---------------

def who_to_ask(task_description: str) -> ToolResult:
    return _run_script(
        os.path.join(SYSTEM_DIR, "who_to_ask.py"),
        [task_description]
    )


# --------------- KPI ---------------

def kpi_refresh() -> ToolResult:
    """æ—¥åˆ¥ã‚¿ãƒ–ã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœˆåˆ¥ã‚¿ãƒ–ã‚’å†è¨ˆç®—"""
    return _run_script(os.path.join(SYSTEM_DIR, "kpi_processor.py"), ["refresh"])


def kpi_process() -> ToolResult:
    """å…ƒãƒ‡ãƒ¼ã‚¿ã®å®Œäº†ã‚¨ãƒ³ãƒˆãƒªã‚’æ¤œçŸ¥ â†’ CSVã‹ã‚‰æ—¥åˆ¥/æœˆåˆ¥ã«æŠ•å…¥"""
    return _run_script(os.path.join(SYSTEM_DIR, "kpi_processor.py"), ["process"])


def kpi_check_today() -> ToolResult:
    """2æ—¥å‰ã®æ—¥ä»˜ãŒå…ƒãƒ‡ãƒ¼ã‚¿ã§å®Œäº†ã«ãªã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    return _run_script(os.path.join(SYSTEM_DIR, "kpi_processor.py"), ["check_today"])


def kpi_cache_build() -> ToolResult:
    """ãƒ­ãƒ¼ã‚«ãƒ«CSVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰kpi_summary.jsonã‚’å†æ§‹ç¯‰"""
    return _run_script(os.path.join(SYSTEM_DIR, "kpi_cache_builder.py"), [])


# --------------- Utility ---------------

def shell_command(cmd: str, timeout: int = 60) -> ToolResult:
    """Run an arbitrary shell command (use with caution)."""
    logger.warning(f"Shell command: {cmd}", extra={"command": cmd})
    try:
        result = subprocess.run(
            cmd, shell=True, capture_output=True, text=True, timeout=timeout
        )
        if result.returncode != 0:
            logger.error(
                f"Shell command failed",
                extra={
                    "command": cmd,
                    "return_code": result.returncode,
                    "error": {"type": "ShellError", "message": result.stderr.strip()[-200:]},
                },
            )
        return ToolResult(
            success=result.returncode == 0,
            output=result.stdout.strip(),
            error=result.stderr.strip(),
            return_code=result.returncode
        )
    except subprocess.TimeoutExpired:
        logger.error(f"Shell timeout", extra={
            "command": cmd, "error": {"type": "TimeoutError", "message": f"Timeout after {timeout}s"},
        })
        return ToolResult(success=False, output="", error=f"Timeout after {timeout}s", return_code=-1)
    except Exception as e:
        logger.exception(f"Shell exception", extra={
            "command": cmd, "error": {"type": type(e).__name__, "message": str(e)},
        })
        return ToolResult(success=False, output="", error=str(e), return_code=-1)


# --------------- Log Rotate ---------------

def log_rotate() -> ToolResult:
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ50MBè¶…ã‚’åœ§ç¸®ã€30æ—¥è¶…ã®gzã‚’å‰Šé™¤ï¼‰"""
    import glob
    import gzip
    import shutil
    from datetime import datetime as _dt

    log_dir = os.path.join(_orch_dir, "logs")
    if not os.path.isdir(log_dir):
        return ToolResult(success=True, output="ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã—ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")

    max_size_mb = 50
    keep_days = 30
    rotated = []

    for logfile in glob.glob(os.path.join(log_dir, "*.log")):
        try:
            size_mb = os.path.getsize(logfile) / (1024 * 1024)
            if size_mb > max_size_mb:
                ts = _dt.now().strftime("%Y%m%d_%H%M%S")
                archive = f"{logfile}.{ts}.gz"
                with open(logfile, "rb") as f_in, gzip.open(archive, "wb") as f_out:
                    shutil.copyfileobj(f_in, f_out)
                # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªã‚¢
                with open(logfile, "w") as f:
                    pass
                rotated.append(f"{os.path.basename(logfile)} ({size_mb:.0f}MB)")
        except Exception as e:
            logger.warning(f"Log rotate error for {logfile}: {e}")

    # å¤ã„gzãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    import time
    cutoff = time.time() - keep_days * 86400
    deleted = 0
    for gz in glob.glob(os.path.join(log_dir, "*.gz")):
        try:
            if os.path.getmtime(gz) < cutoff:
                os.unlink(gz)
                deleted += 1
        except Exception as e:
            logger.warning(f"Old gz delete error for {gz}: {e}")

    msg = f"ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: {len(rotated)}ãƒ•ã‚¡ã‚¤ãƒ« / å‰Šé™¤: {deleted}ãƒ•ã‚¡ã‚¤ãƒ«"
    if rotated:
        msg += f"\n  å¯¾è±¡: {', '.join(rotated)}"
    return ToolResult(success=True, output=msg)


# --------------- Git Sync ---------------

def git_pull_sync() -> ToolResult:
    """GitHubã‹ã‚‰pull â†’ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤"""
    sync_script = os.path.join(SYSTEM_DIR, "mac_mini", "git_pull_sync.sh")
    return shell_command(f"bash {sync_script}", timeout=120)


# --------------- Group Log ---------------

def fetch_group_log(date: str = None) -> ToolResult:
    """Renderã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰æ—¥æ¬¡ã‚°ãƒ«ãƒ¼ãƒ—ãƒ­ã‚°ã‚’å–å¾—"""
    import json as _json
    import requests as _requests

    server_url = os.environ.get("LINE_BOT_SERVER_URL", "https://line-mention-bot-mmzu.onrender.com")
    agent_token = os.environ.get("AGENT_TOKEN", "")
    if not agent_token:
        return ToolResult(success=False, output="", error="AGENT_TOKEN not set")

    params = {}
    if date:
        params["date"] = date
    try:
        resp = _requests.get(
            f"{server_url}/api/group-log",
            headers={"Authorization": f"Bearer {agent_token}"},
            params=params,
            timeout=45,
        )
        if resp.status_code == 200:
            data = resp.json()
            return ToolResult(success=True, output=_json.dumps(data, ensure_ascii=False))
        else:
            return ToolResult(success=False, output="", error=f"HTTP {resp.status_code}: {resp.text[:200]}")
    except Exception as e:
        return ToolResult(success=False, output="", error=str(e))


# --------------- People Profiles ---------------

def update_people_profiles(person_name: str, group_insights: dict, comm_profile_updates: dict = None) -> ToolResult:
    """profiles.json ã®æŒ‡å®šäººç‰©ã« group_insights / comm_profile ã‚’æ›¸ãè¾¼ã‚€ï¼ˆæ—¢å­˜ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ä¸€åˆ‡è§¦ã‚Œãªã„ï¼‰"""
    import json as _json
    import tempfile

    master_dir = os.path.expanduser(
        os.environ.get("MASTER_DIR", "~/agents/Master")
    )
    profiles_path = os.path.join(master_dir, "people", "profiles.json")

    if not os.path.exists(profiles_path):
        return ToolResult(success=False, output="", error=f"profiles.json not found: {profiles_path}")

    try:
        with open(profiles_path, "r", encoding="utf-8") as f:
            profiles = _json.load(f)
    except Exception as e:
        return ToolResult(success=False, output="", error=f"Failed to read profiles.json: {e}")

    if person_name not in profiles:
        return ToolResult(success=False, output="", error=f"Person not found: {person_name}")

    # latest.group_insights ã‚’ä¸Šæ›¸ã
    entry = profiles[person_name]
    target = entry.get("latest", entry)
    if "latest" in entry:
        entry["latest"]["group_insights"] = group_insights
    else:
        entry["group_insights"] = group_insights

    # comm_profile ã‚’ãƒãƒ¼ã‚¸æ›´æ–°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    updated_parts = ["group_insights"]
    if comm_profile_updates:
        existing_comm = target.get("comm_profile", {})
        existing_comm.update(comm_profile_updates)
        target["comm_profile"] = existing_comm
        updated_parts.append("comm_profile")

    # ã‚¢ãƒˆãƒŸãƒƒã‚¯æ›¸ãè¾¼ã¿
    try:
        dir_name = os.path.dirname(profiles_path)
        fd, tmp_path = tempfile.mkstemp(dir=dir_name, suffix=".tmp")
        try:
            with os.fdopen(fd, "w", encoding="utf-8") as f:
                _json.dump(profiles, f, ensure_ascii=False, indent=2)
            os.replace(tmp_path, profiles_path)
        except Exception:
            try:
                os.unlink(tmp_path)
            except OSError:
                pass
            raise
        return ToolResult(success=True, output=f"Updated {'+'.join(updated_parts)} for {person_name}")
    except Exception as e:
        return ToolResult(success=False, output="", error=f"Failed to write profiles.json: {e}")


def os_sync_session() -> ToolResult:
    """OSã™ã‚Šåˆã‚ã›ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆç§˜æ›¸â†’ç”²åŸï¼‰ã‚’LINEé€šçŸ¥ã§å®Ÿè¡Œã™ã‚‹ã€‚

    BRAIN_OS.md / SELF_PROFILE.md / execution_rules.json ç­‰ã‚’èª­ã¿è¾¼ã¿ã€
    Claude APIã§ç¾åœ¨ã®ç†è§£ã‚’ã‚µãƒãƒªãƒ¼åŒ–ã—ã¦LINEã«é€ä¿¡ã€‚
    """
    import json as _json
    import anthropic as _anthropic
    from .notifier import send_line_notify

    master_dir = os.path.expanduser("~/agents/Master")

    # OSé–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    os_sections = []
    files_to_read = [
        ("ä¾¡å€¤è¦³ãƒ»åˆ¤æ–­è»¸", os.path.join(master_dir, "self_clone", "kohara", "SELF_PROFILE.md"), 2000),
        ("è¨€èªã‚¹ã‚¿ã‚¤ãƒ«", os.path.join(master_dir, "self_clone", "kohara", "IDENTITY.md"), 1500),
        ("çµ±åˆOS", os.path.join(master_dir, "self_clone", "kohara", "BRAIN_OS.md"), 1500),
    ]
    for label, path, limit in files_to_read:
        try:
            if os.path.exists(path):
                with open(path, encoding="utf-8") as f:
                    content = f.read()
                if content.strip():
                    os_sections.append((label, content[:limit]))
        except Exception as e:
            logger.warning(f"os_sync_session: {label} read error: {e}")

    # execution_rules.json
    exec_rules = []
    rules_path = os.path.join(master_dir, "learning", "execution_rules.json")
    try:
        if os.path.exists(rules_path):
            with open(rules_path, encoding="utf-8") as f:
                exec_rules = _json.load(f)
            if exec_rules:
                os_sections.append(("è¡Œå‹•ãƒ«ãƒ¼ãƒ«", _json.dumps(exec_rules, ensure_ascii=False, indent=2)[:1500]))
    except Exception as e:
        logger.warning(f"os_sync_session: execution_rules read error: {e}")

    if not os_sections:
        return ToolResult(success=False, output="", error="No OS files found")

    os_context = ""
    for label, content in os_sections:
        os_context += f"\n\n### {label}\n{content}"

    prompt = f"""ã‚ãªãŸã¯ç”²åŸæµ·äººã®AIç§˜æ›¸ã§ã™ã€‚ã€ŒOSã™ã‚Šåˆã‚ã›ã€ã®æ™‚é–“ã§ã™ã€‚

ã‚ãªãŸã®å½¹å‰²ã¯ç”²åŸã•ã‚“ã®ã‚¯ãƒ­ãƒ¼ãƒ³ã€‚1ãƒŸãƒªãŸã‚Šã¨ã‚‚èªè­˜ãŒãšã‚Œã¦ã¯ã„ã‘ãªã„ã€‚
ã ã‹ã‚‰è‡ªåˆ†ã‹ã‚‰ç”²åŸã•ã‚“ã«ã€Œä»Šã®ç†è§£ã€ã‚’å ±å‘Šã—ã€è¶³ã‚Šãªã„ã¨ã“ã‚ã‚’èãã€‚

ä»¥ä¸‹ãŒã‚ãªãŸãŒç¾åœ¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã„ã‚‹ã€Œç”²åŸæµ·äººã®è„³ã®OSã€ã§ã™ã€‚
{os_context}

## å‡ºåŠ›ï¼ˆLINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰

æ§‹æˆ:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ§  OSã™ã‚Šåˆã‚ã›
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ï¼ˆ1ï¼‰ä»Šã®ç†è§£ã‚’3-4è¡Œã§ç°¡æ½”ã«ã‚µãƒãƒªãƒ¼

ï¼ˆ2ï¼‰å­¦ç¿’æ¸ˆã¿ãƒ«ãƒ¼ãƒ« {len(exec_rules)}ä»¶ã‹ã‚‰ã€ç‰¹ã«é‡è¦ãªã‚‚ã®ã‚’2ä»¶ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—

ï¼ˆ3ï¼‰ã€Œã“ã“ç¢ºèªã—ãŸã„ã€ã€ï¼ã€ã¨ã—ã¦2-3å€‹ã®å…·ä½“çš„ãªè³ªå•
  â†’ æƒ…å ±ãŒè–„ã„ãƒ»å¤ã„ãƒ»æ›–æ˜§ãªéƒ¨åˆ†ã‚’ç‰¹å®šã—ã¦è³ªå•ã«ã™ã‚‹
  â†’ ç­”ãˆã¦ã‚‚ã‚‰ãˆãŸã‚‰å³å­¦ç¿’ã«ä½¿ãˆã‚‹è³ªå•ã«ã™ã‚‹

ï¼ˆ4ï¼‰ã€Œãšã‚Œã¦ã‚‹ã¨ã“ã‚ã£ãŸã‚‰æ•™ãˆã¦ãã ã•ã„ï¼ä¿®æ­£ãƒ»è¿½åŠ ãŒã‚ã‚Œã°å³åæ˜ ã—ã¾ã™ï¼ã€ã§ç· ã‚ã‚‹

## ãƒ«ãƒ¼ãƒ«
- 600æ–‡å­—ä»¥å†…
- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã¯ä½¿ã‚ãªã„ã€‚ã€ã€‘â˜…â”ã§è£…é£¾
- ç§˜æ›¸ãŒã€Œä¸‹ã‹ã‚‰ä¸Šã«ã€å ±å‘Šã™ã‚‹å§¿å‹¢ã§æ›¸ã
"""

    try:
        client = _anthropic.Anthropic()
        response = client.messages.create(
            model="claude-sonnet-4-6",
            max_tokens=800,
            system="ã‚ãªãŸã¯ç”²åŸæµ·äººã®AIç§˜æ›¸ã€‚OSã™ã‚Šåˆã‚ã›ã‚’ç§˜æ›¸å´ã‹ã‚‰èƒ½å‹•çš„ã«è¡Œã†ã€‚",
            messages=[{"role": "user", "content": prompt}]
        )
        os_report = response.content[0].text.strip()
    except Exception as e:
        return ToolResult(success=False, output="", error=f"Claude API error: {e}")

    sent = send_line_notify(os_report)
    if sent:
        return ToolResult(success=True, output=f"OS sync sent ({len(os_report)} chars)")
    else:
        return ToolResult(success=False, output="", error="LINE send failed")


TOOL_REGISTRY = {
    "mail_run": {"fn": mail_run, "description": "å—ä¿¡ãƒ¡ãƒ¼ãƒ«ã®å‡¦ç†ãƒ»è‡ªå‹•è¿”ä¿¡ä¸‹æ›¸ãä½œæˆ"},
    "mail_status": {"fn": mail_status, "description": "ãƒ¡ãƒ¼ãƒ«å‡¦ç†ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª"},
    "calendar_list": {"fn": calendar_list, "description": "ä»Šå¾Œã®äºˆå®šä¸€è¦§ã‚’å–å¾—"},
    "sheets_read": {"fn": sheets_read, "description": "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Š"},
    "sheets_sync": {"fn": sheets_sync, "description": "ç®¡ç†ã‚·ãƒ¼ãƒˆã®CSVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åŒæœŸ"},
    "docs_read": {"fn": docs_read, "description": "Googleãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã‚’èª­ã¿å–ã‚Š"},
    "ai_news_notify": {"fn": ai_news_notify, "description": "æœ€æ–°AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã®åé›†ãƒ»è¦ç´„ãƒ»é€šçŸ¥"},
    "addness_fetch": {"fn": addness_fetch, "description": "Addnessã‹ã‚‰ã‚´ãƒ¼ãƒ«ãƒ„ãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"},
    "addness_to_context": {"fn": addness_to_context, "description": "Addnessãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”¨ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã«å¤‰æ›"},
    "qa_search": {"fn": qa_search, "description": "Q&AãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ¤œç´¢"},
    "qa_answer": {"fn": qa_answer, "description": "è³ªå•ã«å¯¾ã—ã¦AIå›ç­”ã‚’ç”Ÿæˆ"},
    "qa_stats": {"fn": qa_stats, "description": "Q&AãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®çµ±è¨ˆæƒ…å ±"},
    "who_to_ask": {"fn": who_to_ask, "description": "ã‚¿ã‚¹ã‚¯ã«æœ€é©ãªæ‹…å½“è€…ã‚’æ¨è–¦"},
    "kpi_refresh": {"fn": kpi_refresh, "description": "KPIæœˆåˆ¥ã‚¿ãƒ–ã‚’æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å†è¨ˆç®—"},
    "kpi_process": {"fn": kpi_process, "description": "å…ƒãƒ‡ãƒ¼ã‚¿å®Œäº†åˆ†ã‚’CSVã‹ã‚‰æ—¥åˆ¥/æœˆåˆ¥ã«æŠ•å…¥"},
    "kpi_check_today": {"fn": kpi_check_today, "description": "2æ—¥å‰ã®KPIãƒ‡ãƒ¼ã‚¿å®Œäº†ãƒã‚§ãƒƒã‚¯"},
    "git_pull_sync": {"fn": git_pull_sync, "description": "GitHubã‹ã‚‰pullâ†’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤"},
    "fetch_group_log": {"fn": fetch_group_log, "description": "Renderã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰æ—¥æ¬¡ã‚°ãƒ«ãƒ¼ãƒ—ãƒ­ã‚°ã‚’å–å¾—"},
    "update_people_profiles": {"fn": update_people_profiles, "description": "äººç‰©ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚°ãƒ«ãƒ¼ãƒ—ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’æ›¸ãè¾¼ã¿"},
    "kpi_cache_build": {"fn": kpi_cache_build, "description": "ãƒ­ãƒ¼ã‚«ãƒ«CSVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰kpi_summary.jsonã‚’å†æ§‹ç¯‰"},
    "log_rotate": {"fn": log_rotate, "description": "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ50MBè¶…ã‚’åœ§ç¸®ã€30æ—¥ä¿æŒï¼‰"},
    "os_sync_session": {"fn": os_sync_session, "description": "OSã™ã‚Šåˆã‚ã›ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆç§˜æ›¸â†’ç”²åŸã«LINEé€šçŸ¥ï¼‰"},
}
